{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPworwS5vkj9/fNbjv7uHUf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# import"],"metadata":{"id":"KJKYeVTmF-sQ"}},{"cell_type":"code","source":["# embedding sizeをDeBERTa-v3に合わせてみる"],"metadata":{"id":"itybQGmf3bZQ","executionInfo":{"status":"ok","timestamp":1663066670624,"user_tz":-540,"elapsed":8,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5176531e","executionInfo":{"status":"ok","timestamp":1663066670625,"user_tz":-540,"elapsed":9,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["# tabularとNLP 両方, それこそマルチモーダルにするか???\n","# SAINT + DeBERTa → 情報抽出 → 数層のMLP\n","\n","# 順番的には\n","# 1. html contentを無視した lightgbm baseline\n","# 3. SAINTの実装\n","# 4. DeBERTa等, 自然言語モデルの実装\n","# 5. 3-4よりMultimodal化"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","%cd /content/drive/MyDrive/_MUFG_student"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJChsaHZFhXI","executionInfo":{"status":"ok","timestamp":1663066727035,"user_tz":-540,"elapsed":56418,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"1b2b6eee-ef25-412b-c0e0-55e3ff0d385f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/_MUFG_student\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install einops"],"metadata":{"id":"LOB4ymqhC6K0","executionInfo":{"status":"ok","timestamp":1663066730423,"user_tz":-540,"elapsed":3390,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"839f06e9","executionInfo":{"status":"ok","timestamp":1663066735764,"user_tz":-540,"elapsed":5344,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["# base\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import glob\n","import shutil\n","\n","# others\n","import os\n","import warnings\n","warnings.simplefilter('ignore')\n","\n","# main\n","\n","import sys\n","ROOT_PATH = '/content/drive/My Drive/_MUFG_student'\n","sys.path.append(ROOT_PATH)\n","ROOT_PATH = '/content/drive/My Drive/_MUFG_student/saint'\n","sys.path.append(ROOT_PATH)\n","ROOT_PATH = '/content/drive/My Drive/_MUFG_student/saint/models'\n","sys.path.append(ROOT_PATH)\n","\n","import torch\n","from torch import nn\n","import argparse\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","from saint.utils import count_parameters, classification_scores, mean_sq_error\n","from saint.augmentations import embed_data_mask\n","from saint.augmentations import add_noise\n","from saint.models import SAINT\n","from saint.pretraining import SAINT_pretrain\n","import re\n","import gc\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWByfiO89--E","executionInfo":{"status":"ok","timestamp":1663066735764,"user_tz":-540,"elapsed":4,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"9c97af88-61a5-4bd9-d9b7-1429a56d6a27"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["data  figure  outputs  saint  src\n"]}]},{"cell_type":"markdown","source":["# configration"],"metadata":{"id":"wdZHg7wrGDsM"}},{"cell_type":"code","source":["class SAINT_Config:\n","\n","    # private\n","    _exp_num = '003'\n","\n","    # 学習param\n","    seed = 0\n","    num_fold = 5\n","    model_name = \"saint\"\n","    drop_columns = ['id', 'html_content', 'goal']\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # saint param\n","    task = 'binary'\n","    dtask = 'clf'\n","    cont_embeddings = 'MLP'\n","    embedding_size = 128# 768\n","    transformer_depth = 4# 6\n","    attention_heads = 8\n","    attention_dropout = 0.3# 0.1\n","    ff_dropout = 0.3# 0.1\n","    attentiontype = 'colrow'\n","    optimizer = 'AdamW'\n","    scheduler = 'cosine'\n","\n","    lr = 0.0001\n","    epochs = 60# 100\n","    eval_epoch = 1\n","    batchsize = 4\n","    set_seed = seed# saint用\n","    dset_seed = seed# saint用\n","\n","    vision_dset = False\n","    dset_id = None\n","    active_log = False\n","    pretrain = True\n","    pretrain_epochs = 100\n","\n","    pt_tasks = ['contrastive','denoising']\n","    pt_aug = []# ['mixup','cutmix']\n","    pt_aug_lam = 0.1\n","    mixup_lam = 0.3\n","    train_mask_prob = 0# 0\n","    mask_prob = 0\n","    ssl_avail_y = 0\n","    pt_projhead_style = 'diff'\n","    nce_temp = 0.7\n","    lam0 = 0.5\n","    lam1 = 10\n","    lam2 = 1\n","    lam3 = 10\n","    final_mlp_style = 'sep'\n","\n","    # 保存先\n","    save_folder_name = f'Exp{_exp_num}_{model_name}'\n","    run_name = save_folder_name# saint用\n","    \n","def set_seed(seed=0):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","def setup(config):\n","    print(\"### Configration Setup...\")\n","\n","    set_seed(config.seed)\n","    config.train_path = './data/train.csv'\n","    config.test_path = './data/test.csv'\n","\n","    config.output_path = './outputs'\n","    config.experiment_path = os.path.join(config.output_path, config.save_folder_name)\n","    print(f'    experiment_path  >> {config.experiment_path}')\n","    config.model_save_path = os.path.join(config.experiment_path, 'model')\n","    config.modelsave_path = os.path.join(config.experiment_path, 'model')# saint用\n","\n","    print(f'    model_save_path >> {config.model_save_path}')\n","    config.figure_save_path = os.path.join(config.experiment_path, 'figure')\n","    print(f'    figure_save_path >> {config.figure_save_path}')\n","    config.preds_save_path = os.path.join(config.experiment_path, 'preds')\n","    print(f'    preds_save_path >> {config.preds_save_path}')\n","    \n","    for d in [config.output_path, config.experiment_path, config.model_save_path, config.figure_save_path, config.preds_save_path]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    print(\"### Setup Complete. \\n\")\n","    return config"],"metadata":{"id":"RUVB8nb_G9mQ","executionInfo":{"status":"ok","timestamp":1663066735765,"user_tz":-540,"elapsed":2,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"f_eWqcaAaV_5"}},{"cell_type":"code","source":["# 前処理系\n","# Train Test 共通の処理関数\n","def goal_split(x):\n","    x = x.split('-')\n","    x = re.sub('[^0-9]', '',  x[0])\n","    return int(x)\n","\n","def singular_mask(df, column, threshold):\n","    counts = df[column].value_counts()\n","    res_bool = df[column].isin(counts[counts<threshold].index)\n","    df.loc[res_bool, column] = 'unknown'\n","    return df\n","\n","def test_cat_mask(df, column, unique_list):\n","    def cat_mask(x):\n","        if x not in unique_list[column]:\n","            x = 'unknown'\n","        return x\n","    df.loc[:,column] = df[column].map(cat_mask)\n","    return df\n","# ======================\n","\n","\n","def get_train_data(config):\n","\n","    train_df = pd.read_csv(config.train_path)\n","    \n","    # 前処理\n","    train_df['goal_min'] = train_df['goal'].map(goal_split)\n","    # 数によってunknownにするカテゴリ変数の設定\n","    unique_cat_list = {}\n","    threshold = 10\n","    train_df = singular_mask(train_df, 'category2', threshold)\n","    counts = train_df['category2'].value_counts()\n","    unique_cat_list['category2'] = counts[counts>threshold].index.values # save\n","    # print(unique_cat_list)\n","    config.unique_cat_list = unique_cat_list\n","\n","    if len(config.drop_columns) > 0:# 余計な列のdrop\n","        train_df = train_df.drop(config.drop_columns, axis=1)\n","    \n","    # label encoding + categoriesの登録\n","    config.categories = train_df.columns[train_df.dtypes==\"object\"].values\n","    cat_dims = []\n","    if len(config.categories)>0:\n","        label_encoders = {}\n","        for c in config.categories:\n","            print(c)\n","            encoder = LabelEncoder()\n","            train_df[c] = encoder.fit_transform(train_df[c])\n","            label_encoders[c] = encoder\n","            cat_dims.append(len(encoder.classes_))\n","        config.label_encoders = label_encoders\n","\n","    X = train_df.drop('state', axis=1)\n","    y = train_df['state']\n","    categories = list(config.categories)\n","    continuous = list(set(X.columns.tolist()) - set(categories))\n","    cat_idxs = [ i for i, c in enumerate(X.columns) if c in categories]\n","    con_idxs = list(set(range(len(X.columns))) - set(cat_idxs))\n","    cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int)\n","\n","    config.cat_dims = cat_dims\n","    config.con_idxs = con_idxs\n","    config.cat_idxs = cat_idxs\n","\n","    return X, y, cat_dims, cat_idxs, con_idxs\n","    # return cat_dims, cat_idxs, con_idxs, train_df\n","    # train_df >> X_train, y_train, X_valid, y_valid, train_mean, train_std\n","\n","def get_test_data(config):\n","    test_df = pd.read_csv(config.test_path)\n","\n","    # 前処理\n","    test_df['goal_min'] = test_df['goal'].map(goal_split)\n","    test_df = test_cat_mask(test_df, 'category2', config.unique_cat_list)\n","\n","    if len(config.drop_columns) > 0:\n","        test_df = test_df.drop(config.drop_columns, axis=1)\n","    \n","    # label encoding\n","    if len(config.categories)>0:\n","        for c in config.categories:\n","            print(c)\n","            test_df[c] = config.label_encoders[c].transform(test_df[c])\n","\n","    return test_df"],"metadata":{"id":"a0dhZALSabVl","executionInfo":{"status":"ok","timestamp":1663066736121,"user_tz":-540,"elapsed":4,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class DataSetCatCon(Dataset):\n","    def __init__(self, X, Y, cat_cols, task='clf', continuous_mean_std=None):\n","\n","        cat_cols = list(cat_cols)\n","\n","        temp = X.fillna(\"MissingValue\")\n","        X_mask = temp.ne(\"MissingValue\").astype(int)\n","\n","        con_cols = list(set(np.arange(X.shape[1])) - set(cat_cols))\n","        self.X1 = X.iloc[:,cat_cols].copy().astype(np.int64) #categorical columns\n","        self.X2 = X.iloc[:,con_cols].copy().astype(np.float32) #numerical columns\n","        self.X1_mask = X_mask.iloc[:,cat_cols].copy().astype(np.int64) #categorical columns\n","        self.X2_mask = X_mask.iloc[:,con_cols].copy().astype(np.int64) #numerical columns\n","        self.y = Y\n","        self.cls = np.expand_dims(np.zeros_like(self.y,dtype=int), -1)\n","        self.cls_mask = np.expand_dims(np.ones_like(self.y,dtype=int), -1)\n","        if continuous_mean_std is not None:\n","            mean, std = continuous_mean_std\n","            self.X2 = (self.X2 - mean) / std\n","\n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        # X1 has categorical data, X2 has continuous\n","        return np.concatenate((self.cls[idx], self.X1.iloc[idx])), np.array(self.X2.iloc[idx]), np.array(self.y.iloc[idx]), np.concatenate((self.cls_mask[idx], self.X1_mask.iloc[idx])), np.array(self.X2_mask.iloc[idx])\n"],"metadata":{"id":"uy0Rv1tlNjIY","executionInfo":{"status":"ok","timestamp":1663066736121,"user_tz":-540,"elapsed":4,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train\n","from sklearn.metrics import f1_score\n","def f1_metric(preds, train_data):\n","    labels = train_data.get_label()\n","    preds = np.round(preds)\n","    return 'f1', f1_score(labels, preds), True\n","\n","def saint_training(config, X, y, cat_dims, cat_idxs, con_idxs, param_tuning=False):\n","\n","    folds = StratifiedKFold(n_splits=config.num_fold)\n","    splits = folds.split(np.zeros(len(X)), y)\n","\n","    oof_pred = np.zeros((len(X), 2), dtype=np.float32)\n","    fold_num = np.zeros(len(X), dtype=np.int32)\n","\n","    for fold, (train_index, valid_index) in enumerate(splits):\n","\n","        print(f'\\nStart fold {fold} =====================================')\n","        X_train = X.iloc[train_index].reset_index(drop=True)\n","        y_train = y.iloc[train_index].reset_index(drop=True)\n","        train_mean, train_std = np.array(X_train.iloc[:,con_idxs],dtype=np.float32).mean(0), np.array(X_train.iloc[:,con_idxs],dtype=np.float32).std(0)\n","        train_std = np.where(train_std < 1e-6, 1e-6, train_std)\n","        continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32) \n","        np.save(os.path.join(config.model_save_path, f'cms{fold}.npy'), continuous_mean_std)\n","        print(f'continuous_mean_std: \\n{continuous_mean_std}\\n')# saveする?\n","        X_valid = X.iloc[valid_index].reset_index(drop=True)\n","        y_valid = y.iloc[valid_index].reset_index(drop=True)\n","\n","        print(f'X_train shape: {X_train.shape}')\n","        print(f'y_train shape: {y_train.shape}')\n","        print(f'X_valid shape: {X_valid.shape}')\n","        print(f'y_valid shape: {y_valid.shape}')\n","\n","        # Dataset + Dataloader\n","        train_ds = DataSetCatCon(X_train, y_train, cat_idxs, task=config.dtask, continuous_mean_std=continuous_mean_std)\n","        trainloader = DataLoader(train_ds, batch_size=config.batchsize, shuffle=True, num_workers=os.cpu_count())\n","        valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs, task=config.dtask, continuous_mean_std=continuous_mean_std)\n","        validloader = DataLoader(valid_ds, batch_size=config.batchsize, shuffle=False, num_workers=os.cpu_count())\n","\n","        # define model\n","        model = SAINT(\n","            categories = tuple(cat_dims), \n","            num_continuous = len(con_idxs),                \n","            dim = config.embedding_size,                           \n","            dim_out = 1,                       \n","            depth = config.transformer_depth,                       \n","            heads = config.attention_heads,                         \n","            attn_dropout = config.attention_dropout,             \n","            ff_dropout = config.ff_dropout,                  \n","            mlp_hidden_mults = (4, 2),       \n","            cont_embeddings = config.cont_embeddings,\n","            attentiontype = config.attentiontype,\n","            final_mlp_style = config.final_mlp_style,\n","            y_dim = 2\n","        )\n","        criterion = nn.CrossEntropyLoss().to(config.device)\n","        model.to(config.device)\n","        optimizer = optim.AdamW(model.parameters(),lr=config.lr)\n","\n","        # pretraining\n","        model = SAINT_pretrain(model, cat_idxs, X_train, y_train, continuous_mean_std, config, config.device)\n","\n","        # training\n","        best_valid_auroc = 0\n","        best_valid_accuracy = 0\n","        best_valid_f1 = 0.0\n","        best_valid_preds = None\n","        best_epoch = 0\n","        print('Training begins now.')\n","        for epoch in range(config.epochs):\n","            model.train()\n","            running_loss = 0.0\n","            for i, data in enumerate(trainloader, 0):\n","                optimizer.zero_grad()\n","                x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(config.device), data[1].to(config.device),data[2].to(config.device),data[3].to(config.device),data[4].to(config.device)\n","\n","                _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model, config. vision_dset)   \n","                reps = model.transformer(x_categ_enc, x_cont_enc)\n","                y_reps = reps[:,0,:]\n","                y_outs = model.mlpfory(y_reps)\n","                loss = criterion(y_outs, y_gts.squeeze())\n","                loss.backward()\n","                optimizer.step()\n","                running_loss += loss.item()\n","            print(f'epoch{epoch+1}: running_loss={running_loss}')\n","            if epoch%config.eval_epoch==0:\n","                model.eval()\n","                with torch.no_grad():\n","                    train_accuracy, train_auroc, train_f1, _ = classification_scores(model, trainloader, config.device, 'binary', config.vision_dset)\n","                    print(f'[EPOCH {epoch+1}] TRAIN F1: {train_f1} TRAIN ACCURACY: {train_accuracy:.3f}, TRAIN AUROC: {train_auroc:.3f}')\n","                    \n","                    valid_accuracy, valid_auroc, valid_f1, valid_pred = classification_scores(model, validloader, config.device, 'binary', config.vision_dset)\n","                    print(f'[EPOCH {epoch+1}] VALID F1: {valid_f1} VALID ACCURACY: {valid_accuracy:.3f}, VALID AUROC: {valid_auroc:.3f}')\n","                    if valid_f1 > best_valid_f1:\n","                        best_valid_accuracy = valid_accuracy\n","                        best_valid_auroc = valid_auroc\n","                        best_valid_f1 = valid_f1   \n","                        best_valid_preds = valid_pred\n","                        best_epoch = epoch\n","                        torch.save(model.state_dict(),f'{config.modelsave_path}/bestmodel{fold}.pth')\n","                model.train()\n","\n","        print(f'F1 on best model: {best_valid_f1:.6f} (Epoch{best_epoch})')\n","\n","        print(best_valid_preds.shape)\n","        oof_pred[valid_index] = best_valid_preds.astype(np.float32)\n","        fold_num[valid_index] = fold+1\n","        del model; gc.collect()\n","        \n","    pred = np.argmax(oof_pred, axis=1)# torch.argmax(m(y_outs), dim=1).float()\n","    cv_score = f1_score(y, pred)\n","    print(f'\\nFinal CV = {cv_score:.5f}')\n","\n","    return cv_score, oof_pred\n","\n","# util 入れ替え"],"metadata":{"id":"ledQcK-Ej1h0","executionInfo":{"status":"ok","timestamp":1663066736372,"user_tz":-540,"elapsed":254,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def inferring(config, X_test):\n","    config.model_weights = [p for p in sorted(glob.glob(os.path.join(config.model_save_path, 'bestmodel*.pth')))]\n","    sub_pred = np.zeros((len(X_test),2), dtype=np.float32)\n","    print(sub_pred.shape)\n","    dummy_y = pd.Series([i for i in range(len(X_test))])\n","    for fold, model_weight in enumerate(config.model_weights):\n","\n","        continuous_mean_std = np.load(os.path.join(config.model_save_path, f'cms{fold}.npy'))\n","        test_ds = DataSetCatCon(X_test, dummy_y, config.cat_idxs, task=config.dtask, continuous_mean_std=continuous_mean_std)\n","        testloader = DataLoader(test_ds, batch_size=config.batchsize, shuffle=False, num_workers=os.cpu_count())\n","\n","        model = SAINT(\n","            categories = tuple(config.cat_dims), \n","            num_continuous = len(config.con_idxs),                \n","            dim = config.embedding_size,                           \n","            dim_out = 1,                       \n","            depth = config.transformer_depth,                       \n","            heads = config.attention_heads,                         \n","            attn_dropout = config.attention_dropout,             \n","            ff_dropout = config.ff_dropout,                  \n","            mlp_hidden_mults = (4, 2),       \n","            cont_embeddings = config.cont_embeddings,\n","            attentiontype = config.attentiontype,\n","            final_mlp_style = config.final_mlp_style,\n","            y_dim = 2\n","        )\n","        model.load_state_dict(torch.load(model_weight))\n","        model.to(config.device)\n","\n","        model.eval()\n","        y_pred = torch.empty(0).to(config.device)\n","        y_out = torch.empty(0).to(config.device)\n","        with torch.no_grad():\n","            for i, data in enumerate(testloader, 0):\n","                x_categ, x_cont, _, cat_mask, con_mask = data[0].to(config.device), data[1].to(config.device),data[2].to(config.device),data[3].to(config.device),data[4].to(config.device)\n","                _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model, config.vision_dset)           \n","                reps = model.transformer(x_categ_enc, x_cont_enc)\n","                y_reps = reps[:,0,:]\n","                print(y_reps.size())\n","                y_outs = model.mlpfory(y_reps)\n","                # import ipdb; ipdb.set_trace() \n","                y_out = torch.cat([y_out,y_outs.float()],dim=0) \n","                y_pred = torch.cat([y_pred,torch.argmax(y_outs, dim=1).float()],dim=0)\n","\n","        sub_pred += y_out.detach().cpu().numpy() / len(config.model_weights)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(config.preds_save_path, 'sub_pred.npy'), sub_pred)\n","    return sub_pred# 返すのはprobability"],"metadata":{"id":"jVzzf5KOTW6c","executionInfo":{"status":"ok","timestamp":1663066736372,"user_tz":-540,"elapsed":3,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def copy_scripts(config):\n","    scripts_save_path = os.path.join(config.experiment_path, 'scripts')\n","    os.makedirs(scripts_save_path, exist_ok=True)\n","    for script in glob.glob('./src/*.ipynb'):\n","        dst_file = os.path.join(scripts_save_path, script.split('/')[-1])\n","        print(f'[save file] {dst_file}')\n","        shutil.copyfile(script, dst_file)"],"metadata":{"id":"V_8u1wFoTdRk","executionInfo":{"status":"ok","timestamp":1663066736372,"user_tz":-540,"elapsed":3,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def main():\n","    \n","    saint_config = setup(SAINT_Config())\n","    train_path = './data/train.csv'\n","    test_path = './data/test.csv'\n","    submit_path = './data/sample_submit.csv'\n","\n","    X, y, cat_dims, cat_idxs, con_idxs = get_train_data(saint_config)\n","    X_test = get_test_data(saint_config)\n","    score, oof_pred = saint_training(saint_config, X, y, cat_dims, cat_idxs, con_idxs, param_tuning=False)\n","\n","    sub_pred = inferring(saint_config, X_test)\n","    sub = pd.read_csv(submit_path, header=None)\n","    sub[1] = np.argmax(sub_pred, axis=1).astype(int)\n","\n","    def fix_leak(sub, train_path, test_path):\n","        print(\"===== fix_leak =====\")\n","        train_df = pd.read_csv(train_path)\n","        test_df = pd.read_csv(test_path)\n","        duplicated = pd.merge(test_df, train_df[['goal', 'country', 'duration', 'category1', 'category2', 'html_content', 'state']], on=['goal', 'country', 'duration', 'category1', 'category2', 'html_content'], how=\"left\")\n","        duplicated = duplicated[~duplicated[\"state\"].isnull()]\n","        for i in duplicated.index:\n","            print(f'Fix index{i}: {sub.loc[i,1]}')\n","            sub.loc[i, 1] = int(duplicated.loc[i, \"state\"])\n","            print(f'To {sub.loc[i,1]}')\n","        return sub\n","    sub = fix_leak(sub, train_path, test_path)\n","\n","    # 提出用ファイル\n","    sub.to_csv(os.path.join(saint_config.preds_save_path, f'Exp{saint_config._exp_num}_CV{int(score*(10**10))}_submission.csv'), index=False, header=False)\n","\n","    # scriptの保存\n","    copy_scripts(saint_config)\n","\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"_c0Ys4IsfH9n","outputId":"cb2b69c0-7c6c-4e42-ad4d-fae500f0a42c","executionInfo":{"status":"error","timestamp":1663100249934,"user_tz":-540,"elapsed":10091902,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["### Configration Setup...\n","    experiment_path  >> ./outputs/Exp003_saint\n","    model_save_path >> ./outputs/Exp003_saint/model\n","    figure_save_path >> ./outputs/Exp003_saint/figure\n","    preds_save_path >> ./outputs/Exp003_saint/preds\n","### Setup Complete. \n","\n","country\n","category1\n","category2\n","country\n","category1\n","category2\n","\n","Start fold 0 =====================================\n","continuous_mean_std: \n","[[3.26407051e+01 1.19044473e+04]\n"," [1.21512165e+01 2.16121484e+04]]\n","\n","X_train shape: (7832, 5)\n","y_train shape: (7832,)\n","X_valid shape: (1959, 5)\n","y_valid shape: (1959,)\n","Pretraining begins!\n","Epoch: 0, Running Loss: 2933.033352551982\n","Epoch: 1, Running Loss: 458.09788082540035\n","Epoch: 2, Running Loss: 382.3175116367638\n","Epoch: 3, Running Loss: 309.2883503451012\n","Epoch: 4, Running Loss: 243.42846058821306\n","Epoch: 5, Running Loss: 175.0873505875934\n","Epoch: 6, Running Loss: 165.148962332285\n","Epoch: 7, Running Loss: 177.89241575053893\n","Epoch: 8, Running Loss: 153.03003870195244\n","Epoch: 9, Running Loss: 102.55047184810974\n","Epoch: 10, Running Loss: 103.15929240174592\n","Epoch: 11, Running Loss: 147.01978361600777\n","Epoch: 12, Running Loss: 83.0942824879312\n","Epoch: 13, Running Loss: 118.36365863174433\n","Epoch: 14, Running Loss: 75.31925325887278\n","Epoch: 15, Running Loss: 65.15584200446028\n","Epoch: 16, Running Loss: 90.14594171626959\n","Epoch: 17, Running Loss: 72.38390811633144\n","Epoch: 18, Running Loss: 65.5923742124578\n","Epoch: 19, Running Loss: 61.08616271009669\n","Epoch: 20, Running Loss: 56.01836349547375\n","Epoch: 21, Running Loss: 63.12287687024218\n","Epoch: 22, Running Loss: 51.12263952899957\n","Epoch: 23, Running Loss: 45.59274470503442\n","Epoch: 24, Running Loss: 56.94135939088301\n","Epoch: 25, Running Loss: 49.49625737733004\n","Epoch: 26, Running Loss: 39.07840828204644\n","Epoch: 27, Running Loss: 51.54746677694493\n","Epoch: 28, Running Loss: 49.914869598462246\n","Epoch: 29, Running Loss: 41.195759683003416\n","Epoch: 30, Running Loss: 42.056312014115974\n","Epoch: 31, Running Loss: 46.985097841970855\n","Epoch: 32, Running Loss: 32.43735601393564\n","Epoch: 33, Running Loss: 52.91582009862759\n","Epoch: 34, Running Loss: 36.89997179066995\n","Epoch: 35, Running Loss: 37.35800239216769\n","Epoch: 36, Running Loss: 50.328801843046676\n","Epoch: 37, Running Loss: 32.95101501354657\n","Epoch: 38, Running Loss: 45.2977719088085\n","Epoch: 39, Running Loss: 34.601301454677014\n","Epoch: 40, Running Loss: 35.20641360612353\n","Epoch: 41, Running Loss: 43.61519102015882\n","Epoch: 42, Running Loss: 89.16784453843138\n","Epoch: 43, Running Loss: 21.77510566588171\n","Epoch: 44, Running Loss: 37.52355920487025\n","Epoch: 45, Running Loss: 26.449686470572487\n","Epoch: 46, Running Loss: 31.352891708520474\n","Epoch: 47, Running Loss: 35.061899669643026\n","Epoch: 48, Running Loss: 32.068617739656474\n","Epoch: 49, Running Loss: 31.22050210335874\n","Epoch: 50, Running Loss: 31.0979912035109\n","Epoch: 51, Running Loss: 40.25969575421186\n","Epoch: 52, Running Loss: 28.26714701272431\n","Epoch: 53, Running Loss: 61.413850318756886\n","Epoch: 54, Running Loss: 19.75639980549022\n","Epoch: 55, Running Loss: 20.99197209884005\n","Epoch: 56, Running Loss: 17.91262648141128\n","Epoch: 57, Running Loss: 744.9685406735225\n","Epoch: 58, Running Loss: 11.939779121617903\n","Epoch: 59, Running Loss: 26.069792816604604\n","Epoch: 60, Running Loss: 14.025837214998319\n","Epoch: 61, Running Loss: 28.09158442261105\n","Epoch: 62, Running Loss: 24.90836045049946\n","Epoch: 63, Running Loss: 34.83769478314207\n","Epoch: 64, Running Loss: 28.523802522875485\n","Epoch: 65, Running Loss: 25.545624147023773\n","Epoch: 66, Running Loss: 27.268037389389065\n","Epoch: 67, Running Loss: 21.266139713363373\n","Epoch: 68, Running Loss: 24.354350324341794\n","Epoch: 69, Running Loss: 28.57625214631844\n","Epoch: 70, Running Loss: 21.025149712499115\n","Epoch: 71, Running Loss: 25.818482152273646\n","Epoch: 72, Running Loss: 26.14685860092868\n","Epoch: 73, Running Loss: 18.593050488831068\n","Epoch: 74, Running Loss: 25.186413337360136\n","Epoch: 75, Running Loss: 23.336217837932054\n","Epoch: 76, Running Loss: 26.250676086812746\n","Epoch: 77, Running Loss: 24.480977841638378\n","Epoch: 78, Running Loss: 17.199051237970707\n","Epoch: 79, Running Loss: 25.150481932047114\n","Epoch: 80, Running Loss: 25.428561476568575\n","Epoch: 81, Running Loss: 14.650286883479566\n","Epoch: 82, Running Loss: 20.432551157580747\n","Epoch: 83, Running Loss: 28.542314890051784\n","Epoch: 84, Running Loss: 26.073939188427175\n","Epoch: 85, Running Loss: 14.727600804711983\n","Epoch: 86, Running Loss: 23.726360863176524\n","Epoch: 87, Running Loss: 18.15867565451481\n","Epoch: 88, Running Loss: 27.621181147460447\n","Epoch: 89, Running Loss: 18.21270831368747\n","Epoch: 90, Running Loss: 18.787598131384584\n","Epoch: 91, Running Loss: 22.61110358595033\n","Epoch: 92, Running Loss: 40.187474506004946\n","Epoch: 93, Running Loss: 11.690126468434755\n","Epoch: 94, Running Loss: 16.369503983201867\n","Epoch: 95, Running Loss: 18.445734137341788\n","Epoch: 96, Running Loss: 22.03188432369643\n","Epoch: 97, Running Loss: 24.932766736281337\n","Epoch: 98, Running Loss: 12.41958467727818\n","Epoch: 99, Running Loss: 40.225767781055765\n","END OF PRETRAINING!\n","Training begins now.\n","epoch1: running_loss=1100.734470567666\n","[EPOCH 1] TRAIN F1: 0.7253371185237758 TRAIN ACCURACY: 75.294, TRAIN AUROC: 0.840\n","[EPOCH 1] VALID F1: 0.701617401003904 VALID ACCURACY: 72.690, VALID AUROC: 0.818\n","epoch2: running_loss=983.7072304189205\n","[EPOCH 2] TRAIN F1: 0.7460355029585799 TRAIN ACCURACY: 72.600, TRAIN AUROC: 0.835\n","[EPOCH 2] VALID F1: 0.7333643555141928 VALID ACCURACY: 70.750, VALID AUROC: 0.816\n","epoch3: running_loss=952.6547628538683\n","[EPOCH 3] TRAIN F1: 0.7406784412671713 TRAIN ACCURACY: 76.379, TRAIN AUROC: 0.856\n","[EPOCH 3] VALID F1: 0.7143655673560648 VALID ACCURACY: 73.915, VALID AUROC: 0.827\n","epoch4: running_loss=933.2230142839253\n","[EPOCH 4] TRAIN F1: 0.6782385085181615 TRAIN ACCURACY: 74.438, TRAIN AUROC: 0.856\n","[EPOCH 4] VALID F1: 0.6645489199491741 VALID ACCURACY: 73.047, VALID AUROC: 0.824\n","epoch5: running_loss=921.9296960487845\n","[EPOCH 5] TRAIN F1: 0.7298058396324292 TRAIN ACCURACY: 76.724, TRAIN AUROC: 0.868\n","[EPOCH 5] VALID F1: 0.6916666666666667 VALID ACCURACY: 73.558, VALID AUROC: 0.828\n","epoch6: running_loss=914.4980982253328\n","[EPOCH 6] TRAIN F1: 0.7016938519447931 TRAIN ACCURACY: 75.715, TRAIN AUROC: 0.872\n","[EPOCH 6] VALID F1: 0.6712328767123288 VALID ACCURACY: 73.047, VALID AUROC: 0.830\n","epoch7: running_loss=898.5810594810173\n","[EPOCH 7] TRAIN F1: 0.7859674856374527 TRAIN ACCURACY: 77.643, TRAIN AUROC: 0.878\n","[EPOCH 7] VALID F1: 0.7447013487475916 VALID ACCURACY: 72.945, VALID AUROC: 0.827\n","epoch8: running_loss=885.0439863733482\n","[EPOCH 8] TRAIN F1: 0.7904903417533433 TRAIN ACCURACY: 78.396, TRAIN AUROC: 0.880\n","[EPOCH 8] VALID F1: 0.737457379444715 VALID ACCURACY: 72.486, VALID AUROC: 0.823\n","epoch9: running_loss=871.0123385367915\n","[EPOCH 9] TRAIN F1: 0.790052606408417 TRAIN ACCURACY: 77.579, TRAIN AUROC: 0.883\n","[EPOCH 9] VALID F1: 0.7439024390243902 VALID ACCURACY: 72.129, VALID AUROC: 0.824\n","epoch10: running_loss=863.1430184105411\n","[EPOCH 10] TRAIN F1: 0.7906122984135309 TRAIN ACCURACY: 79.609, TRAIN AUROC: 0.886\n","[EPOCH 10] VALID F1: 0.7307692307692307 VALID ACCURACY: 73.558, VALID AUROC: 0.825\n","epoch11: running_loss=870.7338263897691\n","[EPOCH 11] TRAIN F1: 0.7896984254069923 TRAIN ACCURACY: 79.877, TRAIN AUROC: 0.894\n","[EPOCH 11] VALID F1: 0.720682302771855 VALID ACCURACY: 73.252, VALID AUROC: 0.822\n","epoch12: running_loss=820.4786788006313\n","[EPOCH 12] TRAIN F1: 0.7932717000513612 TRAIN ACCURACY: 79.443, TRAIN AUROC: 0.893\n","[EPOCH 12] VALID F1: 0.7279151943462898 VALID ACCURACY: 72.486, VALID AUROC: 0.821\n","epoch13: running_loss=822.6200178788858\n","[EPOCH 13] TRAIN F1: 0.8024482354473239 TRAIN ACCURACY: 80.631, TRAIN AUROC: 0.900\n","[EPOCH 13] VALID F1: 0.7342945417095779 VALID ACCURACY: 73.660, VALID AUROC: 0.821\n","epoch14: running_loss=824.48385430302\n","[EPOCH 14] TRAIN F1: 0.7944977073780742 TRAIN ACCURACY: 81.116, TRAIN AUROC: 0.901\n","[EPOCH 14] VALID F1: 0.7202643171806168 VALID ACCURACY: 74.068, VALID AUROC: 0.824\n","epoch15: running_loss=819.6247765705921\n","[EPOCH 15] TRAIN F1: 0.8030479142451246 TRAIN ACCURACY: 80.529, TRAIN AUROC: 0.900\n","[EPOCH 15] VALID F1: 0.7275525910723448 VALID ACCURACY: 72.894, VALID AUROC: 0.822\n","epoch16: running_loss=816.0918601488884\n","[EPOCH 16] TRAIN F1: 0.8019683468546349 TRAIN ACCURACY: 80.988, TRAIN AUROC: 0.904\n","[EPOCH 16] VALID F1: 0.7315010570824525 VALID ACCURACY: 74.068, VALID AUROC: 0.820\n","epoch17: running_loss=804.4567120911088\n","[EPOCH 17] TRAIN F1: 0.8009079983976499 TRAIN ACCURACY: 80.963, TRAIN AUROC: 0.906\n","[EPOCH 17] VALID F1: 0.73048128342246 VALID ACCURACY: 74.273, VALID AUROC: 0.825\n","epoch18: running_loss=792.6210885144101\n","[EPOCH 18] TRAIN F1: 0.805446946204665 TRAIN ACCURACY: 81.576, TRAIN AUROC: 0.908\n","[EPOCH 18] VALID F1: 0.7117360735532722 VALID ACCURACY: 72.792, VALID AUROC: 0.821\n","epoch19: running_loss=788.6854875805366\n","[EPOCH 19] TRAIN F1: 0.7679594828735172 TRAIN ACCURACY: 77.771, TRAIN AUROC: 0.872\n","[EPOCH 19] VALID F1: 0.7061965811965812 VALID ACCURACY: 71.924, VALID AUROC: 0.801\n","epoch20: running_loss=785.5855593562301\n","[EPOCH 20] TRAIN F1: 0.8093132154006244 TRAIN ACCURACY: 81.282, TRAIN AUROC: 0.910\n","[EPOCH 20] VALID F1: 0.7204134366925065 VALID ACCURACY: 72.384, VALID AUROC: 0.814\n","epoch21: running_loss=780.5804223635523\n","[EPOCH 21] TRAIN F1: 0.8196129032258064 TRAIN ACCURACY: 82.150, TRAIN AUROC: 0.913\n","[EPOCH 21] VALID F1: 0.7311827956989247 VALID ACCURACY: 73.201, VALID AUROC: 0.821\n","epoch22: running_loss=768.3476633846294\n","[EPOCH 22] TRAIN F1: 0.7803881511746681 TRAIN ACCURACY: 80.784, TRAIN AUROC: 0.915\n","[EPOCH 22] VALID F1: 0.6915451895043732 VALID ACCURACY: 72.996, VALID AUROC: 0.815\n","epoch23: running_loss=768.624364959589\n","[EPOCH 23] TRAIN F1: 0.8207955888144939 TRAIN ACCURACY: 82.572, TRAIN AUROC: 0.916\n","[EPOCH 23] VALID F1: 0.7260345730749084 VALID ACCURACY: 73.303, VALID AUROC: 0.818\n","epoch24: running_loss=753.4981665886289\n","[EPOCH 24] TRAIN F1: 0.7879136690647481 TRAIN ACCURACY: 81.180, TRAIN AUROC: 0.914\n","[EPOCH 24] VALID F1: 0.6997118155619597 VALID ACCURACY: 73.405, VALID AUROC: 0.817\n","epoch25: running_loss=750.9392438723007\n","[EPOCH 25] TRAIN F1: 0.8224275083397485 TRAIN ACCURACY: 82.329, TRAIN AUROC: 0.917\n","[EPOCH 25] VALID F1: 0.7166494312306102 VALID ACCURACY: 72.027, VALID AUROC: 0.811\n","epoch26: running_loss=751.6132266748464\n","[EPOCH 26] TRAIN F1: 0.8189632716853348 TRAIN ACCURACY: 82.252, TRAIN AUROC: 0.917\n","[EPOCH 26] VALID F1: 0.7261410788381742 VALID ACCURACY: 73.047, VALID AUROC: 0.818\n","epoch27: running_loss=742.658790574802\n","[EPOCH 27] TRAIN F1: 0.8212957023733162 TRAIN ACCURACY: 82.214, TRAIN AUROC: 0.919\n","[EPOCH 27] VALID F1: 0.7201225740551582 VALID ACCURACY: 72.027, VALID AUROC: 0.810\n","epoch28: running_loss=731.3012107064715\n","[EPOCH 28] TRAIN F1: 0.8149456521739131 TRAIN ACCURACY: 82.610, TRAIN AUROC: 0.922\n","[EPOCH 28] VALID F1: 0.7152173913043479 VALID ACCURACY: 73.252, VALID AUROC: 0.816\n","epoch29: running_loss=722.615899592621\n","[EPOCH 29] TRAIN F1: 0.8194704466434876 TRAIN ACCURACY: 82.763, TRAIN AUROC: 0.924\n","[EPOCH 29] VALID F1: 0.7096774193548386 VALID ACCURACY: 71.976, VALID AUROC: 0.808\n","epoch30: running_loss=736.434219581919\n","[EPOCH 30] TRAIN F1: 0.7952914154464543 TRAIN ACCURACY: 81.793, TRAIN AUROC: 0.919\n","[EPOCH 30] VALID F1: 0.6781017724413951 VALID ACCURACY: 71.261, VALID AUROC: 0.813\n","epoch31: running_loss=725.1429456520964\n","[EPOCH 31] TRAIN F1: 0.829495407071851 TRAIN ACCURACY: 82.699, TRAIN AUROC: 0.924\n","[EPOCH 31] VALID F1: 0.729985082048732 VALID ACCURACY: 72.282, VALID AUROC: 0.811\n","epoch32: running_loss=728.0281874919092\n","[EPOCH 32] TRAIN F1: 0.8192934782608695 TRAIN ACCURACY: 83.018, TRAIN AUROC: 0.927\n","[EPOCH 32] VALID F1: 0.7109890109890109 VALID ACCURACY: 73.150, VALID AUROC: 0.814\n","epoch33: running_loss=708.5936733364306\n","[EPOCH 33] TRAIN F1: 0.8194810600804773 TRAIN ACCURACY: 83.389, TRAIN AUROC: 0.926\n","[EPOCH 33] VALID F1: 0.7092829349638687 VALID ACCURACY: 73.303, VALID AUROC: 0.816\n","epoch34: running_loss=707.1013527070563\n","[EPOCH 34] TRAIN F1: 0.8298587760591796 TRAIN ACCURACY: 83.848, TRAIN AUROC: 0.931\n","[EPOCH 34] VALID F1: 0.7026455026455026 VALID ACCURACY: 71.312, VALID AUROC: 0.810\n","epoch35: running_loss=703.9304513101015\n","[EPOCH 35] TRAIN F1: 0.8105895196506551 TRAIN ACCURACY: 82.278, TRAIN AUROC: 0.920\n","[EPOCH 35] VALID F1: 0.7014523937600861 VALID ACCURACY: 71.669, VALID AUROC: 0.807\n","epoch36: running_loss=705.382914314526\n","[EPOCH 36] TRAIN F1: 0.8309327036599764 TRAIN ACCURACY: 81.716, TRAIN AUROC: 0.927\n","[EPOCH 36] VALID F1: 0.7326007326007326 VALID ACCURACY: 70.189, VALID AUROC: 0.814\n","epoch37: running_loss=704.9387290660525\n","[EPOCH 37] TRAIN F1: 0.837994722955145 TRAIN ACCURACY: 84.321, TRAIN AUROC: 0.936\n","[EPOCH 37] VALID F1: 0.7158555729984302 VALID ACCURACY: 72.282, VALID AUROC: 0.807\n","epoch38: running_loss=691.6324297699593\n","[EPOCH 38] TRAIN F1: 0.8210143915048205 TRAIN ACCURACY: 83.644, TRAIN AUROC: 0.933\n","[EPOCH 38] VALID F1: 0.6966797974113675 VALID ACCURACY: 72.486, VALID AUROC: 0.812\n","epoch39: running_loss=691.1625878411069\n","[EPOCH 39] TRAIN F1: 0.800339847068819 TRAIN ACCURACY: 81.997, TRAIN AUROC: 0.920\n","[EPOCH 39] VALID F1: 0.6893810335036911 VALID ACCURACY: 72.078, VALID AUROC: 0.809\n","epoch40: running_loss=685.4201252773346\n","[EPOCH 40] TRAIN F1: 0.830188679245283 TRAIN ACCURACY: 84.027, TRAIN AUROC: 0.932\n","[EPOCH 40] VALID F1: 0.7044093630919979 VALID ACCURACY: 72.282, VALID AUROC: 0.811\n","epoch41: running_loss=684.935319752607\n","[EPOCH 41] TRAIN F1: 0.8304715181248298 TRAIN ACCURACY: 84.116, TRAIN AUROC: 0.933\n","[EPOCH 41] VALID F1: 0.7120304844855743 VALID ACCURACY: 72.996, VALID AUROC: 0.812\n","epoch42: running_loss=760.8292459135118\n","[EPOCH 42] TRAIN F1: 0.8347480106100795 TRAIN ACCURACY: 84.091, TRAIN AUROC: 0.933\n","[EPOCH 42] VALID F1: 0.6983122362869199 VALID ACCURACY: 70.801, VALID AUROC: 0.801\n","epoch43: running_loss=710.7415676593446\n","[EPOCH 43] TRAIN F1: 0.8379931060896209 TRAIN ACCURACY: 83.797, TRAIN AUROC: 0.932\n","[EPOCH 43] VALID F1: 0.7229763700351935 VALID ACCURACY: 71.873, VALID AUROC: 0.802\n","epoch44: running_loss=664.9073143849964\n","[EPOCH 44] TRAIN F1: 0.8320285675044636 TRAIN ACCURACY: 84.385, TRAIN AUROC: 0.938\n","[EPOCH 44] VALID F1: 0.7144396551724138 VALID ACCURACY: 72.945, VALID AUROC: 0.807\n","epoch45: running_loss=664.8034813154372\n","[EPOCH 45] TRAIN F1: 0.8413486670151595 TRAIN ACCURACY: 84.499, TRAIN AUROC: 0.935\n","[EPOCH 45] VALID F1: 0.7195059186824497 VALID ACCURACY: 72.180, VALID AUROC: 0.812\n","epoch46: running_loss=666.8529573639535\n","[EPOCH 46] TRAIN F1: 0.8392834128109292 TRAIN ACCURACY: 84.078, TRAIN AUROC: 0.933\n","[EPOCH 46] VALID F1: 0.7166156982670743 VALID ACCURACY: 71.618, VALID AUROC: 0.809\n","epoch47: running_loss=669.8270514951837\n","[EPOCH 47] TRAIN F1: 0.8332876336715108 TRAIN ACCURACY: 84.474, TRAIN AUROC: 0.939\n","[EPOCH 47] VALID F1: 0.7023743787962451 VALID ACCURACY: 72.486, VALID AUROC: 0.807\n","epoch48: running_loss=657.7122803270322\n","[EPOCH 48] TRAIN F1: 0.8479404593866289 TRAIN ACCURACY: 84.870, TRAIN AUROC: 0.942\n","[EPOCH 48] VALID F1: 0.7233606557377049 VALID ACCURACY: 72.435, VALID AUROC: 0.811\n","epoch49: running_loss=645.6213634561636\n","[EPOCH 49] TRAIN F1: 0.8263408010862185 TRAIN ACCURACY: 83.670, TRAIN AUROC: 0.932\n","[EPOCH 49] VALID F1: 0.7051771117166212 VALID ACCURACY: 72.384, VALID AUROC: 0.808\n","epoch50: running_loss=654.9830767684798\n","[EPOCH 50] TRAIN F1: 0.8419644051920245 TRAIN ACCURACY: 84.921, TRAIN AUROC: 0.942\n","[EPOCH 50] VALID F1: 0.701063829787234 VALID ACCURACY: 71.312, VALID AUROC: 0.800\n","epoch51: running_loss=644.618745279259\n","[EPOCH 51] TRAIN F1: 0.8510430645358058 TRAIN ACCURACY: 84.410, TRAIN AUROC: 0.944\n","[EPOCH 51] VALID F1: 0.7217391304347827 VALID ACCURACY: 70.597, VALID AUROC: 0.801\n","epoch52: running_loss=649.0190715892172\n","[EPOCH 52] TRAIN F1: 0.8255080588647512 TRAIN ACCURACY: 84.104, TRAIN AUROC: 0.936\n","[EPOCH 52] VALID F1: 0.6978579481397971 VALID ACCURACY: 72.639, VALID AUROC: 0.813\n","epoch53: running_loss=649.4350488259734\n","[EPOCH 53] TRAIN F1: 0.8368371083683712 TRAIN ACCURACY: 84.640, TRAIN AUROC: 0.940\n","[EPOCH 53] VALID F1: 0.705691056910569 VALID ACCURACY: 72.282, VALID AUROC: 0.810\n","epoch54: running_loss=654.6692019864859\n","[EPOCH 54] TRAIN F1: 0.8493628437290408 TRAIN ACCURACY: 85.661, TRAIN AUROC: 0.946\n","[EPOCH 54] VALID F1: 0.7094703049759229 VALID ACCURACY: 72.282, VALID AUROC: 0.804\n","epoch55: running_loss=645.2823369682919\n","[EPOCH 55] TRAIN F1: 0.8361268873805235 TRAIN ACCURACY: 84.895, TRAIN AUROC: 0.943\n","[EPOCH 55] VALID F1: 0.6953210010881392 VALID ACCURACY: 71.414, VALID AUROC: 0.804\n","epoch56: running_loss=640.3317763156956\n","[EPOCH 56] TRAIN F1: 0.8493890675241157 TRAIN ACCURACY: 85.049, TRAIN AUROC: 0.944\n","[EPOCH 56] VALID F1: 0.7191467750126967 VALID ACCURACY: 71.771, VALID AUROC: 0.797\n","epoch57: running_loss=636.217198197186\n","[EPOCH 57] TRAIN F1: 0.8507678172988581 TRAIN ACCURACY: 85.483, TRAIN AUROC: 0.946\n","[EPOCH 57] VALID F1: 0.7121447028423772 VALID ACCURACY: 71.567, VALID AUROC: 0.800\n","epoch58: running_loss=628.3568716722075\n","[EPOCH 58] TRAIN F1: 0.8404866960823638 TRAIN ACCURACY: 84.768, TRAIN AUROC: 0.940\n","[EPOCH 58] VALID F1: 0.7232237539766703 VALID ACCURACY: 73.354, VALID AUROC: 0.810\n","epoch59: running_loss=629.2430379585126\n","[EPOCH 59] TRAIN F1: 0.848529959062151 TRAIN ACCURACY: 84.410, TRAIN AUROC: 0.941\n","[EPOCH 59] VALID F1: 0.7236971484759096 VALID ACCURACY: 71.312, VALID AUROC: 0.798\n","epoch60: running_loss=642.9077654941906\n","[EPOCH 60] TRAIN F1: 0.8501234888860002 TRAIN ACCURACY: 85.278, TRAIN AUROC: 0.944\n","[EPOCH 60] VALID F1: 0.7269922879177377 VALID ACCURACY: 72.894, VALID AUROC: 0.808\n","F1 on best model: 0.744701 (Epoch6)\n","(1959, 2)\n","\n","Start fold 1 =====================================\n","continuous_mean_std: \n","[[3.2705605e+01 1.1778070e+04]\n"," [1.2187842e+01 2.1753777e+04]]\n","\n","X_train shape: (7833, 5)\n","y_train shape: (7833,)\n","X_valid shape: (1958, 5)\n","y_valid shape: (1958,)\n","Pretraining begins!\n","Epoch: 0, Running Loss: 2741.203919198364\n","Epoch: 1, Running Loss: 455.0504088308662\n","Epoch: 2, Running Loss: 358.2512996881269\n","Epoch: 3, Running Loss: 337.67702594958246\n","Epoch: 4, Running Loss: 184.52430355199613\n","Epoch: 5, Running Loss: 239.9746417598799\n","Epoch: 6, Running Loss: 174.01802803960163\n","Epoch: 7, Running Loss: 143.5051103187725\n","Epoch: 8, Running Loss: 139.6059727241518\n","Epoch: 9, Running Loss: 140.79655633785296\n","Epoch: 10, Running Loss: 100.86746613442665\n","Epoch: 11, Running Loss: 113.85880960349459\n","Epoch: 12, Running Loss: 83.48065860121278\n","Epoch: 13, Running Loss: 96.76760509936139\n","Epoch: 14, Running Loss: 83.20329655887326\n","Epoch: 15, Running Loss: 75.02815905492753\n","Epoch: 16, Running Loss: 71.6472203801386\n","Epoch: 17, Running Loss: 84.90745282024727\n","Epoch: 18, Running Loss: 66.401363054174\n","Epoch: 19, Running Loss: 58.644843051501084\n","Epoch: 20, Running Loss: 70.88754816399887\n","Epoch: 21, Running Loss: 64.91862970282091\n","Epoch: 22, Running Loss: 43.93849920097273\n","Epoch: 23, Running Loss: 77.87675970571581\n","Epoch: 24, Running Loss: 50.958348093612585\n","Epoch: 25, Running Loss: 53.1099219948519\n","Epoch: 26, Running Loss: 48.44075347261969\n","Epoch: 27, Running Loss: 54.67216619750252\n","Epoch: 28, Running Loss: 54.569665018920205\n","Epoch: 29, Running Loss: 45.865270960639464\n","Epoch: 30, Running Loss: 57.20508134903503\n","Epoch: 31, Running Loss: 44.738063733195304\n","Epoch: 32, Running Loss: 39.732592280139215\n","Epoch: 33, Running Loss: 53.055332477757474\n","Epoch: 34, Running Loss: 52.562560951919295\n","Epoch: 35, Running Loss: 34.933333882450825\n","Epoch: 36, Running Loss: 48.02623386334744\n","Epoch: 37, Running Loss: 33.734670317790005\n","Epoch: 38, Running Loss: 65.16051746657467\n","Epoch: 39, Running Loss: 27.752739420422586\n","Epoch: 40, Running Loss: 33.26536111392488\n","Epoch: 41, Running Loss: 38.91210923145991\n","Epoch: 42, Running Loss: 36.79685176219209\n","Epoch: 43, Running Loss: 28.644344554981217\n","Epoch: 44, Running Loss: 41.79961659836408\n","Epoch: 45, Running Loss: 25.882383787582512\n","Epoch: 46, Running Loss: 44.02462319422921\n","Epoch: 47, Running Loss: 33.158827684645075\n","Epoch: 48, Running Loss: 35.190729119218304\n","Epoch: 49, Running Loss: 29.990235486082383\n","Epoch: 50, Running Loss: 28.268419174230075\n","Epoch: 51, Running Loss: 43.801980184041895\n","Epoch: 52, Running Loss: 35.6525163500628\n","Epoch: 53, Running Loss: 22.540003390153288\n","Epoch: 54, Running Loss: 46.59006581350695\n","Epoch: 55, Running Loss: 23.601717929603183\n","Epoch: 56, Running Loss: 30.245835210283985\n","Epoch: 57, Running Loss: 23.64109641672985\n","Epoch: 58, Running Loss: 30.05681221759005\n","Epoch: 59, Running Loss: 46.610881508029706\n","Epoch: 60, Running Loss: 23.597093419142766\n","Epoch: 61, Running Loss: 23.266246709405095\n","Epoch: 62, Running Loss: 28.6199627834867\n","Epoch: 63, Running Loss: 38.78960115764494\n","Epoch: 64, Running Loss: 23.364693981347955\n","Epoch: 65, Running Loss: 27.350523668297683\n","Epoch: 66, Running Loss: 24.779942177745397\n","Epoch: 67, Running Loss: 23.046610012293968\n","Epoch: 68, Running Loss: 25.86519485374447\n","Epoch: 69, Running Loss: 36.802606267723604\n","Epoch: 70, Running Loss: 19.126259728385776\n","Epoch: 71, Running Loss: 17.52263983402372\n","Epoch: 72, Running Loss: 25.503657824898255\n","Epoch: 73, Running Loss: 25.25951036278275\n","Epoch: 74, Running Loss: 20.640320109960157\n","Epoch: 75, Running Loss: 23.033968675721553\n","Epoch: 76, Running Loss: 22.287741442371043\n","Epoch: 77, Running Loss: 25.60211796857766\n","Epoch: 78, Running Loss: 680.1915626443079\n","Epoch: 79, Running Loss: 2091.759936109229\n","Epoch: 80, Running Loss: 41.92489731693058\n","Epoch: 81, Running Loss: 36.577794455894036\n","Epoch: 82, Running Loss: 16.61127889263298\n","Epoch: 83, Running Loss: 49.21812473885802\n","Epoch: 84, Running Loss: 15.001871909553302\n","Epoch: 85, Running Loss: 65.54050886826008\n","Epoch: 86, Running Loss: 13.540123681348632\n","Epoch: 87, Running Loss: 24.515257437247783\n","Epoch: 88, Running Loss: 15.494305408268701\n","Epoch: 89, Running Loss: 19.61887780172401\n","Epoch: 90, Running Loss: 21.142458926333347\n","Epoch: 91, Running Loss: 14.705089589071576\n","Epoch: 92, Running Loss: 17.907054981384135\n","Epoch: 93, Running Loss: 27.280531276468537\n","Epoch: 94, Running Loss: 15.927603564981837\n","Epoch: 95, Running Loss: 29.262725087581202\n","Epoch: 96, Running Loss: 20.66467722741072\n","Epoch: 97, Running Loss: 16.12872642610455\n","Epoch: 98, Running Loss: 16.01868372822355\n","Epoch: 99, Running Loss: 21.793567344589974\n","END OF PRETRAINING!\n","Training begins now.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2c2604539306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcopy_scripts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaint_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-2c2604539306>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaint_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaint_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaint_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaint_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_tuning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msub_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaint_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-ec51f119f2d1>\u001b[0m in \u001b[0;36msaint_training\u001b[0;34m(config, X, y, cat_dims, cat_idxs, con_idxs, param_tuning)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_reps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0my_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlpfory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1165\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (0)."]}]},{"cell_type":"markdown","source":["# Parameter tuning"],"metadata":{"id":"E2E_Wb5IGQDz"}},{"cell_type":"markdown","source":["# Debug"],"metadata":{"id":"sQbfUtLQifRO"}},{"cell_type":"code","source":[],"metadata":{"id":"Y-ZQlfOsgoej","executionInfo":{"status":"aborted","timestamp":1663100249935,"user_tz":-540,"elapsed":2,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":null,"outputs":[]}]}