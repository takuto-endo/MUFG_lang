{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMxeV2aMp0twKNO7md4ID1V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# import"],"metadata":{"id":"KJKYeVTmF-sQ"}},{"cell_type":"code","source":["# 長めのpretrain\n","# dropout"],"metadata":{"id":"itybQGmf3bZQ","executionInfo":{"status":"ok","timestamp":1662714282468,"user_tz":-540,"elapsed":35,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5176531e","executionInfo":{"status":"ok","timestamp":1662714282471,"user_tz":-540,"elapsed":31,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["# tabularとNLP 両方, それこそマルチモーダルにするか???\n","# SAINT + DeBERTa → 情報抽出 → 数層のMLP\n","\n","# 順番的には\n","# 1. html contentを無視した lightgbm baseline\n","# 3. SAINTの実装\n","# 4. DeBERTa等, 自然言語モデルの実装\n","# 5. 3-4よりMultimodal化"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","%cd /content/drive/MyDrive/_MUFG_student"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJChsaHZFhXI","executionInfo":{"status":"ok","timestamp":1662714421486,"user_tz":-540,"elapsed":139045,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"fc7a72a0-8104-4f11-b63b-60de5a8b8f50"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/_MUFG_student\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install einops"],"metadata":{"id":"LOB4ymqhC6K0","executionInfo":{"status":"ok","timestamp":1662714425943,"user_tz":-540,"elapsed":4464,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"839f06e9","executionInfo":{"status":"ok","timestamp":1662714432265,"user_tz":-540,"elapsed":6330,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["# base\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import glob\n","import shutil\n","\n","# others\n","import os\n","import warnings\n","warnings.simplefilter('ignore')\n","\n","# main\n","\n","import sys\n","ROOT_PATH = '/content/drive/My Drive/_MUFG_student'\n","sys.path.append(ROOT_PATH)\n","ROOT_PATH = '/content/drive/My Drive/_MUFG_student/saint'\n","sys.path.append(ROOT_PATH)\n","ROOT_PATH = '/content/drive/My Drive/_MUFG_student/saint/models'\n","sys.path.append(ROOT_PATH)\n","\n","import torch\n","from torch import nn\n","import argparse\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","from saint.utils import count_parameters, classification_scores, mean_sq_error\n","from saint.augmentations import embed_data_mask\n","from saint.augmentations import add_noise\n","from saint.models import SAINT\n","from saint.pretraining import SAINT_pretrain\n","import re\n","import gc\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWByfiO89--E","executionInfo":{"status":"ok","timestamp":1662714432717,"user_tz":-540,"elapsed":457,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"1ca68ba9-576b-4b6a-c51c-ba011b46fa0b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["data  figure  outputs  saint  src\n"]}]},{"cell_type":"markdown","source":["# configration"],"metadata":{"id":"wdZHg7wrGDsM"}},{"cell_type":"code","source":["class SAINT_Config:\n","\n","    # private\n","    _exp_num = '002'\n","\n","    # 学習param\n","    seed = 0\n","    num_fold = 5\n","    model_name = \"saint\"\n","    drop_columns = ['id', 'html_content', 'goal']\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # saint param\n","    task = 'binary'\n","    dtask = 'clf'\n","    cont_embeddings = 'MLP'\n","    embedding_size = 32\n","    transformer_depth = 4# 6\n","    attention_heads = 8\n","    attention_dropout = 0.3# 0.1\n","    ff_dropout = 0.3# 0.1\n","    attentiontype = 'colrow'\n","    optimizer = 'AdamW'\n","    scheduler = 'cosine'\n","\n","    lr = 0.0001\n","    epochs = 60# 100\n","    eval_epoch = 1\n","    batchsize = 256\n","    set_seed = seed# saint用\n","    dset_seed = seed# saint用\n","\n","    vision_dset = False\n","    dset_id = None\n","    active_log = False\n","    pretrain = True\n","    pretrain_epochs = 100\n","\n","    pt_tasks = ['contrastive','denoising']\n","    pt_aug = []# ['mixup','cutmix']\n","    pt_aug_lam = 0.1\n","    mixup_lam = 0.3\n","    train_mask_prob = 0# 0\n","    mask_prob = 0\n","    ssl_avail_y = 0\n","    pt_projhead_style = 'diff'\n","    nce_temp = 0.7\n","    lam0 = 0.5\n","    lam1 = 10\n","    lam2 = 1\n","    lam3 = 10\n","    final_mlp_style = 'sep'\n","\n","    # 保存先\n","    save_folder_name = f'Exp{_exp_num}_{model_name}'\n","    run_name = save_folder_name# saint用\n","    \n","def set_seed(seed=0):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","def setup(config):\n","    print(\"### Configration Setup...\")\n","\n","    set_seed(config.seed)\n","    config.train_path = './data/train.csv'\n","    config.test_path = './data/test.csv'\n","\n","    config.output_path = './outputs'\n","    config.experiment_path = os.path.join(config.output_path, config.save_folder_name)\n","    print(f'    experiment_path  >> {config.experiment_path}')\n","    config.model_save_path = os.path.join(config.experiment_path, 'model')\n","    config.modelsave_path = os.path.join(config.experiment_path, 'model')# saint用\n","\n","    print(f'    model_save_path >> {config.model_save_path}')\n","    config.figure_save_path = os.path.join(config.experiment_path, 'figure')\n","    print(f'    figure_save_path >> {config.figure_save_path}')\n","    config.preds_save_path = os.path.join(config.experiment_path, 'preds')\n","    print(f'    preds_save_path >> {config.preds_save_path}')\n","    \n","    for d in [config.output_path, config.experiment_path, config.model_save_path, config.figure_save_path, config.preds_save_path]:\n","        os.makedirs(d, exist_ok=True)\n","\n","    print(\"### Setup Complete. \\n\")\n","    return config"],"metadata":{"id":"RUVB8nb_G9mQ","executionInfo":{"status":"ok","timestamp":1662714432718,"user_tz":-540,"elapsed":17,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"f_eWqcaAaV_5"}},{"cell_type":"code","source":["# 前処理系\n","# Train Test 共通の処理関数\n","def goal_split(x):\n","    x = x.split('-')\n","    x = re.sub('[^0-9]', '',  x[0])\n","    return int(x)\n","\n","def singular_mask(df, column, threshold):\n","    counts = df[column].value_counts()\n","    res_bool = df[column].isin(counts[counts<threshold].index)\n","    df.loc[res_bool, column] = 'unknown'\n","    return df\n","\n","def test_cat_mask(df, column, unique_list):\n","    def cat_mask(x):\n","        if x not in unique_list[column]:\n","            x = 'unknown'\n","        return x\n","    df.loc[:,column] = df[column].map(cat_mask)\n","    return df\n","# ======================\n","\n","\n","def get_train_data(config):\n","\n","    train_df = pd.read_csv(config.train_path)\n","    \n","    # 前処理\n","    train_df['goal_min'] = train_df['goal'].map(goal_split)\n","    # 数によってunknownにするカテゴリ変数の設定\n","    unique_cat_list = {}\n","    threshold = 10\n","    train_df = singular_mask(train_df, 'category2', threshold)\n","    counts = train_df['category2'].value_counts()\n","    unique_cat_list['category2'] = counts[counts>threshold].index.values # save\n","    # print(unique_cat_list)\n","    config.unique_cat_list = unique_cat_list\n","\n","    if len(config.drop_columns) > 0:# 余計な列のdrop\n","        train_df = train_df.drop(config.drop_columns, axis=1)\n","    \n","    # label encoding + categoriesの登録\n","    config.categories = train_df.columns[train_df.dtypes==\"object\"].values\n","    cat_dims = []\n","    if len(config.categories)>0:\n","        label_encoders = {}\n","        for c in config.categories:\n","            print(c)\n","            encoder = LabelEncoder()\n","            train_df[c] = encoder.fit_transform(train_df[c])\n","            label_encoders[c] = encoder\n","            cat_dims.append(len(encoder.classes_))\n","        config.label_encoders = label_encoders\n","\n","    X = train_df.drop('state', axis=1)\n","    y = train_df['state']\n","    categories = list(config.categories)\n","    continuous = list(set(X.columns.tolist()) - set(categories))\n","    cat_idxs = [ i for i, c in enumerate(X.columns) if c in categories]\n","    con_idxs = list(set(range(len(X.columns))) - set(cat_idxs))\n","    cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int)\n","\n","    config.cat_dims = cat_dims\n","    config.con_idxs = con_idxs\n","    config.cat_idxs = cat_idxs\n","\n","    return X, y, cat_dims, cat_idxs, con_idxs\n","    # return cat_dims, cat_idxs, con_idxs, train_df\n","    # train_df >> X_train, y_train, X_valid, y_valid, train_mean, train_std\n","\n","def get_test_data(config):\n","    test_df = pd.read_csv(config.test_path)\n","\n","    # 前処理\n","    test_df['goal_min'] = test_df['goal'].map(goal_split)\n","    test_df = test_cat_mask(test_df, 'category2', config.unique_cat_list)\n","\n","    if len(config.drop_columns) > 0:\n","        test_df = test_df.drop(config.drop_columns, axis=1)\n","    \n","    # label encoding\n","    if len(config.categories)>0:\n","        for c in config.categories:\n","            print(c)\n","            test_df[c] = config.label_encoders[c].transform(test_df[c])\n","\n","    return test_df"],"metadata":{"id":"a0dhZALSabVl","executionInfo":{"status":"ok","timestamp":1662714432718,"user_tz":-540,"elapsed":15,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class DataSetCatCon(Dataset):\n","    def __init__(self, X, Y, cat_cols, task='clf', continuous_mean_std=None):\n","\n","        cat_cols = list(cat_cols)\n","\n","        temp = X.fillna(\"MissingValue\")\n","        X_mask = temp.ne(\"MissingValue\").astype(int)\n","\n","        con_cols = list(set(np.arange(X.shape[1])) - set(cat_cols))\n","        self.X1 = X.iloc[:,cat_cols].copy().astype(np.int64) #categorical columns\n","        self.X2 = X.iloc[:,con_cols].copy().astype(np.float32) #numerical columns\n","        self.X1_mask = X_mask.iloc[:,cat_cols].copy().astype(np.int64) #categorical columns\n","        self.X2_mask = X_mask.iloc[:,con_cols].copy().astype(np.int64) #numerical columns\n","        self.y = Y\n","        self.cls = np.expand_dims(np.zeros_like(self.y,dtype=int), -1)\n","        self.cls_mask = np.expand_dims(np.ones_like(self.y,dtype=int), -1)\n","        if continuous_mean_std is not None:\n","            mean, std = continuous_mean_std\n","            self.X2 = (self.X2 - mean) / std\n","\n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        # X1 has categorical data, X2 has continuous\n","        return np.concatenate((self.cls[idx], self.X1.iloc[idx])), np.array(self.X2.iloc[idx]), np.array(self.y.iloc[idx]), np.concatenate((self.cls_mask[idx], self.X1_mask.iloc[idx])), np.array(self.X2_mask.iloc[idx])\n"],"metadata":{"id":"uy0Rv1tlNjIY","executionInfo":{"status":"ok","timestamp":1662714432719,"user_tz":-540,"elapsed":15,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train\n","from sklearn.metrics import f1_score\n","def f1_metric(preds, train_data):\n","    labels = train_data.get_label()\n","    preds = np.round(preds)\n","    return 'f1', f1_score(labels, preds), True\n","\n","def saint_training(config, X, y, cat_dims, cat_idxs, con_idxs, param_tuning=False):\n","\n","    folds = StratifiedKFold(n_splits=config.num_fold)\n","    splits = folds.split(np.zeros(len(X)), y)\n","\n","    oof_pred = np.zeros((len(X), 2), dtype=np.float32)\n","    fold_num = np.zeros(len(X), dtype=np.int32)\n","\n","    for fold, (train_index, valid_index) in enumerate(splits):\n","\n","        print(f'\\nStart fold {fold} =====================================')\n","        X_train = X.iloc[train_index].reset_index(drop=True)\n","        y_train = y.iloc[train_index].reset_index(drop=True)\n","        train_mean, train_std = np.array(X_train.iloc[:,con_idxs],dtype=np.float32).mean(0), np.array(X_train.iloc[:,con_idxs],dtype=np.float32).std(0)\n","        train_std = np.where(train_std < 1e-6, 1e-6, train_std)\n","        continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32) \n","        np.save(os.path.join(config.model_save_path, f'cms{fold}.npy'), continuous_mean_std)\n","        print(f'continuous_mean_std: \\n{continuous_mean_std}\\n')# saveする?\n","        X_valid = X.iloc[valid_index].reset_index(drop=True)\n","        y_valid = y.iloc[valid_index].reset_index(drop=True)\n","\n","        print(f'X_train shape: {X_train.shape}')\n","        print(f'y_train shape: {y_train.shape}')\n","        print(f'X_valid shape: {X_valid.shape}')\n","        print(f'y_valid shape: {y_valid.shape}')\n","\n","        # Dataset + Dataloader\n","        train_ds = DataSetCatCon(X_train, y_train, cat_idxs, task=config.dtask, continuous_mean_std=continuous_mean_std)\n","        trainloader = DataLoader(train_ds, batch_size=config.batchsize, shuffle=True, num_workers=os.cpu_count())\n","        valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs, task=config.dtask, continuous_mean_std=continuous_mean_std)\n","        validloader = DataLoader(valid_ds, batch_size=config.batchsize, shuffle=False, num_workers=os.cpu_count())\n","\n","        # define model\n","        model = SAINT(\n","            categories = tuple(cat_dims), \n","            num_continuous = len(con_idxs),                \n","            dim = config.embedding_size,                           \n","            dim_out = 1,                       \n","            depth = config.transformer_depth,                       \n","            heads = config.attention_heads,                         \n","            attn_dropout = config.attention_dropout,             \n","            ff_dropout = config.ff_dropout,                  \n","            mlp_hidden_mults = (4, 2),       \n","            cont_embeddings = config.cont_embeddings,\n","            attentiontype = config.attentiontype,\n","            final_mlp_style = config.final_mlp_style,\n","            y_dim = 2\n","        )\n","        criterion = nn.CrossEntropyLoss().to(config.device)\n","        model.to(config.device)\n","        optimizer = optim.AdamW(model.parameters(),lr=config.lr)\n","\n","        # pretraining\n","        model = SAINT_pretrain(model, cat_idxs, X_train, y_train, continuous_mean_std, config, config.device)\n","\n","        # training\n","        best_valid_auroc = 0\n","        best_valid_accuracy = 0\n","        best_valid_f1 = 0.0\n","        best_valid_preds = None\n","        best_epoch = 0\n","        print('Training begins now.')\n","        for epoch in range(config.epochs):\n","            model.train()\n","            running_loss = 0.0\n","            for i, data in enumerate(trainloader, 0):\n","                optimizer.zero_grad()\n","                x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(config.device), data[1].to(config.device),data[2].to(config.device),data[3].to(config.device),data[4].to(config.device)\n","\n","                _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model, config. vision_dset)   \n","                reps = model.transformer(x_categ_enc, x_cont_enc)\n","                y_reps = reps[:,0,:]\n","                y_outs = model.mlpfory(y_reps)\n","                loss = criterion(y_outs, y_gts.squeeze())\n","                loss.backward()\n","                optimizer.step()\n","                running_loss += loss.item()\n","            print(f'epoch{epoch+1}: running_loss={running_loss}')\n","            if epoch%config.eval_epoch==0:\n","                model.eval()\n","                with torch.no_grad():\n","                    train_accuracy, train_auroc, train_f1, _ = classification_scores(model, trainloader, config.device, 'binary', config.vision_dset)\n","                    print(f'[EPOCH {epoch+1}] TRAIN F1: {train_f1} TRAIN ACCURACY: {train_accuracy:.3f}, TRAIN AUROC: {train_auroc:.3f}')\n","                    \n","                    valid_accuracy, valid_auroc, valid_f1, valid_pred = classification_scores(model, validloader, config.device, 'binary', config.vision_dset)\n","                    print(f'[EPOCH {epoch+1}] VALID F1: {valid_f1} VALID ACCURACY: {valid_accuracy:.3f}, VALID AUROC: {valid_auroc:.3f}')\n","                    if valid_f1 > best_valid_f1:\n","                        best_valid_accuracy = valid_accuracy\n","                        best_valid_auroc = valid_auroc\n","                        best_valid_f1 = valid_f1   \n","                        best_valid_preds = valid_pred\n","                        best_epoch = epoch\n","                        torch.save(model.state_dict(),f'{config.modelsave_path}/bestmodel{fold}.pth')\n","                model.train()\n","\n","        print(f'F1 on best model: {best_valid_f1:.6f} (Epoch{best_epoch})')\n","\n","        print(best_valid_preds.shape)\n","        oof_pred[valid_index] = best_valid_preds.astype(np.float32)\n","        fold_num[valid_index] = fold+1\n","        del model; gc.collect()\n","        \n","    pred = np.argmax(oof_pred, axis=1)# torch.argmax(m(y_outs), dim=1).float()\n","    cv_score = f1_score(y, pred)\n","    print(f'\\nFinal CV = {cv_score:.5f}')\n","\n","    return cv_score, oof_pred\n","\n","# util 入れ替え"],"metadata":{"id":"ledQcK-Ej1h0","executionInfo":{"status":"ok","timestamp":1662714432980,"user_tz":-540,"elapsed":275,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def inferring(config, X_test):\n","    config.model_weights = [p for p in sorted(glob.glob(os.path.join(config.model_save_path, 'bestmodel*.pth')))]\n","    sub_pred = np.zeros((len(X_test),2), dtype=np.float32)\n","    print(sub_pred.shape)\n","    dummy_y = pd.Series([i for i in range(len(X_test))])\n","    for fold, model_weight in enumerate(config.model_weights):\n","\n","        continuous_mean_std = np.load(os.path.join(config.model_save_path, f'cms{fold}.npy'))\n","        test_ds = DataSetCatCon(X_test, dummy_y, config.cat_idxs, task=config.dtask, continuous_mean_std=continuous_mean_std)\n","        testloader = DataLoader(test_ds, batch_size=config.batchsize, shuffle=False, num_workers=os.cpu_count())\n","\n","        model = SAINT(\n","            categories = tuple(config.cat_dims), \n","            num_continuous = len(config.con_idxs),                \n","            dim = config.embedding_size,                           \n","            dim_out = 1,                       \n","            depth = config.transformer_depth,                       \n","            heads = config.attention_heads,                         \n","            attn_dropout = config.attention_dropout,             \n","            ff_dropout = config.ff_dropout,                  \n","            mlp_hidden_mults = (4, 2),       \n","            cont_embeddings = config.cont_embeddings,\n","            attentiontype = config.attentiontype,\n","            final_mlp_style = config.final_mlp_style,\n","            y_dim = 2\n","        )\n","        model.load_state_dict(torch.load(model_weight))\n","        model.to(config.device)\n","\n","        model.eval()\n","        y_pred = torch.empty(0).to(config.device)\n","        y_out = torch.empty(0).to(config.device)\n","        with torch.no_grad():\n","            for i, data in enumerate(testloader, 0):\n","                x_categ, x_cont, _, cat_mask, con_mask = data[0].to(config.device), data[1].to(config.device),data[2].to(config.device),data[3].to(config.device),data[4].to(config.device)\n","                _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model, config.vision_dset)           \n","                reps = model.transformer(x_categ_enc, x_cont_enc)\n","                y_reps = reps[:,0,:]\n","                y_outs = model.mlpfory(y_reps)\n","                # import ipdb; ipdb.set_trace() \n","                y_out = torch.cat([y_out,y_outs.float()],dim=0) \n","                y_pred = torch.cat([y_pred,torch.argmax(y_outs, dim=1).float()],dim=0)\n","\n","        sub_pred += y_out.detach().cpu().numpy() / len(config.model_weights)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(config.preds_save_path, 'sub_pred.npy'), sub_pred)\n","    return sub_pred# 返すのはprobability"],"metadata":{"id":"jVzzf5KOTW6c","executionInfo":{"status":"ok","timestamp":1662714432981,"user_tz":-540,"elapsed":8,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def copy_scripts(config):\n","    scripts_save_path = os.path.join(config.experiment_path, 'scripts')\n","    os.makedirs(scripts_save_path, exist_ok=True)\n","    for script in glob.glob('./src/*.ipynb'):\n","        dst_file = os.path.join(scripts_save_path, script.split('/')[-1])\n","        print(f'[save file] {dst_file}')\n","        shutil.copyfile(script, dst_file)"],"metadata":{"id":"V_8u1wFoTdRk","executionInfo":{"status":"ok","timestamp":1662714432981,"user_tz":-540,"elapsed":7,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def main():\n","    \n","    saint_config = setup(SAINT_Config())\n","    train_path = './data/train.csv'\n","    test_path = './data/test.csv'\n","    submit_path = './data/sample_submit.csv'\n","\n","    X, y, cat_dims, cat_idxs, con_idxs = get_train_data(saint_config)\n","    X_test = get_test_data(saint_config)\n","    score, oof_pred = saint_training(saint_config, X, y, cat_dims, cat_idxs, con_idxs, param_tuning=False)\n","\n","    sub_pred = inferring(saint_config, X_test)\n","    sub = pd.read_csv(submit_path, header=None)\n","    sub[1] = np.argmax(sub_pred, axis=1).astype(int)\n","\n","    def fix_leak(sub, train_path, test_path):\n","        print(\"===== fix_leak =====\")\n","        train_df = pd.read_csv(train_path)\n","        test_df = pd.read_csv(test_path)\n","        duplicated = pd.merge(test_df, train_df[['goal', 'country', 'duration', 'category1', 'category2', 'html_content', 'state']], on=['goal', 'country', 'duration', 'category1', 'category2', 'html_content'], how=\"left\")\n","        duplicated = duplicated[~duplicated[\"state\"].isnull()]\n","        for i in duplicated.index:\n","            print(f'Fix index{i}: {sub.loc[i,1]}')\n","            sub.loc[i, 1] = int(duplicated.loc[i, \"state\"])\n","            print(f'To {sub.loc[i,1]}')\n","        return sub\n","    sub = fix_leak(sub, train_path, test_path)\n","\n","    # 提出用ファイル\n","    sub.to_csv(os.path.join(saint_config.preds_save_path, f'Exp{saint_config._exp_num}_CV{int(score*(10**10))}_submission.csv'), index=False, header=False)\n","\n","    # scriptの保存\n","    copy_scripts(saint_config)\n","\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_c0Ys4IsfH9n","outputId":"9ef1bc82-3916-455b-85d5-f49eff0689da","executionInfo":{"status":"ok","timestamp":1662720720466,"user_tz":-540,"elapsed":6287491,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["### Configration Setup...\n","    experiment_path  >> ./outputs/Exp002_saint\n","    model_save_path >> ./outputs/Exp002_saint/model\n","    figure_save_path >> ./outputs/Exp002_saint/figure\n","    preds_save_path >> ./outputs/Exp002_saint/preds\n","### Setup Complete. \n","\n","country\n","category1\n","category2\n","country\n","category1\n","category2\n","\n","Start fold 0 =====================================\n","continuous_mean_std: \n","[[3.26407051e+01 1.19044473e+04]\n"," [1.21512165e+01 2.16121484e+04]]\n","\n","X_train shape: (7832, 5)\n","y_train shape: (7832,)\n","X_valid shape: (1959, 5)\n","y_valid shape: (1959,)\n","Pretraining begins!\n","Epoch: 0, Running Loss: 528.1503095626831\n","Epoch: 1, Running Loss: 359.9274082183838\n","Epoch: 2, Running Loss: 286.46651792526245\n","Epoch: 3, Running Loss: 228.17384910583496\n","Epoch: 4, Running Loss: 175.41336059570312\n","Epoch: 5, Running Loss: 130.2620143890381\n","Epoch: 6, Running Loss: 94.89448666572571\n","Epoch: 7, Running Loss: 67.66338062286377\n","Epoch: 8, Running Loss: 47.98837959766388\n","Epoch: 9, Running Loss: 35.0691539645195\n","Epoch: 10, Running Loss: 27.50474125146866\n","Epoch: 11, Running Loss: 22.17446205019951\n","Epoch: 12, Running Loss: 18.038609504699707\n","Epoch: 13, Running Loss: 15.23833018541336\n","Epoch: 14, Running Loss: 13.487022906541824\n","Epoch: 15, Running Loss: 11.840557992458344\n","Epoch: 16, Running Loss: 10.583249181509018\n","Epoch: 17, Running Loss: 9.773352265357971\n","Epoch: 18, Running Loss: 8.822931677103043\n","Epoch: 19, Running Loss: 8.140515565872192\n","Epoch: 20, Running Loss: 7.607268288731575\n","Epoch: 21, Running Loss: 7.197546139359474\n","Epoch: 22, Running Loss: 7.0614971071481705\n","Epoch: 23, Running Loss: 6.381888777017593\n","Epoch: 24, Running Loss: 5.893120259046555\n","Epoch: 25, Running Loss: 5.851341173052788\n","Epoch: 26, Running Loss: 5.332881882786751\n","Epoch: 27, Running Loss: 5.239160642027855\n","Epoch: 28, Running Loss: 4.973292648792267\n","Epoch: 29, Running Loss: 4.6959545612335205\n","Epoch: 30, Running Loss: 4.486354656517506\n","Epoch: 31, Running Loss: 4.342729099094868\n","Epoch: 32, Running Loss: 4.203014604747295\n","Epoch: 33, Running Loss: 4.0425480008125305\n","Epoch: 34, Running Loss: 3.8114104494452477\n","Epoch: 35, Running Loss: 3.846645876765251\n","Epoch: 36, Running Loss: 3.693804331123829\n","Epoch: 37, Running Loss: 3.562257841229439\n","Epoch: 38, Running Loss: 3.3927414417266846\n","Epoch: 39, Running Loss: 3.38183431327343\n","Epoch: 40, Running Loss: 3.2938262298703194\n","Epoch: 41, Running Loss: 3.2993416637182236\n","Epoch: 42, Running Loss: 3.0084268301725388\n","Epoch: 43, Running Loss: 3.0344184562563896\n","Epoch: 44, Running Loss: 2.950142629444599\n","Epoch: 45, Running Loss: 2.9867366030812263\n","Epoch: 46, Running Loss: 2.9597508311271667\n","Epoch: 47, Running Loss: 2.8053874373435974\n","Epoch: 48, Running Loss: 2.7362531013786793\n","Epoch: 49, Running Loss: 2.6690001860260963\n","Epoch: 50, Running Loss: 2.5129244551062584\n","Epoch: 51, Running Loss: 2.504128135740757\n","Epoch: 52, Running Loss: 2.466649178415537\n","Epoch: 53, Running Loss: 2.4364447817206383\n","Epoch: 54, Running Loss: 2.3082455545663834\n","Epoch: 55, Running Loss: 2.4089406691491604\n","Epoch: 56, Running Loss: 2.3788755536079407\n","Epoch: 57, Running Loss: 2.259755153208971\n","Epoch: 58, Running Loss: 2.2065187357366085\n","Epoch: 59, Running Loss: 2.2656265757977962\n","Epoch: 60, Running Loss: 2.17616218701005\n","Epoch: 61, Running Loss: 2.233775045722723\n","Epoch: 62, Running Loss: 2.1227267384529114\n","Epoch: 63, Running Loss: 2.016721338033676\n","Epoch: 64, Running Loss: 2.0755968131124973\n","Epoch: 65, Running Loss: 2.060213405638933\n","Epoch: 66, Running Loss: 1.992506518959999\n","Epoch: 67, Running Loss: 1.9081746600568295\n","Epoch: 68, Running Loss: 1.930993739515543\n","Epoch: 69, Running Loss: 1.7610550671815872\n","Epoch: 70, Running Loss: 1.8839824832975864\n","Epoch: 71, Running Loss: 1.700421929359436\n","Epoch: 72, Running Loss: 1.873496051877737\n","Epoch: 73, Running Loss: 1.8527614921331406\n","Epoch: 74, Running Loss: 1.7527698054909706\n","Epoch: 75, Running Loss: 1.8644949868321419\n","Epoch: 76, Running Loss: 1.7844443619251251\n","Epoch: 77, Running Loss: 1.7036399208009243\n","Epoch: 78, Running Loss: 1.6902902200818062\n","Epoch: 79, Running Loss: 1.7346100211143494\n","Epoch: 80, Running Loss: 1.6133813224732876\n","Epoch: 81, Running Loss: 1.6977243050932884\n","Epoch: 82, Running Loss: 1.5768316201865673\n","Epoch: 83, Running Loss: 1.63176691532135\n","Epoch: 84, Running Loss: 1.643893588334322\n","Epoch: 85, Running Loss: 1.5199132487177849\n","Epoch: 86, Running Loss: 1.474622543901205\n","Epoch: 87, Running Loss: 1.6859447564929724\n","Epoch: 88, Running Loss: 1.4826692417263985\n","Epoch: 89, Running Loss: 1.491614069789648\n","Epoch: 90, Running Loss: 1.363463506102562\n","Epoch: 91, Running Loss: 1.5093250758945942\n","Epoch: 92, Running Loss: 1.4270069971680641\n","Epoch: 93, Running Loss: 1.3364126551896334\n","Epoch: 94, Running Loss: 1.3825258892029524\n","Epoch: 95, Running Loss: 1.3903410360217094\n","Epoch: 96, Running Loss: 1.301028087735176\n","Epoch: 97, Running Loss: 1.3134480006992817\n","Epoch: 98, Running Loss: 1.3234273754060268\n","Epoch: 99, Running Loss: 1.3193752896040678\n","END OF PRETRAINING!\n","Training begins now.\n","epoch1: running_loss=20.53057026863098\n","[EPOCH 1] TRAIN F1: 0.693195479682616 TRAIN ACCURACY: 67.416, TRAIN AUROC: 0.737\n","[EPOCH 1] VALID F1: 0.6933333333333334 VALID ACCURACY: 67.126, VALID AUROC: 0.747\n","epoch2: running_loss=18.117008805274963\n","[EPOCH 2] TRAIN F1: 0.68974395651552 TRAIN ACCURACY: 72.306, TRAIN AUROC: 0.805\n","[EPOCH 2] VALID F1: 0.682842287694974 VALID ACCURACY: 71.976, VALID AUROC: 0.795\n","epoch3: running_loss=16.481042832136154\n","[EPOCH 3] TRAIN F1: 0.7509218054672601 TRAIN ACCURACY: 74.987, TRAIN AUROC: 0.840\n","[EPOCH 3] VALID F1: 0.729038854805726 VALID ACCURACY: 72.945, VALID AUROC: 0.819\n","epoch4: running_loss=15.43463933467865\n","[EPOCH 4] TRAIN F1: 0.74622030237581 TRAIN ACCURACY: 75.996, TRAIN AUROC: 0.852\n","[EPOCH 4] VALID F1: 0.7301414581066378 VALID ACCURACY: 74.681, VALID AUROC: 0.833\n","epoch5: running_loss=14.902606397867203\n","[EPOCH 5] TRAIN F1: 0.7583125246418716 TRAIN ACCURACY: 76.519, TRAIN AUROC: 0.861\n","[EPOCH 5] VALID F1: 0.7273684210526316 VALID ACCURACY: 73.558, VALID AUROC: 0.828\n","epoch6: running_loss=14.463798254728317\n","[EPOCH 6] TRAIN F1: 0.7607800054929964 TRAIN ACCURACY: 77.758, TRAIN AUROC: 0.868\n","[EPOCH 6] VALID F1: 0.725565985643291 VALID ACCURACY: 74.630, VALID AUROC: 0.829\n","epoch7: running_loss=14.411312729120255\n","[EPOCH 7] TRAIN F1: 0.7545263157894736 TRAIN ACCURACY: 77.669, TRAIN AUROC: 0.870\n","[EPOCH 7] VALID F1: 0.7087323943661972 VALID ACCURACY: 73.609, VALID AUROC: 0.828\n","epoch8: running_loss=13.9337697327137\n","[EPOCH 8] TRAIN F1: 0.7670542092730074 TRAIN ACCURACY: 78.767, TRAIN AUROC: 0.880\n","[EPOCH 8] VALID F1: 0.7186440677966102 VALID ACCURACY: 74.579, VALID AUROC: 0.828\n","epoch9: running_loss=13.720248281955719\n","[EPOCH 9] TRAIN F1: 0.7822102425876011 TRAIN ACCURACY: 79.367, TRAIN AUROC: 0.884\n","[EPOCH 9] VALID F1: 0.7257019438444924 VALID ACCURACY: 74.068, VALID AUROC: 0.827\n","epoch10: running_loss=13.483736485242844\n","[EPOCH 10] TRAIN F1: 0.787043233837505 TRAIN ACCURACY: 79.686, TRAIN AUROC: 0.888\n","[EPOCH 10] VALID F1: 0.7334754797441365 VALID ACCURACY: 74.477, VALID AUROC: 0.830\n","epoch11: running_loss=13.239507883787155\n","[EPOCH 11] TRAIN F1: 0.7757859900717043 TRAIN ACCURACY: 79.239, TRAIN AUROC: 0.889\n","[EPOCH 11] VALID F1: 0.7087486157253599 VALID ACCURACY: 73.150, VALID AUROC: 0.820\n","epoch12: running_loss=13.181416511535645\n","[EPOCH 12] TRAIN F1: 0.7855678556785568 TRAIN ACCURACY: 79.967, TRAIN AUROC: 0.894\n","[EPOCH 12] VALID F1: 0.7209175314036046 VALID ACCURACY: 73.915, VALID AUROC: 0.825\n","epoch13: running_loss=12.893148362636566\n","[EPOCH 13] TRAIN F1: 0.7752857762986543 TRAIN ACCURACY: 80.171, TRAIN AUROC: 0.899\n","[EPOCH 13] VALID F1: 0.7010428736964078 VALID ACCURACY: 73.660, VALID AUROC: 0.823\n","epoch14: running_loss=12.678408443927765\n","[EPOCH 14] TRAIN F1: 0.7983794733288319 TRAIN ACCURACY: 80.937, TRAIN AUROC: 0.900\n","[EPOCH 14] VALID F1: 0.7233814874264312 VALID ACCURACY: 73.609, VALID AUROC: 0.827\n","epoch15: running_loss=12.545654714107513\n","[EPOCH 15] TRAIN F1: 0.7788279773156899 TRAIN ACCURACY: 80.580, TRAIN AUROC: 0.906\n","[EPOCH 15] VALID F1: 0.6933333333333334 VALID ACCURACY: 72.996, VALID AUROC: 0.819\n","epoch16: running_loss=12.506541430950165\n","[EPOCH 16] TRAIN F1: 0.8071796225419031 TRAIN ACCURACY: 81.346, TRAIN AUROC: 0.908\n","[EPOCH 16] VALID F1: 0.724301528729573 VALID ACCURACY: 73.303, VALID AUROC: 0.823\n","epoch17: running_loss=12.156291723251343\n","[EPOCH 17] TRAIN F1: 0.8139441698944836 TRAIN ACCURACY: 82.214, TRAIN AUROC: 0.914\n","[EPOCH 17] VALID F1: 0.7191854233654877 VALID ACCURACY: 73.252, VALID AUROC: 0.822\n","epoch18: running_loss=12.112764984369278\n","[EPOCH 18] TRAIN F1: 0.8187778651980069 TRAIN ACCURACY: 82.354, TRAIN AUROC: 0.916\n","[EPOCH 18] VALID F1: 0.7248953974895397 VALID ACCURACY: 73.150, VALID AUROC: 0.820\n","epoch19: running_loss=11.818189918994904\n","[EPOCH 19] TRAIN F1: 0.8147738276386775 TRAIN ACCURACY: 82.903, TRAIN AUROC: 0.921\n","[EPOCH 19] VALID F1: 0.7041322314049587 VALID ACCURACY: 72.588, VALID AUROC: 0.814\n","epoch20: running_loss=11.702525585889816\n","[EPOCH 20] TRAIN F1: 0.8173424327579285 TRAIN ACCURACY: 82.572, TRAIN AUROC: 0.920\n","[EPOCH 20] VALID F1: 0.7177848775292864 VALID ACCURACY: 72.945, VALID AUROC: 0.812\n","epoch21: running_loss=11.495414108037949\n","[EPOCH 21] TRAIN F1: 0.819575943459128 TRAIN ACCURACY: 82.725, TRAIN AUROC: 0.923\n","[EPOCH 21] VALID F1: 0.7194860813704497 VALID ACCURACY: 73.252, VALID AUROC: 0.819\n","epoch22: running_loss=11.41511532664299\n","[EPOCH 22] TRAIN F1: 0.8114059853190287 TRAIN ACCURACY: 82.942, TRAIN AUROC: 0.927\n","[EPOCH 22] VALID F1: 0.7015349630471859 VALID ACCURACY: 73.201, VALID AUROC: 0.815\n","epoch23: running_loss=11.188141822814941\n","[EPOCH 23] TRAIN F1: 0.8243502051983584 TRAIN ACCURACY: 83.606, TRAIN AUROC: 0.929\n","[EPOCH 23] VALID F1: 0.7062706270627063 VALID ACCURACY: 72.741, VALID AUROC: 0.813\n","epoch24: running_loss=11.190326005220413\n","[EPOCH 24] TRAIN F1: 0.8358090185676392 TRAIN ACCURACY: 84.193, TRAIN AUROC: 0.933\n","[EPOCH 24] VALID F1: 0.7174603174603175 VALID ACCURACY: 72.741, VALID AUROC: 0.814\n","epoch25: running_loss=11.002783566713333\n","[EPOCH 25] TRAIN F1: 0.826342506011221 TRAIN ACCURACY: 83.401, TRAIN AUROC: 0.929\n","[EPOCH 25] VALID F1: 0.7136 VALID ACCURACY: 72.588, VALID AUROC: 0.811\n","epoch26: running_loss=10.849076896905899\n","[EPOCH 26] TRAIN F1: 0.8389049749934193 TRAIN ACCURACY: 84.372, TRAIN AUROC: 0.936\n","[EPOCH 26] VALID F1: 0.7202505219206681 VALID ACCURACY: 72.639, VALID AUROC: 0.813\n","epoch27: running_loss=10.622380077838898\n","[EPOCH 27] TRAIN F1: 0.8413627894596752 TRAIN ACCURACY: 84.780, TRAIN AUROC: 0.937\n","[EPOCH 27] VALID F1: 0.7167813658020116 VALID ACCURACY: 72.690, VALID AUROC: 0.811\n","epoch28: running_loss=10.48142185807228\n","[EPOCH 28] TRAIN F1: 0.8430141287284144 TRAIN ACCURACY: 84.678, TRAIN AUROC: 0.938\n","[EPOCH 28] VALID F1: 0.7182148417228853 VALID ACCURACY: 72.282, VALID AUROC: 0.807\n","epoch29: running_loss=10.33202001452446\n","[EPOCH 29] TRAIN F1: 0.8411290322580646 TRAIN ACCURACY: 84.908, TRAIN AUROC: 0.941\n","[EPOCH 29] VALID F1: 0.7125201504567438 VALID ACCURACY: 72.690, VALID AUROC: 0.810\n","epoch30: running_loss=10.339076787233353\n","[EPOCH 30] TRAIN F1: 0.8454795237472196 TRAIN ACCURACY: 84.921, TRAIN AUROC: 0.941\n","[EPOCH 30] VALID F1: 0.723404255319149 VALID ACCURACY: 72.792, VALID AUROC: 0.814\n","epoch31: running_loss=10.223431468009949\n","[EPOCH 31] TRAIN F1: 0.8478522681653954 TRAIN ACCURACY: 85.483, TRAIN AUROC: 0.946\n","[EPOCH 31] VALID F1: 0.7100907634810465 VALID ACCURACY: 72.282, VALID AUROC: 0.806\n","epoch32: running_loss=10.146991640329361\n","[EPOCH 32] TRAIN F1: 0.8469108802624385 TRAIN ACCURACY: 85.700, TRAIN AUROC: 0.945\n","[EPOCH 32] VALID F1: 0.6969863013698631 VALID ACCURACY: 71.771, VALID AUROC: 0.806\n","epoch33: running_loss=9.97069376707077\n","[EPOCH 33] TRAIN F1: 0.8520788912579957 TRAIN ACCURACY: 85.827, TRAIN AUROC: 0.948\n","[EPOCH 33] VALID F1: 0.7138331573389652 VALID ACCURACY: 72.333, VALID AUROC: 0.807\n","epoch34: running_loss=9.655290603637695\n","[EPOCH 34] TRAIN F1: 0.8513056419970233 TRAIN ACCURACY: 85.968, TRAIN AUROC: 0.948\n","[EPOCH 34] VALID F1: 0.691304347826087 VALID ACCURACY: 71.006, VALID AUROC: 0.802\n","epoch35: running_loss=9.668027341365814\n","[EPOCH 35] TRAIN F1: 0.8573353091741882 TRAIN ACCURACY: 86.479, TRAIN AUROC: 0.951\n","[EPOCH 35] VALID F1: 0.7108239095315024 VALID ACCURACY: 72.588, VALID AUROC: 0.807\n","epoch36: running_loss=9.646728038787842\n","[EPOCH 36] TRAIN F1: 0.8576724480338939 TRAIN ACCURACY: 86.274, TRAIN AUROC: 0.952\n","[EPOCH 36] VALID F1: 0.7025884838880084 VALID ACCURACY: 71.261, VALID AUROC: 0.801\n","epoch37: running_loss=9.529968500137329\n","[EPOCH 37] TRAIN F1: 0.8627297614391864 TRAIN ACCURACY: 86.555, TRAIN AUROC: 0.951\n","[EPOCH 37] VALID F1: 0.7038183694530444 VALID ACCURACY: 70.699, VALID AUROC: 0.802\n","epoch38: running_loss=9.658118546009064\n","[EPOCH 38] TRAIN F1: 0.8652005174644243 TRAIN ACCURACY: 86.696, TRAIN AUROC: 0.953\n","[EPOCH 38] VALID F1: 0.7137699845281074 VALID ACCURACY: 71.669, VALID AUROC: 0.806\n","epoch39: running_loss=9.356213703751564\n","[EPOCH 39] TRAIN F1: 0.8618309675739029 TRAIN ACCURACY: 86.453, TRAIN AUROC: 0.952\n","[EPOCH 39] VALID F1: 0.7060030785017958 VALID ACCURACY: 70.750, VALID AUROC: 0.796\n","epoch40: running_loss=9.232311427593231\n","[EPOCH 40] TRAIN F1: 0.8638867033831629 TRAIN ACCURACY: 86.747, TRAIN AUROC: 0.955\n","[EPOCH 40] VALID F1: 0.7051482059282372 VALID ACCURACY: 71.057, VALID AUROC: 0.798\n","epoch41: running_loss=9.127884104847908\n","[EPOCH 41] TRAIN F1: 0.8641584158415841 TRAIN ACCURACY: 86.862, TRAIN AUROC: 0.957\n","[EPOCH 41] VALID F1: 0.7044025157232703 VALID ACCURACY: 71.210, VALID AUROC: 0.801\n","epoch42: running_loss=9.01852248609066\n","[EPOCH 42] TRAIN F1: 0.8675116744496331 TRAIN ACCURACY: 87.321, TRAIN AUROC: 0.957\n","[EPOCH 42] VALID F1: 0.7070600632244467 VALID ACCURACY: 71.618, VALID AUROC: 0.800\n","epoch43: running_loss=8.938573345541954\n","[EPOCH 43] TRAIN F1: 0.8714249557074158 TRAIN ACCURACY: 87.028, TRAIN AUROC: 0.958\n","[EPOCH 43] VALID F1: 0.7169431875314228 VALID ACCURACY: 71.261, VALID AUROC: 0.800\n","epoch44: running_loss=8.947901219129562\n","[EPOCH 44] TRAIN F1: 0.8694838192029956 TRAIN ACCURACY: 87.538, TRAIN AUROC: 0.959\n","[EPOCH 44] VALID F1: 0.6954666666666667 VALID ACCURACY: 70.852, VALID AUROC: 0.796\n","epoch45: running_loss=8.831169337034225\n","[EPOCH 45] TRAIN F1: 0.8740892240828326 TRAIN ACCURACY: 87.423, TRAIN AUROC: 0.960\n","[EPOCH 45] VALID F1: 0.7165991902834008 VALID ACCURACY: 71.414, VALID AUROC: 0.800\n","epoch46: running_loss=8.675303533673286\n","[EPOCH 46] TRAIN F1: 0.8717052178590641 TRAIN ACCURACY: 87.819, TRAIN AUROC: 0.963\n","[EPOCH 46] VALID F1: 0.6993534482758621 VALID ACCURACY: 71.516, VALID AUROC: 0.801\n","epoch47: running_loss=8.490992560982704\n","[EPOCH 47] TRAIN F1: 0.8787012987012988 TRAIN ACCURACY: 88.075, TRAIN AUROC: 0.962\n","[EPOCH 47] VALID F1: 0.710376871450697 VALID ACCURACY: 71.363, VALID AUROC: 0.800\n","epoch48: running_loss=8.451226785779\n","[EPOCH 48] TRAIN F1: 0.8816614420062696 TRAIN ACCURACY: 88.432, TRAIN AUROC: 0.964\n","[EPOCH 48] VALID F1: 0.7158218125960062 VALID ACCURACY: 71.669, VALID AUROC: 0.801\n","epoch49: running_loss=8.379325270652771\n","[EPOCH 49] TRAIN F1: 0.8836611389638771 TRAIN ACCURACY: 88.445, TRAIN AUROC: 0.964\n","[EPOCH 49] VALID F1: 0.7076766649720386 VALID ACCURACY: 70.648, VALID AUROC: 0.797\n","epoch50: running_loss=8.42647397518158\n","[EPOCH 50] TRAIN F1: 0.8836608066184074 TRAIN ACCURACY: 88.509, TRAIN AUROC: 0.965\n","[EPOCH 50] VALID F1: 0.7043121149897331 VALID ACCURACY: 70.597, VALID AUROC: 0.796\n","epoch51: running_loss=8.354144304990768\n","[EPOCH 51] TRAIN F1: 0.880674448767834 TRAIN ACCURACY: 88.253, TRAIN AUROC: 0.965\n","[EPOCH 51] VALID F1: 0.7104049205535624 VALID ACCURACY: 71.159, VALID AUROC: 0.795\n","epoch52: running_loss=8.319911494851112\n","[EPOCH 52] TRAIN F1: 0.8783532536520583 TRAIN ACCURACY: 88.304, TRAIN AUROC: 0.965\n","[EPOCH 52] VALID F1: 0.7126925119490175 VALID ACCURACY: 72.384, VALID AUROC: 0.800\n","epoch53: running_loss=8.221158728003502\n","[EPOCH 53] TRAIN F1: 0.8845189388940213 TRAIN ACCURACY: 88.828, TRAIN AUROC: 0.968\n","[EPOCH 53] VALID F1: 0.7057591623036649 VALID ACCURACY: 71.312, VALID AUROC: 0.795\n","epoch54: running_loss=8.255822613835335\n","[EPOCH 54] TRAIN F1: 0.8866166192078695 TRAIN ACCURACY: 88.815, TRAIN AUROC: 0.968\n","[EPOCH 54] VALID F1: 0.7063655030800821 VALID ACCURACY: 70.801, VALID AUROC: 0.793\n","epoch55: running_loss=7.984424322843552\n","[EPOCH 55] TRAIN F1: 0.8850514104930134 TRAIN ACCURACY: 88.866, TRAIN AUROC: 0.969\n","[EPOCH 55] VALID F1: 0.7034700315457414 VALID ACCURACY: 71.210, VALID AUROC: 0.793\n","epoch56: running_loss=7.877841040492058\n","[EPOCH 56] TRAIN F1: 0.8855826201448321 TRAIN ACCURACY: 88.905, TRAIN AUROC: 0.969\n","[EPOCH 56] VALID F1: 0.7006302521008404 VALID ACCURACY: 70.904, VALID AUROC: 0.795\n","epoch57: running_loss=7.947379916906357\n","[EPOCH 57] TRAIN F1: 0.8893013389897918 TRAIN ACCURACY: 89.339, TRAIN AUROC: 0.970\n","[EPOCH 57] VALID F1: 0.7094105480868667 VALID ACCURACY: 71.312, VALID AUROC: 0.792\n","epoch58: running_loss=7.728829354047775\n","[EPOCH 58] TRAIN F1: 0.8883881230116648 TRAIN ACCURACY: 89.249, TRAIN AUROC: 0.971\n","[EPOCH 58] VALID F1: 0.7092050209205022 VALID ACCURACY: 71.618, VALID AUROC: 0.794\n","epoch59: running_loss=7.755864202976227\n","[EPOCH 59] TRAIN F1: 0.8865583834249905 TRAIN ACCURACY: 88.675, TRAIN AUROC: 0.969\n","[EPOCH 59] VALID F1: 0.7100050787201626 VALID ACCURACY: 70.852, VALID AUROC: 0.792\n","epoch60: running_loss=7.626941040158272\n","[EPOCH 60] TRAIN F1: 0.8875096974398757 TRAIN ACCURACY: 88.892, TRAIN AUROC: 0.968\n","[EPOCH 60] VALID F1: 0.7096441464672513 VALID ACCURACY: 71.261, VALID AUROC: 0.795\n","F1 on best model: 0.733475 (Epoch9)\n","(1959, 2)\n","\n","Start fold 1 =====================================\n","continuous_mean_std: \n","[[3.2705605e+01 1.1778070e+04]\n"," [1.2187842e+01 2.1753777e+04]]\n","\n","X_train shape: (7833, 5)\n","y_train shape: (7833,)\n","X_valid shape: (1958, 5)\n","y_valid shape: (1958,)\n","Pretraining begins!\n","Epoch: 0, Running Loss: 508.63348388671875\n","Epoch: 1, Running Loss: 358.7673969268799\n","Epoch: 2, Running Loss: 284.566668510437\n","Epoch: 3, Running Loss: 222.36436414718628\n","Epoch: 4, Running Loss: 169.3856863975525\n","Epoch: 5, Running Loss: 126.03420925140381\n","Epoch: 6, Running Loss: 89.75311374664307\n","Epoch: 7, Running Loss: 63.5659966468811\n","Epoch: 8, Running Loss: 46.065698981285095\n","Epoch: 9, Running Loss: 34.70807605981827\n","Epoch: 10, Running Loss: 26.880872428417206\n","Epoch: 11, Running Loss: 22.106436550617218\n","Epoch: 12, Running Loss: 18.686249673366547\n","Epoch: 13, Running Loss: 16.047694832086563\n","Epoch: 14, Running Loss: 14.075811713933945\n","Epoch: 15, Running Loss: 12.35647764801979\n","Epoch: 16, Running Loss: 11.19843664765358\n","Epoch: 17, Running Loss: 10.16381248831749\n","Epoch: 18, Running Loss: 9.274616062641144\n","Epoch: 19, Running Loss: 8.435197368264198\n","Epoch: 20, Running Loss: 7.719924792647362\n","Epoch: 21, Running Loss: 7.249574512243271\n","Epoch: 22, Running Loss: 6.939071342349052\n","Epoch: 23, Running Loss: 6.316858679056168\n","Epoch: 24, Running Loss: 6.052852809429169\n","Epoch: 25, Running Loss: 5.833561822772026\n","Epoch: 26, Running Loss: 5.301992684602737\n","Epoch: 27, Running Loss: 5.348114222288132\n","Epoch: 28, Running Loss: 4.968677759170532\n","Epoch: 29, Running Loss: 4.634652264416218\n","Epoch: 30, Running Loss: 4.543503314256668\n","Epoch: 31, Running Loss: 4.28421451151371\n","Epoch: 32, Running Loss: 4.231146655976772\n","Epoch: 33, Running Loss: 3.9892747327685356\n","Epoch: 34, Running Loss: 3.847056046128273\n","Epoch: 35, Running Loss: 3.7497518733143806\n","Epoch: 36, Running Loss: 3.5276930555701256\n","Epoch: 37, Running Loss: 3.3437540531158447\n","Epoch: 38, Running Loss: 3.369103342294693\n","Epoch: 39, Running Loss: 3.247538208961487\n","Epoch: 40, Running Loss: 3.181229442358017\n","Epoch: 41, Running Loss: 3.1450782418251038\n","Epoch: 42, Running Loss: 3.0026001557707787\n","Epoch: 43, Running Loss: 3.029048539698124\n","Epoch: 44, Running Loss: 2.885753720998764\n","Epoch: 45, Running Loss: 2.8434326350688934\n","Epoch: 46, Running Loss: 2.6484285593032837\n","Epoch: 47, Running Loss: 2.7377695590257645\n","Epoch: 48, Running Loss: 2.630017325282097\n","Epoch: 49, Running Loss: 2.6175773441791534\n","Epoch: 50, Running Loss: 2.473388943821192\n","Epoch: 51, Running Loss: 2.4931226149201393\n","Epoch: 52, Running Loss: 2.4529374055564404\n","Epoch: 53, Running Loss: 2.352846682071686\n","Epoch: 54, Running Loss: 2.266926806420088\n","Epoch: 55, Running Loss: 2.221692718565464\n","Epoch: 56, Running Loss: 2.28953592851758\n","Epoch: 57, Running Loss: 2.1603216901421547\n","Epoch: 58, Running Loss: 2.189696993678808\n","Epoch: 59, Running Loss: 2.116940710693598\n","Epoch: 60, Running Loss: 2.04633641988039\n","Epoch: 61, Running Loss: 2.0639162994921207\n","Epoch: 62, Running Loss: 2.159010488539934\n","Epoch: 63, Running Loss: 2.042343806475401\n","Epoch: 64, Running Loss: 1.8809975236654282\n","Epoch: 65, Running Loss: 1.8808016031980515\n","Epoch: 66, Running Loss: 1.8786464370787144\n","Epoch: 67, Running Loss: 1.9251699037849903\n","Epoch: 68, Running Loss: 1.9123837649822235\n","Epoch: 69, Running Loss: 1.8060233667492867\n","Epoch: 70, Running Loss: 1.8096471391618252\n","Epoch: 71, Running Loss: 1.736658114939928\n","Epoch: 72, Running Loss: 1.8076638653874397\n","Epoch: 73, Running Loss: 1.732032286003232\n","Epoch: 74, Running Loss: 1.6518686562776566\n","Epoch: 75, Running Loss: 1.6713865362107754\n","Epoch: 76, Running Loss: 1.5442138873040676\n","Epoch: 77, Running Loss: 1.5715927965939045\n","Epoch: 78, Running Loss: 1.5540083292871714\n","Epoch: 79, Running Loss: 1.630864031612873\n","Epoch: 80, Running Loss: 1.5119977444410324\n","Epoch: 81, Running Loss: 1.548005547374487\n","Epoch: 82, Running Loss: 1.5694580301642418\n","Epoch: 83, Running Loss: 1.5415124204009771\n","Epoch: 84, Running Loss: 1.4201071225106716\n","Epoch: 85, Running Loss: 1.4554083794355392\n","Epoch: 86, Running Loss: 1.499002629891038\n","Epoch: 87, Running Loss: 1.4042131770402193\n","Epoch: 88, Running Loss: 1.556241111829877\n","Epoch: 89, Running Loss: 1.4238299746066332\n","Epoch: 90, Running Loss: 1.4094860199838877\n","Epoch: 91, Running Loss: 1.4250735957175493\n","Epoch: 92, Running Loss: 1.3816613405942917\n","Epoch: 93, Running Loss: 1.4325914289802313\n","Epoch: 94, Running Loss: 1.3660291135311127\n","Epoch: 95, Running Loss: 1.3550921622663736\n","Epoch: 96, Running Loss: 1.3422515895217657\n","Epoch: 97, Running Loss: 1.2579430565238\n","Epoch: 98, Running Loss: 1.25524527952075\n","Epoch: 99, Running Loss: 1.2521943524479866\n","END OF PRETRAINING!\n","Training begins now.\n","epoch1: running_loss=19.982304632663727\n","[EPOCH 1] TRAIN F1: 0.6460251046025105 TRAIN ACCURACY: 67.599, TRAIN AUROC: 0.751\n","[EPOCH 1] VALID F1: 0.6325167037861916 VALID ACCURACY: 66.292, VALID AUROC: 0.731\n","epoch2: running_loss=17.79831373691559\n","[EPOCH 2] TRAIN F1: 0.7215953817895566 TRAIN ACCURACY: 72.909, TRAIN AUROC: 0.809\n","[EPOCH 2] VALID F1: 0.6913319238900634 VALID ACCURACY: 70.174, VALID AUROC: 0.780\n","epoch3: running_loss=16.172596633434296\n","[EPOCH 3] TRAIN F1: 0.7145187601957586 TRAIN ACCURACY: 75.424, TRAIN AUROC: 0.841\n","[EPOCH 3] VALID F1: 0.6646562123039806 VALID ACCURACY: 71.604, VALID AUROC: 0.804\n","epoch4: running_loss=15.170677661895752\n","[EPOCH 4] TRAIN F1: 0.7345517841601392 TRAIN ACCURACY: 76.637, TRAIN AUROC: 0.857\n","[EPOCH 4] VALID F1: 0.6900995899238431 VALID ACCURACY: 72.983, VALID AUROC: 0.812\n","epoch5: running_loss=14.619946002960205\n","[EPOCH 5] TRAIN F1: 0.7598368206342939 TRAIN ACCURACY: 76.701, TRAIN AUROC: 0.861\n","[EPOCH 5] VALID F1: 0.7102212855637513 VALID ACCURACY: 71.910, VALID AUROC: 0.813\n","epoch6: running_loss=14.272495299577713\n","[EPOCH 6] TRAIN F1: 0.7742187500000001 TRAIN ACCURACY: 77.863, TRAIN AUROC: 0.873\n","[EPOCH 6] VALID F1: 0.7256544502617801 VALID ACCURACY: 73.238, VALID AUROC: 0.822\n","epoch7: running_loss=13.970645397901535\n","[EPOCH 7] TRAIN F1: 0.7680195466268493 TRAIN ACCURACY: 78.182, TRAIN AUROC: 0.873\n","[EPOCH 7] VALID F1: 0.7096069868995634 VALID ACCURACY: 72.829, VALID AUROC: 0.819\n","epoch8: running_loss=13.72565034031868\n","[EPOCH 8] TRAIN F1: 0.761168384879725 TRAIN ACCURACY: 78.705, TRAIN AUROC: 0.882\n","[EPOCH 8] VALID F1: 0.6928406466512702 VALID ACCURACY: 72.829, VALID AUROC: 0.821\n","epoch9: running_loss=13.578085899353027\n","[EPOCH 9] TRAIN F1: 0.7757060597751576 TRAIN ACCURACY: 79.114, TRAIN AUROC: 0.884\n","[EPOCH 9] VALID F1: 0.7072495849474267 VALID ACCURACY: 72.983, VALID AUROC: 0.819\n","epoch10: running_loss=13.33243277668953\n","[EPOCH 10] TRAIN F1: 0.7753168965036913 TRAIN ACCURACY: 79.408, TRAIN AUROC: 0.889\n","[EPOCH 10] VALID F1: 0.7096045197740113 VALID ACCURACY: 73.749, VALID AUROC: 0.824\n","epoch11: running_loss=13.190089017152786\n","[EPOCH 11] TRAIN F1: 0.7893247068338051 TRAIN ACCURACY: 80.046, TRAIN AUROC: 0.893\n","[EPOCH 11] VALID F1: 0.7235198261814231 VALID ACCURACY: 74.004, VALID AUROC: 0.822\n","epoch12: running_loss=13.041850924491882\n","[EPOCH 12] TRAIN F1: 0.7507427213309565 TRAIN ACCURACY: 78.578, TRAIN AUROC: 0.890\n","[EPOCH 12] VALID F1: 0.6910617876424715 VALID ACCURACY: 73.698, VALID AUROC: 0.823\n","epoch13: running_loss=12.899873673915863\n","[EPOCH 13] TRAIN F1: 0.8007722007722008 TRAIN ACCURACY: 80.237, TRAIN AUROC: 0.898\n","[EPOCH 13] VALID F1: 0.7253886010362695 VALID ACCURACY: 72.932, VALID AUROC: 0.819\n","epoch14: running_loss=12.677961140871048\n","[EPOCH 14] TRAIN F1: 0.7951475048249242 TRAIN ACCURACY: 81.029, TRAIN AUROC: 0.902\n","[EPOCH 14] VALID F1: 0.7033333333333333 VALID ACCURACY: 72.727, VALID AUROC: 0.813\n","epoch15: running_loss=12.40099248290062\n","[EPOCH 15] TRAIN F1: 0.7899562702778954 TRAIN ACCURACY: 80.991, TRAIN AUROC: 0.907\n","[EPOCH 15] VALID F1: 0.7013729977116705 VALID ACCURACY: 73.340, VALID AUROC: 0.815\n","epoch16: running_loss=12.381337404251099\n","[EPOCH 16] TRAIN F1: 0.8023255813953488 TRAIN ACCURACY: 81.335, TRAIN AUROC: 0.909\n","[EPOCH 16] VALID F1: 0.7178649237472767 VALID ACCURACY: 73.544, VALID AUROC: 0.811\n","epoch17: running_loss=12.218652784824371\n","[EPOCH 17] TRAIN F1: 0.8132965444751018 TRAIN ACCURACY: 81.859, TRAIN AUROC: 0.914\n","[EPOCH 17] VALID F1: 0.7187335092348285 VALID ACCURACY: 72.778, VALID AUROC: 0.812\n","epoch18: running_loss=12.057258516550064\n","[EPOCH 18] TRAIN F1: 0.802968771880689 TRAIN ACCURACY: 82.038, TRAIN AUROC: 0.916\n","[EPOCH 18] VALID F1: 0.6993166287015945 VALID ACCURACY: 73.034, VALID AUROC: 0.815\n","epoch19: running_loss=11.73539325594902\n","[EPOCH 19] TRAIN F1: 0.8121442125237192 TRAIN ACCURACY: 82.306, TRAIN AUROC: 0.917\n","[EPOCH 19] VALID F1: 0.7001090512540894 VALID ACCURACY: 71.910, VALID AUROC: 0.807\n","epoch20: running_loss=11.662180006504059\n","[EPOCH 20] TRAIN F1: 0.8098669623059868 TRAIN ACCURACY: 82.484, TRAIN AUROC: 0.922\n","[EPOCH 20] VALID F1: 0.706079196876743 VALID ACCURACY: 73.085, VALID AUROC: 0.812\n","epoch21: running_loss=11.517389923334122\n","[EPOCH 21] TRAIN F1: 0.8217795484727755 TRAIN ACCURACY: 82.867, TRAIN AUROC: 0.923\n","[EPOCH 21] VALID F1: 0.7161152614727856 VALID ACCURACY: 72.829, VALID AUROC: 0.813\n","epoch22: running_loss=11.339362889528275\n","[EPOCH 22] TRAIN F1: 0.8175842235004108 TRAIN ACCURACY: 82.995, TRAIN AUROC: 0.927\n","[EPOCH 22] VALID F1: 0.7044578976334618 VALID ACCURACY: 72.574, VALID AUROC: 0.811\n","epoch23: running_loss=11.341074675321579\n","[EPOCH 23] TRAIN F1: 0.833872847339117 TRAIN ACCURACY: 83.621, TRAIN AUROC: 0.930\n","[EPOCH 23] VALID F1: 0.7170984455958549 VALID ACCURACY: 72.114, VALID AUROC: 0.808\n","epoch24: running_loss=10.986209869384766\n","[EPOCH 24] TRAIN F1: 0.8311965811965812 TRAIN ACCURACY: 83.863, TRAIN AUROC: 0.931\n","[EPOCH 24] VALID F1: 0.7197860962566844 VALID ACCURACY: 73.238, VALID AUROC: 0.804\n","epoch25: running_loss=11.038592547178268\n","[EPOCH 25] TRAIN F1: 0.8255845942228335 TRAIN ACCURACY: 83.812, TRAIN AUROC: 0.932\n","[EPOCH 25] VALID F1: 0.6986225895316804 VALID ACCURACY: 72.063, VALID AUROC: 0.802\n","epoch26: running_loss=10.759779304265976\n","[EPOCH 26] TRAIN F1: 0.8309113133233735 TRAIN ACCURACY: 84.106, TRAIN AUROC: 0.934\n","[EPOCH 26] VALID F1: 0.7023484434735117 VALID ACCURACY: 72.165, VALID AUROC: 0.802\n","epoch27: running_loss=10.527846366167068\n","[EPOCH 27] TRAIN F1: 0.8418019905709797 TRAIN ACCURACY: 84.578, TRAIN AUROC: 0.937\n","[EPOCH 27] VALID F1: 0.7151132174828857 VALID ACCURACY: 72.370, VALID AUROC: 0.801\n","epoch28: running_loss=10.522620916366577\n","[EPOCH 28] TRAIN F1: 0.8407847324169225 TRAIN ACCURACY: 84.770, TRAIN AUROC: 0.938\n","[EPOCH 28] VALID F1: 0.7082213863514238 VALID ACCURACY: 72.268, VALID AUROC: 0.802\n","epoch29: running_loss=10.411621168255806\n","[EPOCH 29] TRAIN F1: 0.8482964114522608 TRAIN ACCURACY: 85.050, TRAIN AUROC: 0.941\n","[EPOCH 29] VALID F1: 0.7161390762843798 VALID ACCURACY: 72.063, VALID AUROC: 0.805\n","epoch30: running_loss=10.259203046560287\n","[EPOCH 30] TRAIN F1: 0.8501616031027796 TRAIN ACCURACY: 85.204, TRAIN AUROC: 0.941\n","[EPOCH 30] VALID F1: 0.7154639175257732 VALID ACCURACY: 71.808, VALID AUROC: 0.797\n","epoch31: running_loss=10.055512964725494\n","[EPOCH 31] TRAIN F1: 0.8517129928894636 TRAIN ACCURACY: 85.357, TRAIN AUROC: 0.943\n","[EPOCH 31] VALID F1: 0.7143603133159269 VALID ACCURACY: 72.063, VALID AUROC: 0.806\n","epoch32: running_loss=9.949960112571716\n","[EPOCH 32] TRAIN F1: 0.8534965490298215 TRAIN ACCURACY: 85.638, TRAIN AUROC: 0.945\n","[EPOCH 32] VALID F1: 0.7203345530580241 VALID ACCURACY: 72.676, VALID AUROC: 0.805\n","epoch33: running_loss=9.873565077781677\n","[EPOCH 33] TRAIN F1: 0.8496420047732698 TRAIN ACCURACY: 85.523, TRAIN AUROC: 0.944\n","[EPOCH 33] VALID F1: 0.7088204038257173 VALID ACCURACY: 72.012, VALID AUROC: 0.798\n","epoch34: running_loss=9.834951281547546\n","[EPOCH 34] TRAIN F1: 0.8555456739931393 TRAIN ACCURACY: 85.484, TRAIN AUROC: 0.945\n","[EPOCH 34] VALID F1: 0.7185261003070623 VALID ACCURACY: 71.910, VALID AUROC: 0.798\n","epoch35: running_loss=9.881317466497421\n","[EPOCH 35] TRAIN F1: 0.8488685344827587 TRAIN ACCURACY: 85.676, TRAIN AUROC: 0.948\n","[EPOCH 35] VALID F1: 0.6938553561718326 VALID ACCURACY: 71.246, VALID AUROC: 0.798\n","epoch36: running_loss=9.653078645467758\n","[EPOCH 36] TRAIN F1: 0.8543132655720617 TRAIN ACCURACY: 85.727, TRAIN AUROC: 0.947\n","[EPOCH 36] VALID F1: 0.7079646017699115 VALID ACCURACY: 71.348, VALID AUROC: 0.795\n","epoch37: running_loss=9.458605974912643\n","[EPOCH 37] TRAIN F1: 0.8613061332626838 TRAIN ACCURACY: 86.633, TRAIN AUROC: 0.951\n","[EPOCH 37] VALID F1: 0.7103707684040839 VALID ACCURACY: 72.472, VALID AUROC: 0.798\n","epoch38: running_loss=9.380654752254486\n","[EPOCH 38] TRAIN F1: 0.8550803595750478 TRAIN ACCURACY: 86.416, TRAIN AUROC: 0.953\n","[EPOCH 38] VALID F1: 0.7003891050583658 VALID ACCURACY: 72.472, VALID AUROC: 0.802\n","epoch39: running_loss=9.417942807078362\n","[EPOCH 39] TRAIN F1: 0.8478892733564013 TRAIN ACCURACY: 85.970, TRAIN AUROC: 0.950\n","[EPOCH 39] VALID F1: 0.7009397457158651 VALID ACCURACY: 72.370, VALID AUROC: 0.797\n","epoch40: running_loss=9.420664310455322\n","[EPOCH 40] TRAIN F1: 0.8697327852004111 TRAIN ACCURACY: 87.055, TRAIN AUROC: 0.954\n","[EPOCH 40] VALID F1: 0.712799167533819 VALID ACCURACY: 71.808, VALID AUROC: 0.800\n","epoch41: running_loss=9.30423517525196\n","[EPOCH 41] TRAIN F1: 0.8617842876165113 TRAIN ACCURACY: 86.748, TRAIN AUROC: 0.954\n","[EPOCH 41] VALID F1: 0.7020364415862808 VALID ACCURACY: 71.604, VALID AUROC: 0.797\n","epoch42: running_loss=9.038906916975975\n","[EPOCH 42] TRAIN F1: 0.8687688080596624 TRAIN ACCURACY: 87.195, TRAIN AUROC: 0.956\n","[EPOCH 42] VALID F1: 0.7157784743991642 VALID ACCURACY: 72.217, VALID AUROC: 0.797\n","epoch43: running_loss=9.043529719114304\n","[EPOCH 43] TRAIN F1: 0.8700105042016807 TRAIN ACCURACY: 87.361, TRAIN AUROC: 0.958\n","[EPOCH 43] VALID F1: 0.7147401908801696 VALID ACCURACY: 72.523, VALID AUROC: 0.795\n","epoch44: running_loss=9.077752649784088\n","[EPOCH 44] TRAIN F1: 0.8741721854304636 TRAIN ACCURACY: 87.387, TRAIN AUROC: 0.958\n","[EPOCH 44] VALID F1: 0.7158974358974359 VALID ACCURACY: 71.706, VALID AUROC: 0.800\n","epoch45: running_loss=9.0082438737154\n","[EPOCH 45] TRAIN F1: 0.8673550436854646 TRAIN ACCURACY: 87.208, TRAIN AUROC: 0.956\n","[EPOCH 45] VALID F1: 0.706072004298764 VALID ACCURACY: 72.063, VALID AUROC: 0.796\n","epoch46: running_loss=8.850376203656197\n","[EPOCH 46] TRAIN F1: 0.8709256844850065 TRAIN ACCURACY: 87.361, TRAIN AUROC: 0.956\n","[EPOCH 46] VALID F1: 0.7118997912317329 VALID ACCURACY: 71.808, VALID AUROC: 0.792\n","epoch47: running_loss=8.698658972978592\n","[EPOCH 47] TRAIN F1: 0.8689967982924227 TRAIN ACCURACY: 87.463, TRAIN AUROC: 0.959\n","[EPOCH 47] VALID F1: 0.7022318998366903 VALID ACCURACY: 72.063, VALID AUROC: 0.796\n","epoch48: running_loss=8.76586040854454\n","[EPOCH 48] TRAIN F1: 0.8760288717234392 TRAIN ACCURACY: 87.502, TRAIN AUROC: 0.959\n","[EPOCH 48] VALID F1: 0.7160995429151853 VALID ACCURACY: 71.450, VALID AUROC: 0.790\n","epoch49: running_loss=8.700460687279701\n","[EPOCH 49] TRAIN F1: 0.8747712418300654 TRAIN ACCURACY: 87.770, TRAIN AUROC: 0.960\n","[EPOCH 49] VALID F1: 0.7062566277836692 VALID ACCURACY: 71.706, VALID AUROC: 0.790\n","epoch50: running_loss=8.701078206300735\n","[EPOCH 50] TRAIN F1: 0.8801968656909728 TRAIN ACCURACY: 88.191, TRAIN AUROC: 0.962\n","[EPOCH 50] VALID F1: 0.7063784923563521 VALID ACCURACY: 71.553, VALID AUROC: 0.792\n","epoch51: running_loss=8.47448779642582\n","[EPOCH 51] TRAIN F1: 0.8779973649538867 TRAIN ACCURACY: 88.178, TRAIN AUROC: 0.963\n","[EPOCH 51] VALID F1: 0.7076429716729022 VALID ACCURACY: 72.063, VALID AUROC: 0.791\n","epoch52: running_loss=8.418498918414116\n","[EPOCH 52] TRAIN F1: 0.8818897637795275 TRAIN ACCURACY: 88.510, TRAIN AUROC: 0.964\n","[EPOCH 52] VALID F1: 0.709814323607427 VALID ACCURACY: 72.063, VALID AUROC: 0.792\n","epoch53: running_loss=8.450829356908798\n","[EPOCH 53] TRAIN F1: 0.8792394655704008 TRAIN ACCURACY: 87.999, TRAIN AUROC: 0.963\n","[EPOCH 53] VALID F1: 0.7123711340206187 VALID ACCURACY: 71.502, VALID AUROC: 0.789\n","epoch54: running_loss=8.210089698433876\n","[EPOCH 54] TRAIN F1: 0.8847406664996242 TRAIN ACCURACY: 88.255, TRAIN AUROC: 0.964\n","[EPOCH 54] VALID F1: 0.7148594377510041 VALID ACCURACY: 70.991, VALID AUROC: 0.788\n","epoch55: running_loss=8.177554041147232\n","[EPOCH 55] TRAIN F1: 0.8817005545286507 TRAIN ACCURACY: 88.561, TRAIN AUROC: 0.965\n","[EPOCH 55] VALID F1: 0.7071352502662407 VALID ACCURACY: 71.910, VALID AUROC: 0.792\n","epoch56: running_loss=8.487125635147095\n","[EPOCH 56] TRAIN F1: 0.8723518369536069 TRAIN ACCURACY: 87.846, TRAIN AUROC: 0.962\n","[EPOCH 56] VALID F1: 0.6989130434782609 VALID ACCURACY: 71.706, VALID AUROC: 0.790\n","epoch57: running_loss=8.280683442950249\n","[EPOCH 57] TRAIN F1: 0.8814009020960467 TRAIN ACCURACY: 88.587, TRAIN AUROC: 0.966\n","[EPOCH 57] VALID F1: 0.6977491961414791 VALID ACCURACY: 71.195, VALID AUROC: 0.785\n","epoch58: running_loss=8.127248853445053\n","[EPOCH 58] TRAIN F1: 0.8836650193669026 TRAIN ACCURACY: 88.880, TRAIN AUROC: 0.967\n","[EPOCH 58] VALID F1: 0.7002188183807438 VALID ACCURACY: 72.012, VALID AUROC: 0.790\n","epoch59: running_loss=8.191052749752998\n","[EPOCH 59] TRAIN F1: 0.8889464147035983 TRAIN ACCURACY: 89.046, TRAIN AUROC: 0.967\n","[EPOCH 59] VALID F1: 0.7077888133821223 VALID ACCURACY: 71.450, VALID AUROC: 0.789\n","epoch60: running_loss=7.992905780673027\n","[EPOCH 60] TRAIN F1: 0.8909393822888634 TRAIN ACCURACY: 89.136, TRAIN AUROC: 0.967\n","[EPOCH 60] VALID F1: 0.7057602490918526 VALID ACCURACY: 71.042, VALID AUROC: 0.788\n","F1 on best model: 0.725654 (Epoch5)\n","(1958, 2)\n","\n","Start fold 2 =====================================\n","continuous_mean_std: \n","[[3.2692326e+01 1.1924119e+04]\n"," [1.2165538e+01 2.1744918e+04]]\n","\n","X_train shape: (7833, 5)\n","y_train shape: (7833,)\n","X_valid shape: (1958, 5)\n","y_valid shape: (1958,)\n","Pretraining begins!\n","Epoch: 0, Running Loss: 507.7030324935913\n","Epoch: 1, Running Loss: 354.6939067840576\n","Epoch: 2, Running Loss: 279.9006814956665\n","Epoch: 3, Running Loss: 222.5421109199524\n","Epoch: 4, Running Loss: 170.57185125350952\n","Epoch: 5, Running Loss: 125.72563529014587\n","Epoch: 6, Running Loss: 89.63241934776306\n","Epoch: 7, Running Loss: 63.534213066101074\n","Epoch: 8, Running Loss: 46.3758544921875\n","Epoch: 9, Running Loss: 35.11992835998535\n","Epoch: 10, Running Loss: 27.892035007476807\n","Epoch: 11, Running Loss: 22.736249804496765\n","Epoch: 12, Running Loss: 19.14877724647522\n","Epoch: 13, Running Loss: 16.242411822080612\n","Epoch: 14, Running Loss: 14.192317515611649\n","Epoch: 15, Running Loss: 12.488178819417953\n","Epoch: 16, Running Loss: 11.437486082315445\n","Epoch: 17, Running Loss: 10.145480453968048\n","Epoch: 18, Running Loss: 9.190126538276672\n","Epoch: 19, Running Loss: 8.369248941540718\n","Epoch: 20, Running Loss: 7.923793405294418\n","Epoch: 21, Running Loss: 7.260925337672234\n","Epoch: 22, Running Loss: 6.759992331266403\n","Epoch: 23, Running Loss: 6.513012692332268\n","Epoch: 24, Running Loss: 5.865755200386047\n","Epoch: 25, Running Loss: 5.780953332781792\n","Epoch: 26, Running Loss: 5.4694486409425735\n","Epoch: 27, Running Loss: 5.088938146829605\n","Epoch: 28, Running Loss: 4.924378037452698\n","Epoch: 29, Running Loss: 4.696287125349045\n","Epoch: 30, Running Loss: 4.449979588389397\n","Epoch: 31, Running Loss: 4.225470907986164\n","Epoch: 32, Running Loss: 4.1032879576087\n","Epoch: 33, Running Loss: 4.049563653767109\n","Epoch: 34, Running Loss: 3.9681152552366257\n","Epoch: 35, Running Loss: 3.756050482392311\n","Epoch: 36, Running Loss: 3.585158593952656\n","Epoch: 37, Running Loss: 3.511103868484497\n","Epoch: 38, Running Loss: 3.3086373433470726\n","Epoch: 39, Running Loss: 3.2572908848524094\n","Epoch: 40, Running Loss: 3.149809740483761\n","Epoch: 41, Running Loss: 3.111377589404583\n","Epoch: 42, Running Loss: 3.10551904886961\n","Epoch: 43, Running Loss: 2.920319028198719\n","Epoch: 44, Running Loss: 2.919468715786934\n","Epoch: 45, Running Loss: 2.8222105652093887\n","Epoch: 46, Running Loss: 2.7301922366023064\n","Epoch: 47, Running Loss: 2.6815298087894917\n","Epoch: 48, Running Loss: 2.6442173905670643\n","Epoch: 49, Running Loss: 2.547424837946892\n","Epoch: 50, Running Loss: 2.548538312315941\n","Epoch: 51, Running Loss: 2.4240701720118523\n","Epoch: 52, Running Loss: 2.3748041689395905\n","Epoch: 53, Running Loss: 2.2950406298041344\n","Epoch: 54, Running Loss: 2.2513597421348095\n","Epoch: 55, Running Loss: 2.26732924208045\n","Epoch: 56, Running Loss: 2.367476064711809\n","Epoch: 57, Running Loss: 2.3084759674966335\n","Epoch: 58, Running Loss: 2.0787858478724957\n","Epoch: 59, Running Loss: 2.0812419205904007\n","Epoch: 60, Running Loss: 2.0694719292223454\n","Epoch: 61, Running Loss: 2.1318044029176235\n","Epoch: 62, Running Loss: 1.9679017439484596\n","Epoch: 63, Running Loss: 1.890035953372717\n","Epoch: 64, Running Loss: 1.8929532021284103\n","Epoch: 65, Running Loss: 1.8649202957749367\n","Epoch: 66, Running Loss: 1.8756646811962128\n","Epoch: 67, Running Loss: 1.891539167612791\n","Epoch: 68, Running Loss: 1.8603267632424831\n","Epoch: 69, Running Loss: 1.7681289054453373\n","Epoch: 70, Running Loss: 1.7920238971710205\n","Epoch: 71, Running Loss: 1.66618787124753\n","Epoch: 72, Running Loss: 1.766274880617857\n","Epoch: 73, Running Loss: 1.7082443311810493\n","Epoch: 74, Running Loss: 1.609490528702736\n","Epoch: 75, Running Loss: 1.5750114899128675\n","Epoch: 76, Running Loss: 1.6005122736096382\n","Epoch: 77, Running Loss: 1.533037569373846\n","Epoch: 78, Running Loss: 1.556506384164095\n","Epoch: 79, Running Loss: 1.5072778165340424\n","Epoch: 80, Running Loss: 1.6325233057141304\n","Epoch: 81, Running Loss: 1.5327881891280413\n","Epoch: 82, Running Loss: 1.5499788261950016\n","Epoch: 83, Running Loss: 1.535997573286295\n","Epoch: 84, Running Loss: 1.4751792177557945\n","Epoch: 85, Running Loss: 1.529371252283454\n","Epoch: 86, Running Loss: 1.4609000477939844\n","Epoch: 87, Running Loss: 1.4376843124628067\n","Epoch: 88, Running Loss: 1.416734341531992\n","Epoch: 89, Running Loss: 1.3915389236062765\n","Epoch: 90, Running Loss: 1.3391559720039368\n","Epoch: 91, Running Loss: 1.4353760741651058\n","Epoch: 92, Running Loss: 1.3235527966171503\n","Epoch: 93, Running Loss: 1.3062516748905182\n","Epoch: 94, Running Loss: 1.4178085681051016\n","Epoch: 95, Running Loss: 1.2247359473258257\n","Epoch: 96, Running Loss: 1.3507575895637274\n","Epoch: 97, Running Loss: 1.3484692387282848\n","Epoch: 98, Running Loss: 1.3574666250497103\n","Epoch: 99, Running Loss: 1.2419946249574423\n","END OF PRETRAINING!\n","Training begins now.\n","epoch1: running_loss=19.680684745311737\n","[EPOCH 1] TRAIN F1: 0.7035948451277414 TRAIN ACCURACY: 66.526, TRAIN AUROC: 0.751\n","[EPOCH 1] VALID F1: 0.6988382484361036 VALID ACCURACY: 65.577, VALID AUROC: 0.742\n","epoch2: running_loss=17.878561198711395\n","[EPOCH 2] TRAIN F1: 0.7045203969128996 TRAIN ACCURACY: 72.629, TRAIN AUROC: 0.806\n","[EPOCH 2] VALID F1: 0.6920565832426551 VALID ACCURACY: 71.093, VALID AUROC: 0.789\n","epoch3: running_loss=16.47379145026207\n","[EPOCH 3] TRAIN F1: 0.750093761720215 TRAIN ACCURACY: 74.480, TRAIN AUROC: 0.837\n","[EPOCH 3] VALID F1: 0.7325062034739455 VALID ACCURACY: 72.472, VALID AUROC: 0.817\n","epoch4: running_loss=15.391388684511185\n","[EPOCH 4] TRAIN F1: 0.7415289834780174 TRAIN ACCURACY: 76.433, TRAIN AUROC: 0.854\n","[EPOCH 4] VALID F1: 0.7185761957730812 VALID ACCURACY: 74.157, VALID AUROC: 0.831\n","epoch5: running_loss=14.819976598024368\n","[EPOCH 5] TRAIN F1: 0.7645371577574968 TRAIN ACCURACY: 76.944, TRAIN AUROC: 0.864\n","[EPOCH 5] VALID F1: 0.7318579516212043 VALID ACCURACY: 73.391, VALID AUROC: 0.834\n","epoch6: running_loss=14.464244604110718\n","[EPOCH 6] TRAIN F1: 0.7384570849616442 TRAIN ACCURACY: 76.931, TRAIN AUROC: 0.865\n","[EPOCH 6] VALID F1: 0.7180667433831991 VALID ACCURACY: 74.974, VALID AUROC: 0.833\n","epoch7: running_loss=14.239481717348099\n","[EPOCH 7] TRAIN F1: 0.7450412624873317 TRAIN ACCURACY: 77.518, TRAIN AUROC: 0.870\n","[EPOCH 7] VALID F1: 0.7137931034482758 VALID ACCURACY: 74.566, VALID AUROC: 0.828\n","epoch8: running_loss=14.057973027229309\n","[EPOCH 8] TRAIN F1: 0.752763234438627 TRAIN ACCURACY: 78.297, TRAIN AUROC: 0.879\n","[EPOCH 8] VALID F1: 0.7222222222222222 VALID ACCURACY: 75.485, VALID AUROC: 0.835\n","epoch9: running_loss=13.702457964420319\n","[EPOCH 9] TRAIN F1: 0.7841631355932204 TRAIN ACCURACY: 79.191, TRAIN AUROC: 0.882\n","[EPOCH 9] VALID F1: 0.7342436974789917 VALID ACCURACY: 74.157, VALID AUROC: 0.835\n","epoch10: running_loss=13.531613796949387\n","[EPOCH 10] TRAIN F1: 0.7860991379310345 TRAIN ACCURACY: 79.727, TRAIN AUROC: 0.888\n","[EPOCH 10] VALID F1: 0.7306034482758621 VALID ACCURACY: 74.464, VALID AUROC: 0.833\n","epoch11: running_loss=13.336447894573212\n","[EPOCH 11] TRAIN F1: 0.7729140104830713 TRAIN ACCURACY: 79.535, TRAIN AUROC: 0.890\n","[EPOCH 11] VALID F1: 0.7242937853107345 VALID ACCURACY: 75.077, VALID AUROC: 0.837\n","epoch12: running_loss=13.169018477201462\n","[EPOCH 12] TRAIN F1: 0.7998952331063383 TRAIN ACCURACY: 80.493, TRAIN AUROC: 0.896\n","[EPOCH 12] VALID F1: 0.7267015706806282 VALID ACCURACY: 73.340, VALID AUROC: 0.834\n","epoch13: running_loss=12.920140266418457\n","[EPOCH 13] TRAIN F1: 0.7996832937450513 TRAIN ACCURACY: 80.620, TRAIN AUROC: 0.899\n","[EPOCH 13] VALID F1: 0.7344573234984194 VALID ACCURACY: 74.259, VALID AUROC: 0.835\n","epoch14: running_loss=12.802719354629517\n","[EPOCH 14] TRAIN F1: 0.7835601066068172 TRAIN ACCURACY: 80.301, TRAIN AUROC: 0.900\n","[EPOCH 14] VALID F1: 0.715008431703204 VALID ACCURACY: 74.106, VALID AUROC: 0.832\n","epoch15: running_loss=12.75183680653572\n","[EPOCH 15] TRAIN F1: 0.7929843944206602 TRAIN ACCURACY: 80.863, TRAIN AUROC: 0.904\n","[EPOCH 15] VALID F1: 0.7278724573941726 VALID ACCURACY: 74.719, VALID AUROC: 0.830\n","epoch16: running_loss=12.377595454454422\n","[EPOCH 16] TRAIN F1: 0.7940932928512283 TRAIN ACCURACY: 80.952, TRAIN AUROC: 0.908\n","[EPOCH 16] VALID F1: 0.7269736842105262 VALID ACCURACY: 74.566, VALID AUROC: 0.834\n","epoch17: running_loss=12.303320109844208\n","[EPOCH 17] TRAIN F1: 0.8153401628578935 TRAIN ACCURACY: 82.050, TRAIN AUROC: 0.912\n","[EPOCH 17] VALID F1: 0.7280378748027355 VALID ACCURACY: 73.596, VALID AUROC: 0.830\n","epoch18: running_loss=11.921618461608887\n","[EPOCH 18] TRAIN F1: 0.8089528377298162 TRAIN ACCURACY: 81.693, TRAIN AUROC: 0.913\n","[EPOCH 18] VALID F1: 0.7218366257341163 VALID ACCURACY: 73.391, VALID AUROC: 0.830\n","epoch19: running_loss=11.824496120214462\n","[EPOCH 19] TRAIN F1: 0.8069837778388781 TRAIN ACCURACY: 82.076, TRAIN AUROC: 0.918\n","[EPOCH 19] VALID F1: 0.7263790278536317 VALID ACCURACY: 74.413, VALID AUROC: 0.830\n","epoch20: running_loss=11.857968807220459\n","[EPOCH 20] TRAIN F1: 0.8244758011341158 TRAIN ACCURACY: 83.008, TRAIN AUROC: 0.921\n","[EPOCH 20] VALID F1: 0.7251336898395722 VALID ACCURACY: 73.749, VALID AUROC: 0.828\n","epoch21: running_loss=11.618106424808502\n","[EPOCH 21] TRAIN F1: 0.8112082119572757 TRAIN ACCURACY: 82.625, TRAIN AUROC: 0.924\n","[EPOCH 21] VALID F1: 0.7195121951219512 VALID ACCURACY: 74.157, VALID AUROC: 0.823\n","epoch22: running_loss=11.37601563334465\n","[EPOCH 22] TRAIN F1: 0.8303053730189408 TRAIN ACCURACY: 83.187, TRAIN AUROC: 0.925\n","[EPOCH 22] VALID F1: 0.7276485788113694 VALID ACCURACY: 73.085, VALID AUROC: 0.826\n","epoch23: running_loss=11.316926956176758\n","[EPOCH 23] TRAIN F1: 0.8281146782930374 TRAIN ACCURACY: 83.391, TRAIN AUROC: 0.926\n","[EPOCH 23] VALID F1: 0.7309110057925223 VALID ACCURACY: 73.902, VALID AUROC: 0.829\n","epoch24: running_loss=11.046328783035278\n","[EPOCH 24] TRAIN F1: 0.8268230902546327 TRAIN ACCURACY: 83.416, TRAIN AUROC: 0.933\n","[EPOCH 24] VALID F1: 0.7246531483457843 VALID ACCURACY: 73.647, VALID AUROC: 0.826\n","epoch25: running_loss=10.976974606513977\n","[EPOCH 25] TRAIN F1: 0.8225569924010132 TRAIN ACCURACY: 83.008, TRAIN AUROC: 0.927\n","[EPOCH 25] VALID F1: 0.7282377919320595 VALID ACCURACY: 73.851, VALID AUROC: 0.825\n","epoch26: running_loss=10.883748561143875\n","[EPOCH 26] TRAIN F1: 0.84306332076453 TRAIN ACCURACY: 84.591, TRAIN AUROC: 0.934\n","[EPOCH 26] VALID F1: 0.7270822420115244 VALID ACCURACY: 73.391, VALID AUROC: 0.825\n","epoch27: running_loss=10.700856387615204\n","[EPOCH 27] TRAIN F1: 0.8468989810038999 TRAIN ACCURACY: 84.463, TRAIN AUROC: 0.937\n","[EPOCH 27] VALID F1: 0.7281012658227848 VALID ACCURACY: 72.574, VALID AUROC: 0.823\n","epoch28: running_loss=10.594422698020935\n","[EPOCH 28] TRAIN F1: 0.8467930407686315 TRAIN ACCURACY: 84.936, TRAIN AUROC: 0.940\n","[EPOCH 28] VALID F1: 0.7214659685863875 VALID ACCURACY: 72.829, VALID AUROC: 0.827\n","epoch29: running_loss=10.427618384361267\n","[EPOCH 29] TRAIN F1: 0.8458230157695817 TRAIN ACCURACY: 84.897, TRAIN AUROC: 0.940\n","[EPOCH 29] VALID F1: 0.7189952904238618 VALID ACCURACY: 72.574, VALID AUROC: 0.820\n","epoch30: running_loss=10.347182601690292\n","[EPOCH 30] TRAIN F1: 0.8445197445588427 TRAIN ACCURACY: 84.770, TRAIN AUROC: 0.939\n","[EPOCH 30] VALID F1: 0.7217573221757323 VALID ACCURACY: 72.829, VALID AUROC: 0.823\n","epoch31: running_loss=10.394792407751083\n","[EPOCH 31] TRAIN F1: 0.8441164843852945 TRAIN ACCURACY: 84.897, TRAIN AUROC: 0.941\n","[EPOCH 31] VALID F1: 0.7194473963868224 VALID ACCURACY: 73.034, VALID AUROC: 0.823\n","epoch32: running_loss=10.296972274780273\n","[EPOCH 32] TRAIN F1: 0.8492935635792778 TRAIN ACCURACY: 85.293, TRAIN AUROC: 0.944\n","[EPOCH 32] VALID F1: 0.7263267429760665 VALID ACCURACY: 73.136, VALID AUROC: 0.819\n","epoch33: running_loss=10.161335289478302\n","[EPOCH 33] TRAIN F1: 0.852868479250683 TRAIN ACCURACY: 85.561, TRAIN AUROC: 0.944\n","[EPOCH 33] VALID F1: 0.724607329842932 VALID ACCURACY: 73.136, VALID AUROC: 0.819\n","epoch34: running_loss=9.878218322992325\n","[EPOCH 34] TRAIN F1: 0.8564736499674692 TRAIN ACCURACY: 85.919, TRAIN AUROC: 0.947\n","[EPOCH 34] VALID F1: 0.7150368033648791 VALID ACCURACY: 72.319, VALID AUROC: 0.816\n","epoch35: running_loss=9.771188735961914\n","[EPOCH 35] TRAIN F1: 0.8551919608348364 TRAIN ACCURACY: 85.650, TRAIN AUROC: 0.948\n","[EPOCH 35] VALID F1: 0.7156153050672183 VALID ACCURACY: 71.910, VALID AUROC: 0.818\n","epoch36: running_loss=9.622051805257797\n","[EPOCH 36] TRAIN F1: 0.8563484708063022 TRAIN ACCURACY: 86.148, TRAIN AUROC: 0.950\n","[EPOCH 36] VALID F1: 0.7207207207207207 VALID ACCURACY: 73.085, VALID AUROC: 0.819\n","epoch37: running_loss=9.720652237534523\n","[EPOCH 37] TRAIN F1: 0.8566953797963979 TRAIN ACCURACY: 85.982, TRAIN AUROC: 0.949\n","[EPOCH 37] VALID F1: 0.721038961038961 VALID ACCURACY: 72.574, VALID AUROC: 0.817\n","epoch38: running_loss=9.548953145742416\n","[EPOCH 38] TRAIN F1: 0.8583145918772326 TRAIN ACCURACY: 86.327, TRAIN AUROC: 0.952\n","[EPOCH 38] VALID F1: 0.7148167817312798 VALID ACCURACY: 72.574, VALID AUROC: 0.815\n","epoch39: running_loss=9.303672537207603\n","[EPOCH 39] TRAIN F1: 0.859916054564533 TRAIN ACCURACY: 86.365, TRAIN AUROC: 0.952\n","[EPOCH 39] VALID F1: 0.7175732217573223 VALID ACCURACY: 72.421, VALID AUROC: 0.813\n","epoch40: running_loss=9.40432833135128\n","[EPOCH 40] TRAIN F1: 0.8659131774980734 TRAIN ACCURACY: 86.672, TRAIN AUROC: 0.953\n","[EPOCH 40] VALID F1: 0.7149460708782743 VALID ACCURACY: 71.655, VALID AUROC: 0.812\n","epoch41: running_loss=9.344765663146973\n","[EPOCH 41] TRAIN F1: 0.8641554009712561 TRAIN ACCURACY: 86.787, TRAIN AUROC: 0.955\n","[EPOCH 41] VALID F1: 0.7067510548523207 VALID ACCURACY: 71.604, VALID AUROC: 0.811\n","epoch42: running_loss=9.086460962891579\n","[EPOCH 42] TRAIN F1: 0.8657419523684899 TRAIN ACCURACY: 86.902, TRAIN AUROC: 0.955\n","[EPOCH 42] VALID F1: 0.7108307045215562 VALID ACCURACY: 71.910, VALID AUROC: 0.810\n","epoch43: running_loss=9.095818430185318\n","[EPOCH 43] TRAIN F1: 0.8573728699852409 TRAIN ACCURACY: 86.429, TRAIN AUROC: 0.954\n","[EPOCH 43] VALID F1: 0.7060097455332972 VALID ACCURACY: 72.268, VALID AUROC: 0.812\n","epoch44: running_loss=9.050895988941193\n","[EPOCH 44] TRAIN F1: 0.8730529595015577 TRAIN ACCURACY: 87.514, TRAIN AUROC: 0.957\n","[EPOCH 44] VALID F1: 0.7107611548556431 VALID ACCURACY: 71.859, VALID AUROC: 0.814\n","epoch45: running_loss=9.172764658927917\n","[EPOCH 45] TRAIN F1: 0.8645927455789337 TRAIN ACCURACY: 86.608, TRAIN AUROC: 0.954\n","[EPOCH 45] VALID F1: 0.710880829015544 VALID ACCURACY: 71.502, VALID AUROC: 0.809\n","epoch46: running_loss=9.06367065012455\n","[EPOCH 46] TRAIN F1: 0.866410697735999 TRAIN ACCURACY: 87.119, TRAIN AUROC: 0.958\n","[EPOCH 46] VALID F1: 0.7099521021820117 VALID ACCURACY: 72.165, VALID AUROC: 0.806\n","epoch47: running_loss=8.746151551604271\n","[EPOCH 47] TRAIN F1: 0.8743679502139247 TRAIN ACCURACY: 87.629, TRAIN AUROC: 0.960\n","[EPOCH 47] VALID F1: 0.7107438016528925 VALID ACCURACY: 71.399, VALID AUROC: 0.808\n","epoch48: running_loss=8.683976978063583\n","[EPOCH 48] TRAIN F1: 0.8696808510638298 TRAIN ACCURACY: 87.489, TRAIN AUROC: 0.959\n","[EPOCH 48] VALID F1: 0.7099521021820117 VALID ACCURACY: 72.165, VALID AUROC: 0.807\n","epoch49: running_loss=8.457845196127892\n","[EPOCH 49] TRAIN F1: 0.8722782793414763 TRAIN ACCURACY: 87.719, TRAIN AUROC: 0.961\n","[EPOCH 49] VALID F1: 0.7119914346895074 VALID ACCURACY: 72.523, VALID AUROC: 0.810\n","epoch50: running_loss=8.570282518863678\n","[EPOCH 50] TRAIN F1: 0.8821798643981068 TRAIN ACCURACY: 88.242, TRAIN AUROC: 0.963\n","[EPOCH 50] VALID F1: 0.7205731832139203 VALID ACCURACY: 72.114, VALID AUROC: 0.810\n","epoch51: running_loss=8.487393707036972\n","[EPOCH 51] TRAIN F1: 0.877817319098458 TRAIN ACCURACY: 88.165, TRAIN AUROC: 0.963\n","[EPOCH 51] VALID F1: 0.7069327731092436 VALID ACCURACY: 71.502, VALID AUROC: 0.805\n","epoch52: running_loss=8.39069464802742\n","[EPOCH 52] TRAIN F1: 0.8838244924688932 TRAIN ACCURACY: 88.676, TRAIN AUROC: 0.965\n","[EPOCH 52] VALID F1: 0.7130162049137481 VALID ACCURACY: 71.961, VALID AUROC: 0.806\n","epoch53: running_loss=8.368285611271858\n","[EPOCH 53] TRAIN F1: 0.8783054861202474 TRAIN ACCURACY: 88.191, TRAIN AUROC: 0.964\n","[EPOCH 53] VALID F1: 0.703957783641161 VALID ACCURACY: 71.348, VALID AUROC: 0.805\n","epoch54: running_loss=8.362975299358368\n","[EPOCH 54] TRAIN F1: 0.8777821163607966 TRAIN ACCURACY: 88.012, TRAIN AUROC: 0.962\n","[EPOCH 54] VALID F1: 0.7118644067796609 VALID ACCURACY: 72.217, VALID AUROC: 0.810\n","epoch55: running_loss=8.270796090364456\n","[EPOCH 55] TRAIN F1: 0.8807861391259373 TRAIN ACCURACY: 88.229, TRAIN AUROC: 0.965\n","[EPOCH 55] VALID F1: 0.7167095115681235 VALID ACCURACY: 71.859, VALID AUROC: 0.809\n","epoch56: running_loss=8.198388069868088\n","[EPOCH 56] TRAIN F1: 0.8831475409836065 TRAIN ACCURACY: 88.625, TRAIN AUROC: 0.966\n","[EPOCH 56] VALID F1: 0.7064464571124134 VALID ACCURACY: 71.859, VALID AUROC: 0.807\n","epoch57: running_loss=8.173758089542389\n","[EPOCH 57] TRAIN F1: 0.8832766291546715 TRAIN ACCURACY: 88.612, TRAIN AUROC: 0.965\n","[EPOCH 57] VALID F1: 0.7128608923884514 VALID ACCURACY: 72.063, VALID AUROC: 0.809\n","epoch58: running_loss=8.09006354212761\n","[EPOCH 58] TRAIN F1: 0.8858471760797343 TRAIN ACCURACY: 89.034, TRAIN AUROC: 0.968\n","[EPOCH 58] VALID F1: 0.7129032258064517 VALID ACCURACY: 72.727, VALID AUROC: 0.809\n","epoch59: running_loss=7.900197938084602\n","[EPOCH 59] TRAIN F1: 0.8884605499871499 TRAIN ACCURACY: 88.919, TRAIN AUROC: 0.967\n","[EPOCH 59] VALID F1: 0.7128916281458654 VALID ACCURACY: 71.450, VALID AUROC: 0.806\n","epoch60: running_loss=8.024090871214867\n","[EPOCH 60] TRAIN F1: 0.8879278388731002 TRAIN ACCURACY: 88.421, TRAIN AUROC: 0.967\n","[EPOCH 60] VALID F1: 0.7182266009852217 VALID ACCURACY: 70.787, VALID AUROC: 0.804\n","F1 on best model: 0.734457 (Epoch12)\n","(1958, 2)\n","\n","Start fold 3 =====================================\n","continuous_mean_std: \n","[[3.2695648e+01 1.1754196e+04]\n"," [1.2207630e+01 2.1678641e+04]]\n","\n","X_train shape: (7833, 5)\n","y_train shape: (7833,)\n","X_valid shape: (1958, 5)\n","y_valid shape: (1958,)\n","Pretraining begins!\n","Epoch: 0, Running Loss: 500.9923734664917\n","Epoch: 1, Running Loss: 356.8122339248657\n","Epoch: 2, Running Loss: 285.65810775756836\n","Epoch: 3, Running Loss: 230.18050861358643\n","Epoch: 4, Running Loss: 178.4138159751892\n","Epoch: 5, Running Loss: 130.01457142829895\n","Epoch: 6, Running Loss: 90.69034552574158\n","Epoch: 7, Running Loss: 63.19200539588928\n","Epoch: 8, Running Loss: 45.40504729747772\n","Epoch: 9, Running Loss: 33.32705932855606\n","Epoch: 10, Running Loss: 25.66109699010849\n","Epoch: 11, Running Loss: 20.642320811748505\n","Epoch: 12, Running Loss: 17.164611995220184\n","Epoch: 13, Running Loss: 14.190746396780014\n","Epoch: 14, Running Loss: 12.627057433128357\n","Epoch: 15, Running Loss: 11.38450077176094\n","Epoch: 16, Running Loss: 9.823358163237572\n","Epoch: 17, Running Loss: 8.878247648477554\n","Epoch: 18, Running Loss: 8.280551299452782\n","Epoch: 19, Running Loss: 7.494409695267677\n","Epoch: 20, Running Loss: 6.9545053988695145\n","Epoch: 21, Running Loss: 6.399380072951317\n","Epoch: 22, Running Loss: 6.156216770410538\n","Epoch: 23, Running Loss: 5.674890324473381\n","Epoch: 24, Running Loss: 5.31616485118866\n","Epoch: 25, Running Loss: 5.136462569236755\n","Epoch: 26, Running Loss: 4.850191235542297\n","Epoch: 27, Running Loss: 4.710859231650829\n","Epoch: 28, Running Loss: 4.52700512856245\n","Epoch: 29, Running Loss: 4.134240940213203\n","Epoch: 30, Running Loss: 4.083933047950268\n","Epoch: 31, Running Loss: 3.9363057538866997\n","Epoch: 32, Running Loss: 3.9272966384887695\n","Epoch: 33, Running Loss: 3.6699900180101395\n","Epoch: 34, Running Loss: 3.5471604838967323\n","Epoch: 35, Running Loss: 3.4512842297554016\n","Epoch: 36, Running Loss: 3.3781274780631065\n","Epoch: 37, Running Loss: 3.326331578195095\n","Epoch: 38, Running Loss: 3.1513516679406166\n","Epoch: 39, Running Loss: 3.0402018427848816\n","Epoch: 40, Running Loss: 2.9319152384996414\n","Epoch: 41, Running Loss: 2.8769114315509796\n","Epoch: 42, Running Loss: 2.8918319419026375\n","Epoch: 43, Running Loss: 2.801784075796604\n","Epoch: 44, Running Loss: 2.640883132815361\n","Epoch: 45, Running Loss: 2.636984884738922\n","Epoch: 46, Running Loss: 2.650514304637909\n","Epoch: 47, Running Loss: 2.554908737540245\n","Epoch: 48, Running Loss: 2.5505733266472816\n","Epoch: 49, Running Loss: 2.4355819411575794\n","Epoch: 50, Running Loss: 2.284868750721216\n","Epoch: 51, Running Loss: 2.3621175177395344\n","Epoch: 52, Running Loss: 2.224117036908865\n","Epoch: 53, Running Loss: 2.2814071103930473\n","Epoch: 54, Running Loss: 2.2455820739269257\n","Epoch: 55, Running Loss: 2.154833573848009\n","Epoch: 56, Running Loss: 2.0756135880947113\n","Epoch: 57, Running Loss: 2.0036631636321545\n","Epoch: 58, Running Loss: 2.0519889742136\n","Epoch: 59, Running Loss: 1.971304103732109\n","Epoch: 60, Running Loss: 1.9968554824590683\n","Epoch: 61, Running Loss: 1.8791962750256062\n","Epoch: 62, Running Loss: 1.8986942917108536\n","Epoch: 63, Running Loss: 1.8807925917208195\n","Epoch: 64, Running Loss: 1.8165645841509104\n","Epoch: 65, Running Loss: 1.7772703245282173\n","Epoch: 66, Running Loss: 1.79069509729743\n","Epoch: 67, Running Loss: 1.7353947646915913\n","Epoch: 68, Running Loss: 1.8060390539467335\n","Epoch: 69, Running Loss: 1.7393902577459812\n","Epoch: 70, Running Loss: 1.643017292022705\n","Epoch: 71, Running Loss: 1.7232261970639229\n","Epoch: 72, Running Loss: 1.6084967702627182\n","Epoch: 73, Running Loss: 1.5963141843676567\n","Epoch: 74, Running Loss: 1.7181765548884869\n","Epoch: 75, Running Loss: 1.6297366246581078\n","Epoch: 76, Running Loss: 1.5424637906253338\n","Epoch: 77, Running Loss: 1.5281945951282978\n","Epoch: 78, Running Loss: 1.474986869841814\n","Epoch: 79, Running Loss: 1.5436263158917427\n","Epoch: 80, Running Loss: 1.504438640549779\n","Epoch: 81, Running Loss: 1.420053819194436\n","Epoch: 82, Running Loss: 1.463808249682188\n","Epoch: 83, Running Loss: 1.4663019180297852\n","Epoch: 84, Running Loss: 1.4578419402241707\n","Epoch: 85, Running Loss: 1.359758798032999\n","Epoch: 86, Running Loss: 1.3249948434531689\n","Epoch: 87, Running Loss: 1.3624448850750923\n","Epoch: 88, Running Loss: 1.424886742606759\n","Epoch: 89, Running Loss: 1.3005454204976559\n","Epoch: 90, Running Loss: 1.4562071673572063\n","Epoch: 91, Running Loss: 1.3839688785374165\n","Epoch: 92, Running Loss: 1.220445841550827\n","Epoch: 93, Running Loss: 1.2572976276278496\n","Epoch: 94, Running Loss: 1.2934396173804998\n","Epoch: 95, Running Loss: 1.3088424913585186\n","Epoch: 96, Running Loss: 1.259011521935463\n","Epoch: 97, Running Loss: 1.2254902720451355\n","Epoch: 98, Running Loss: 1.2565935496240854\n","Epoch: 99, Running Loss: 1.1980697335675359\n","END OF PRETRAINING!\n","Training begins now.\n","epoch1: running_loss=20.076738595962524\n","[EPOCH 1] TRAIN F1: 0.6518375241779497 TRAIN ACCURACY: 67.828, TRAIN AUROC: 0.748\n","[EPOCH 1] VALID F1: 0.6604292790313704 VALID ACCURACY: 68.488, VALID AUROC: 0.763\n","epoch2: running_loss=17.96895444393158\n","[EPOCH 2] TRAIN F1: 0.7119579500657031 TRAIN ACCURACY: 72.016, TRAIN AUROC: 0.803\n","[EPOCH 2] VALID F1: 0.7251707829742511 VALID ACCURACY: 73.289, VALID AUROC: 0.808\n","epoch3: running_loss=16.20414799451828\n","[EPOCH 3] TRAIN F1: 0.7326519634211942 TRAIN ACCURACY: 74.620, TRAIN AUROC: 0.838\n","[EPOCH 3] VALID F1: 0.7322287546766435 VALID ACCURACY: 74.413, VALID AUROC: 0.832\n","epoch4: running_loss=15.196583032608032\n","[EPOCH 4] TRAIN F1: 0.7222304174657028 TRAIN ACCURACY: 75.961, TRAIN AUROC: 0.855\n","[EPOCH 4] VALID F1: 0.7235772357723578 VALID ACCURACY: 75.689, VALID AUROC: 0.841\n","epoch5: running_loss=14.67608693242073\n","[EPOCH 5] TRAIN F1: 0.7595772787318361 TRAIN ACCURACY: 76.765, TRAIN AUROC: 0.859\n","[EPOCH 5] VALID F1: 0.7475169890224778 VALID ACCURACY: 75.332, VALID AUROC: 0.840\n","epoch6: running_loss=14.297690778970718\n","[EPOCH 6] TRAIN F1: 0.7651202977535558 TRAIN ACCURACY: 77.442, TRAIN AUROC: 0.870\n","[EPOCH 6] VALID F1: 0.7522170057381324 VALID ACCURACY: 75.741, VALID AUROC: 0.842\n","epoch7: running_loss=14.055843085050583\n","[EPOCH 7] TRAIN F1: 0.7654789323939846 TRAIN ACCURACY: 77.901, TRAIN AUROC: 0.875\n","[EPOCH 7] VALID F1: 0.7498666666666666 VALID ACCURACY: 76.047, VALID AUROC: 0.843\n","epoch8: running_loss=13.870584428310394\n","[EPOCH 8] TRAIN F1: 0.7735899492114409 TRAIN ACCURACY: 78.374, TRAIN AUROC: 0.875\n","[EPOCH 8] VALID F1: 0.746190225959012 VALID ACCURACY: 75.332, VALID AUROC: 0.841\n","epoch9: running_loss=13.708331137895584\n","[EPOCH 9] TRAIN F1: 0.7641444183151196 TRAIN ACCURACY: 78.233, TRAIN AUROC: 0.878\n","[EPOCH 9] VALID F1: 0.7459634015069968 VALID ACCURACY: 75.894, VALID AUROC: 0.839\n","epoch10: running_loss=13.485345274209976\n","[EPOCH 10] TRAIN F1: 0.7772511848341233 TRAIN ACCURACY: 78.399, TRAIN AUROC: 0.884\n","[EPOCH 10] VALID F1: 0.7408552292632664 VALID ACCURACY: 74.311, VALID AUROC: 0.832\n","epoch11: running_loss=13.176390081644058\n","[EPOCH 11] TRAIN F1: 0.7655460972442649 TRAIN ACCURACY: 79.254, TRAIN AUROC: 0.893\n","[EPOCH 11] VALID F1: 0.7309417040358744 VALID ACCURACY: 75.485, VALID AUROC: 0.834\n","epoch12: running_loss=13.148944199085236\n","[EPOCH 12] TRAIN F1: 0.7905423457119959 TRAIN ACCURACY: 79.982, TRAIN AUROC: 0.894\n","[EPOCH 12] VALID F1: 0.7486910994764399 VALID ACCURACY: 75.485, VALID AUROC: 0.836\n","epoch13: running_loss=12.845159649848938\n","[EPOCH 13] TRAIN F1: 0.7935871743486973 TRAIN ACCURACY: 80.276, TRAIN AUROC: 0.898\n","[EPOCH 13] VALID F1: 0.7381076842655516 VALID ACCURACY: 74.413, VALID AUROC: 0.828\n","epoch14: running_loss=12.614592134952545\n","[EPOCH 14] TRAIN F1: 0.797363216875412 TRAIN ACCURACY: 80.378, TRAIN AUROC: 0.902\n","[EPOCH 14] VALID F1: 0.7443298969072166 VALID ACCURACY: 74.668, VALID AUROC: 0.829\n","epoch15: running_loss=12.39876613020897\n","[EPOCH 15] TRAIN F1: 0.8094686736137914 TRAIN ACCURACY: 81.093, TRAIN AUROC: 0.908\n","[EPOCH 15] VALID F1: 0.7467204843592332 VALID ACCURACY: 74.362, VALID AUROC: 0.828\n","epoch16: running_loss=12.174982905387878\n","[EPOCH 16] TRAIN F1: 0.8066313357793179 TRAIN ACCURACY: 81.833, TRAIN AUROC: 0.913\n","[EPOCH 16] VALID F1: 0.7281501340482575 VALID ACCURACY: 74.106, VALID AUROC: 0.824\n","epoch17: running_loss=12.152771323919296\n","[EPOCH 17] TRAIN F1: 0.8144153623569644 TRAIN ACCURACY: 81.986, TRAIN AUROC: 0.917\n","[EPOCH 17] VALID F1: 0.7387012987012987 VALID ACCURACY: 74.311, VALID AUROC: 0.825\n","epoch18: running_loss=11.951826214790344\n","[EPOCH 18] TRAIN F1: 0.8186204198722128 TRAIN ACCURACY: 82.242, TRAIN AUROC: 0.917\n","[EPOCH 18] VALID F1: 0.7508951406649615 VALID ACCURACY: 75.128, VALID AUROC: 0.828\n","epoch19: running_loss=11.784184575080872\n","[EPOCH 19] TRAIN F1: 0.8120832766362771 TRAIN ACCURACY: 82.369, TRAIN AUROC: 0.920\n","[EPOCH 19] VALID F1: 0.7263948497854077 VALID ACCURACY: 73.953, VALID AUROC: 0.818\n","epoch20: running_loss=11.635836511850357\n","[EPOCH 20] TRAIN F1: 0.8049020988871672 TRAIN ACCURACY: 82.318, TRAIN AUROC: 0.923\n","[EPOCH 20] VALID F1: 0.728579325594251 VALID ACCURACY: 74.923, VALID AUROC: 0.825\n","epoch21: running_loss=11.343666940927505\n","[EPOCH 21] TRAIN F1: 0.8163988014165078 TRAIN ACCURACY: 82.791, TRAIN AUROC: 0.926\n","[EPOCH 21] VALID F1: 0.7301927194860813 VALID ACCURACY: 74.259, VALID AUROC: 0.823\n","epoch22: running_loss=11.275515049695969\n","[EPOCH 22] TRAIN F1: 0.8226464779460172 TRAIN ACCURACY: 82.804, TRAIN AUROC: 0.928\n","[EPOCH 22] VALID F1: 0.7231168831168832 VALID ACCURACY: 72.778, VALID AUROC: 0.818\n","epoch23: running_loss=11.021000385284424\n","[EPOCH 23] TRAIN F1: 0.8378553810203816 TRAIN ACCURACY: 84.055, TRAIN AUROC: 0.932\n","[EPOCH 23] VALID F1: 0.7320061255742727 VALID ACCURACY: 73.187, VALID AUROC: 0.817\n","epoch24: running_loss=11.002422243356705\n","[EPOCH 24] TRAIN F1: 0.8352805238156373 TRAIN ACCURACY: 83.621, TRAIN AUROC: 0.931\n","[EPOCH 24] VALID F1: 0.730827067669173 VALID ACCURACY: 72.574, VALID AUROC: 0.817\n","epoch25: running_loss=10.789813160896301\n","[EPOCH 25] TRAIN F1: 0.8337099561345208 TRAIN ACCURACY: 84.029, TRAIN AUROC: 0.936\n","[EPOCH 25] VALID F1: 0.7312729177579885 VALID ACCURACY: 73.800, VALID AUROC: 0.820\n","epoch26: running_loss=10.536356002092361\n","[EPOCH 26] TRAIN F1: 0.8327497980070024 TRAIN ACCURACY: 84.144, TRAIN AUROC: 0.937\n","[EPOCH 26] VALID F1: 0.7239003709591945 VALID ACCURACY: 73.391, VALID AUROC: 0.814\n","epoch27: running_loss=10.407903134822845\n","[EPOCH 27] TRAIN F1: 0.8286152558917864 TRAIN ACCURACY: 84.310, TRAIN AUROC: 0.940\n","[EPOCH 27] VALID F1: 0.7196928140427865 VALID ACCURACY: 73.902, VALID AUROC: 0.815\n","epoch28: running_loss=10.37986221909523\n","[EPOCH 28] TRAIN F1: 0.8360049321824907 TRAIN ACCURACY: 84.718, TRAIN AUROC: 0.943\n","[EPOCH 28] VALID F1: 0.7115697990222705 VALID ACCURACY: 72.880, VALID AUROC: 0.809\n","epoch29: running_loss=10.313722223043442\n","[EPOCH 29] TRAIN F1: 0.8480367159612443 TRAIN ACCURACY: 84.782, TRAIN AUROC: 0.942\n","[EPOCH 29] VALID F1: 0.7337038908539666 VALID ACCURACY: 73.085, VALID AUROC: 0.817\n","epoch30: running_loss=10.274971902370453\n","[EPOCH 30] TRAIN F1: 0.8366500829187397 TRAIN ACCURACY: 84.910, TRAIN AUROC: 0.944\n","[EPOCH 30] VALID F1: 0.7166938553561718 VALID ACCURACY: 73.391, VALID AUROC: 0.815\n","epoch31: running_loss=9.904187381267548\n","[EPOCH 31] TRAIN F1: 0.8421341379783295 TRAIN ACCURACY: 85.306, TRAIN AUROC: 0.945\n","[EPOCH 31] VALID F1: 0.7217720151269584 VALID ACCURACY: 73.698, VALID AUROC: 0.813\n","epoch32: running_loss=10.035049065947533\n","[EPOCH 32] TRAIN F1: 0.8541803386271163 TRAIN ACCURACY: 85.816, TRAIN AUROC: 0.947\n","[EPOCH 32] VALID F1: 0.7143603133159269 VALID ACCURACY: 72.063, VALID AUROC: 0.806\n","epoch33: running_loss=9.807918548583984\n","[EPOCH 33] TRAIN F1: 0.8562835098731528 TRAIN ACCURACY: 85.970, TRAIN AUROC: 0.948\n","[EPOCH 33] VALID F1: 0.7187985499741067 VALID ACCURACY: 72.268, VALID AUROC: 0.809\n","epoch34: running_loss=9.680265873670578\n","[EPOCH 34] TRAIN F1: 0.8575462012320328 TRAIN ACCURACY: 85.829, TRAIN AUROC: 0.949\n","[EPOCH 34] VALID F1: 0.7311608961303462 VALID ACCURACY: 73.034, VALID AUROC: 0.814\n","epoch35: running_loss=9.732401385903358\n","[EPOCH 35] TRAIN F1: 0.8583081173529798 TRAIN ACCURACY: 86.250, TRAIN AUROC: 0.951\n","[EPOCH 35] VALID F1: 0.719626168224299 VALID ACCURACY: 72.421, VALID AUROC: 0.808\n","epoch36: running_loss=9.434842705726624\n","[EPOCH 36] TRAIN F1: 0.8607428796429978 TRAIN ACCURACY: 86.455, TRAIN AUROC: 0.952\n","[EPOCH 36] VALID F1: 0.707165109034268 VALID ACCURACY: 71.195, VALID AUROC: 0.803\n","epoch37: running_loss=9.344799637794495\n","[EPOCH 37] TRAIN F1: 0.8658505483295078 TRAIN ACCURACY: 86.570, TRAIN AUROC: 0.953\n","[EPOCH 37] VALID F1: 0.718079673135853 VALID ACCURACY: 71.808, VALID AUROC: 0.806\n","epoch38: running_loss=9.326387241482735\n","[EPOCH 38] TRAIN F1: 0.8643892339544514 TRAIN ACCURACY: 86.621, TRAIN AUROC: 0.954\n","[EPOCH 38] VALID F1: 0.7207859358841779 VALID ACCURACY: 72.421, VALID AUROC: 0.808\n","epoch39: running_loss=9.328360676765442\n","[EPOCH 39] TRAIN F1: 0.867801047120419 TRAIN ACCURACY: 87.106, TRAIN AUROC: 0.955\n","[EPOCH 39] VALID F1: 0.7067901234567902 VALID ACCURACY: 70.889, VALID AUROC: 0.798\n","epoch40: running_loss=9.186889380216599\n","[EPOCH 40] TRAIN F1: 0.8708932238193019 TRAIN ACCURACY: 87.157, TRAIN AUROC: 0.956\n","[EPOCH 40] VALID F1: 0.7120524457892082 VALID ACCURACY: 70.838, VALID AUROC: 0.801\n","epoch41: running_loss=9.111320570111275\n","[EPOCH 41] TRAIN F1: 0.8661396574440051 TRAIN ACCURACY: 87.029, TRAIN AUROC: 0.957\n","[EPOCH 41] VALID F1: 0.7188796680497925 VALID ACCURACY: 72.319, VALID AUROC: 0.805\n","epoch42: running_loss=8.966718256473541\n","[EPOCH 42] TRAIN F1: 0.8641711229946524 TRAIN ACCURACY: 87.029, TRAIN AUROC: 0.957\n","[EPOCH 42] VALID F1: 0.7164650184113623 VALID ACCURACY: 72.472, VALID AUROC: 0.803\n","epoch43: running_loss=8.983321517705917\n","[EPOCH 43] TRAIN F1: 0.8632860040567951 TRAIN ACCURACY: 87.093, TRAIN AUROC: 0.958\n","[EPOCH 43] VALID F1: 0.704812834224599 VALID ACCURACY: 71.808, VALID AUROC: 0.804\n","epoch44: running_loss=8.85621128976345\n","[EPOCH 44] TRAIN F1: 0.8765120967741935 TRAIN ACCURACY: 87.489, TRAIN AUROC: 0.959\n","[EPOCH 44] VALID F1: 0.7188118811881189 VALID ACCURACY: 70.991, VALID AUROC: 0.803\n","epoch45: running_loss=8.868135690689087\n","[EPOCH 45] TRAIN F1: 0.8778139232270658 TRAIN ACCURACY: 88.012, TRAIN AUROC: 0.961\n","[EPOCH 45] VALID F1: 0.7077555213148432 VALID ACCURACY: 70.940, VALID AUROC: 0.801\n","epoch46: running_loss=8.557394459843636\n","[EPOCH 46] TRAIN F1: 0.8700882117080995 TRAIN ACCURACY: 87.591, TRAIN AUROC: 0.961\n","[EPOCH 46] VALID F1: 0.7158671586715867 VALID ACCURACY: 72.472, VALID AUROC: 0.797\n","epoch47: running_loss=8.6398254185915\n","[EPOCH 47] TRAIN F1: 0.8755525787006028 TRAIN ACCURACY: 88.140, TRAIN AUROC: 0.963\n","[EPOCH 47] VALID F1: 0.7074973600844773 VALID ACCURACY: 71.706, VALID AUROC: 0.799\n","epoch48: running_loss=8.445150002837181\n","[EPOCH 48] TRAIN F1: 0.8789144050104385 TRAIN ACCURACY: 88.153, TRAIN AUROC: 0.963\n","[EPOCH 48] VALID F1: 0.7098445595854923 VALID ACCURACY: 71.399, VALID AUROC: 0.799\n","epoch49: running_loss=8.512941360473633\n","[EPOCH 49] TRAIN F1: 0.8768988999476166 TRAIN ACCURACY: 87.999, TRAIN AUROC: 0.962\n","[EPOCH 49] VALID F1: 0.7084412221646815 VALID ACCURACY: 71.246, VALID AUROC: 0.797\n","epoch50: running_loss=8.390040710568428\n","[EPOCH 50] TRAIN F1: 0.8801771294607971 TRAIN ACCURACY: 88.255, TRAIN AUROC: 0.963\n","[EPOCH 50] VALID F1: 0.7078651685393259 VALID ACCURACY: 70.787, VALID AUROC: 0.795\n","epoch51: running_loss=8.439836531877518\n","[EPOCH 51] TRAIN F1: 0.8824672800311002 TRAIN ACCURACY: 88.421, TRAIN AUROC: 0.964\n","[EPOCH 51] VALID F1: 0.7120204603580563 VALID ACCURACY: 71.246, VALID AUROC: 0.799\n","epoch52: running_loss=8.328183978796005\n","[EPOCH 52] TRAIN F1: 0.8845604466952345 TRAIN ACCURACY: 88.651, TRAIN AUROC: 0.965\n","[EPOCH 52] VALID F1: 0.7087576374745418 VALID ACCURACY: 70.787, VALID AUROC: 0.792\n","epoch53: running_loss=8.033454224467278\n","[EPOCH 53] TRAIN F1: 0.8871220020855056 TRAIN ACCURACY: 88.944, TRAIN AUROC: 0.967\n","[EPOCH 53] VALID F1: 0.7038363171355498 VALID ACCURACY: 70.429, VALID AUROC: 0.795\n","epoch54: running_loss=8.03177098929882\n","[EPOCH 54] TRAIN F1: 0.8845484949832777 TRAIN ACCURACY: 88.983, TRAIN AUROC: 0.968\n","[EPOCH 54] VALID F1: 0.7061288632792037 VALID ACCURACY: 71.348, VALID AUROC: 0.798\n","epoch55: running_loss=8.083872109651566\n","[EPOCH 55] TRAIN F1: 0.8842105263157896 TRAIN ACCURACY: 88.765, TRAIN AUROC: 0.968\n","[EPOCH 55] VALID F1: 0.7053984575835476 VALID ACCURACY: 70.735, VALID AUROC: 0.794\n","epoch56: running_loss=8.080468639731407\n","[EPOCH 56] TRAIN F1: 0.8822810590631366 TRAIN ACCURACY: 88.931, TRAIN AUROC: 0.969\n","[EPOCH 56] VALID F1: 0.7016604177825388 VALID ACCURACY: 71.553, VALID AUROC: 0.796\n","epoch57: running_loss=7.948299095034599\n","[EPOCH 57] TRAIN F1: 0.8799674487996746 TRAIN ACCURACY: 88.702, TRAIN AUROC: 0.969\n","[EPOCH 57] VALID F1: 0.7070815450643777 VALID ACCURACY: 72.114, VALID AUROC: 0.798\n","epoch58: running_loss=7.764805942773819\n","[EPOCH 58] TRAIN F1: 0.8873862158647594 TRAIN ACCURACY: 88.944, TRAIN AUROC: 0.968\n","[EPOCH 58] VALID F1: 0.7057623661397247 VALID ACCURACY: 70.531, VALID AUROC: 0.795\n","epoch59: running_loss=7.88495908677578\n","[EPOCH 59] TRAIN F1: 0.8888592394929953 TRAIN ACCURACY: 89.366, TRAIN AUROC: 0.971\n","[EPOCH 59] VALID F1: 0.7013262599469495 VALID ACCURACY: 71.246, VALID AUROC: 0.797\n","epoch60: running_loss=7.6283766478300095\n","[EPOCH 60] TRAIN F1: 0.8951084863268713 TRAIN ACCURACY: 89.570, TRAIN AUROC: 0.971\n","[EPOCH 60] VALID F1: 0.7138523761375126 VALID ACCURACY: 71.093, VALID AUROC: 0.798\n","F1 on best model: 0.752217 (Epoch5)\n","(1958, 2)\n","\n","Start fold 4 =====================================\n","continuous_mean_std: \n","[[3.2642792e+01 1.1703896e+04]\n"," [1.2096566e+01 2.1424482e+04]]\n","\n","X_train shape: (7833, 5)\n","y_train shape: (7833,)\n","X_valid shape: (1958, 5)\n","y_valid shape: (1958,)\n","Pretraining begins!\n","Epoch: 0, Running Loss: 507.38504791259766\n","Epoch: 1, Running Loss: 354.2146854400635\n","Epoch: 2, Running Loss: 281.67530250549316\n","Epoch: 3, Running Loss: 221.41761541366577\n","Epoch: 4, Running Loss: 168.02262496948242\n","Epoch: 5, Running Loss: 122.257497549057\n","Epoch: 6, Running Loss: 86.88537907600403\n","Epoch: 7, Running Loss: 62.81726801395416\n","Epoch: 8, Running Loss: 44.588364005088806\n","Epoch: 9, Running Loss: 33.15769696235657\n","Epoch: 10, Running Loss: 24.9766725897789\n","Epoch: 11, Running Loss: 20.17573571205139\n","Epoch: 12, Running Loss: 16.793457210063934\n","Epoch: 13, Running Loss: 14.716241359710693\n","Epoch: 14, Running Loss: 12.567539036273956\n","Epoch: 15, Running Loss: 11.386183977127075\n","Epoch: 16, Running Loss: 10.016628682613373\n","Epoch: 17, Running Loss: 9.320171147584915\n","Epoch: 18, Running Loss: 8.568339005112648\n","Epoch: 19, Running Loss: 8.008549645543098\n","Epoch: 20, Running Loss: 7.229740396142006\n","Epoch: 21, Running Loss: 6.751344472169876\n","Epoch: 22, Running Loss: 6.377525880932808\n","Epoch: 23, Running Loss: 5.99419154971838\n","Epoch: 24, Running Loss: 5.65137206017971\n","Epoch: 25, Running Loss: 5.338863372802734\n","Epoch: 26, Running Loss: 5.284495040774345\n","Epoch: 27, Running Loss: 4.879534438252449\n","Epoch: 28, Running Loss: 4.666606493294239\n","Epoch: 29, Running Loss: 4.490648791193962\n","Epoch: 30, Running Loss: 4.4204845651984215\n","Epoch: 31, Running Loss: 4.171465314924717\n","Epoch: 32, Running Loss: 4.025588005781174\n","Epoch: 33, Running Loss: 3.9769573509693146\n","Epoch: 34, Running Loss: 3.880553975701332\n","Epoch: 35, Running Loss: 3.551491290330887\n","Epoch: 36, Running Loss: 3.4164318591356277\n","Epoch: 37, Running Loss: 3.201432980597019\n","Epoch: 38, Running Loss: 3.2070873454213142\n","Epoch: 39, Running Loss: 2.9545992016792297\n","Epoch: 40, Running Loss: 3.0288277342915535\n","Epoch: 41, Running Loss: 3.0658830404281616\n","Epoch: 42, Running Loss: 3.00516626983881\n","Epoch: 43, Running Loss: 2.76642819494009\n","Epoch: 44, Running Loss: 2.6275814473629\n","Epoch: 45, Running Loss: 2.7219040915369987\n","Epoch: 46, Running Loss: 2.585844613611698\n","Epoch: 47, Running Loss: 2.4227505177259445\n","Epoch: 48, Running Loss: 2.4152305647730827\n","Epoch: 49, Running Loss: 2.354462929069996\n","Epoch: 50, Running Loss: 2.389144454151392\n","Epoch: 51, Running Loss: 2.3838274404406548\n","Epoch: 52, Running Loss: 2.295855037868023\n","Epoch: 53, Running Loss: 2.3223785795271397\n","Epoch: 54, Running Loss: 2.2326737083494663\n","Epoch: 55, Running Loss: 2.0743164122104645\n","Epoch: 56, Running Loss: 2.1847919896245003\n","Epoch: 57, Running Loss: 2.166745439171791\n","Epoch: 58, Running Loss: 2.065210711210966\n","Epoch: 59, Running Loss: 2.219522647559643\n","Epoch: 60, Running Loss: 1.97657972574234\n","Epoch: 61, Running Loss: 2.0068622790277004\n","Epoch: 62, Running Loss: 1.8668137975037098\n","Epoch: 63, Running Loss: 1.9353793561458588\n","Epoch: 64, Running Loss: 1.782213982194662\n","Epoch: 65, Running Loss: 1.8801660425961018\n","Epoch: 66, Running Loss: 1.8432840928435326\n","Epoch: 67, Running Loss: 1.7633526511490345\n","Epoch: 68, Running Loss: 1.7768394872546196\n","Epoch: 69, Running Loss: 1.6364533379673958\n","Epoch: 70, Running Loss: 1.699502620846033\n","Epoch: 71, Running Loss: 1.5771908778697252\n","Epoch: 72, Running Loss: 1.675381999462843\n","Epoch: 73, Running Loss: 1.555787205696106\n","Epoch: 74, Running Loss: 1.5801923722028732\n","Epoch: 75, Running Loss: 1.524919331073761\n","Epoch: 76, Running Loss: 1.5779081583023071\n","Epoch: 77, Running Loss: 1.5242993421852589\n","Epoch: 78, Running Loss: 1.4989817291498184\n","Epoch: 79, Running Loss: 1.5655027441680431\n","Epoch: 80, Running Loss: 1.4964976236224174\n","Epoch: 81, Running Loss: 1.4784287214279175\n","Epoch: 82, Running Loss: 1.4116434454917908\n","Epoch: 83, Running Loss: 1.4556686133146286\n","Epoch: 84, Running Loss: 1.4932231418788433\n","Epoch: 85, Running Loss: 1.3471477217972279\n","Epoch: 86, Running Loss: 1.275948591530323\n","Epoch: 87, Running Loss: 1.3726590648293495\n","Epoch: 88, Running Loss: 1.3433689400553703\n","Epoch: 89, Running Loss: 1.4024866111576557\n","Epoch: 90, Running Loss: 1.2277081925421953\n","Epoch: 91, Running Loss: 1.2746005672961473\n","Epoch: 92, Running Loss: 1.2815606705844402\n","Epoch: 93, Running Loss: 1.333784718066454\n","Epoch: 94, Running Loss: 1.2727913465350866\n","Epoch: 95, Running Loss: 1.2541364971548319\n","Epoch: 96, Running Loss: 1.1675680540502071\n","Epoch: 97, Running Loss: 1.1655119620263577\n","Epoch: 98, Running Loss: 1.178540924564004\n","Epoch: 99, Running Loss: 1.2384948823601007\n","END OF PRETRAINING!\n","Training begins now.\n","epoch1: running_loss=19.9811789393425\n","[EPOCH 1] TRAIN F1: 0.6918705213738572 TRAIN ACCURACY: 68.160, TRAIN AUROC: 0.753\n","[EPOCH 1] VALID F1: 0.689965052421368 VALID ACCURACY: 68.284, VALID AUROC: 0.745\n","epoch2: running_loss=17.892121851444244\n","[EPOCH 2] TRAIN F1: 0.7147012162876784 TRAIN ACCURACY: 72.450, TRAIN AUROC: 0.802\n","[EPOCH 2] VALID F1: 0.6941617568291377 VALID ACCURACY: 70.838, VALID AUROC: 0.790\n","epoch3: running_loss=16.24571606516838\n","[EPOCH 3] TRAIN F1: 0.7458492975734354 TRAIN ACCURACY: 74.595, TRAIN AUROC: 0.836\n","[EPOCH 3] VALID F1: 0.737874097007224 VALID ACCURACY: 74.055, VALID AUROC: 0.821\n","epoch4: running_loss=15.38018935918808\n","[EPOCH 4] TRAIN F1: 0.7267958618679878 TRAIN ACCURACY: 76.063, TRAIN AUROC: 0.853\n","[EPOCH 4] VALID F1: 0.7097532314923619 VALID ACCURACY: 74.770, VALID AUROC: 0.833\n","epoch5: running_loss=14.776327162981033\n","[EPOCH 5] TRAIN F1: 0.7553235334523973 TRAIN ACCURACY: 77.263, TRAIN AUROC: 0.864\n","[EPOCH 5] VALID F1: 0.7361419068736141 VALID ACCURACY: 75.689, VALID AUROC: 0.841\n","epoch6: running_loss=14.360182881355286\n","[EPOCH 6] TRAIN F1: 0.7707743761255467 TRAIN ACCURACY: 77.250, TRAIN AUROC: 0.867\n","[EPOCH 6] VALID F1: 0.7501287995878413 VALID ACCURACY: 75.230, VALID AUROC: 0.838\n","epoch7: running_loss=14.325851678848267\n","[EPOCH 7] TRAIN F1: 0.7756985388361959 TRAIN ACCURACY: 77.659, TRAIN AUROC: 0.870\n","[EPOCH 7] VALID F1: 0.732612055641422 VALID ACCURACY: 73.493, VALID AUROC: 0.831\n","epoch8: running_loss=13.828550696372986\n","[EPOCH 8] TRAIN F1: 0.7761074896900358 TRAIN ACCURACY: 78.514, TRAIN AUROC: 0.878\n","[EPOCH 8] VALID F1: 0.7489270386266094 VALID ACCURACY: 76.098, VALID AUROC: 0.840\n","epoch9: running_loss=13.675276905298233\n","[EPOCH 9] TRAIN F1: 0.7883933096806893 TRAIN ACCURACY: 78.680, TRAIN AUROC: 0.883\n","[EPOCH 9] VALID F1: 0.758130081300813 VALID ACCURACY: 75.689, VALID AUROC: 0.839\n","epoch10: running_loss=13.615020900964737\n","[EPOCH 10] TRAIN F1: 0.7695120236253692 TRAIN ACCURACY: 79.076, TRAIN AUROC: 0.889\n","[EPOCH 10] VALID F1: 0.7231638418079097 VALID ACCURACY: 74.974, VALID AUROC: 0.836\n","epoch11: running_loss=13.397435933351517\n","[EPOCH 11] TRAIN F1: 0.7824684054853456 TRAIN ACCURACY: 79.344, TRAIN AUROC: 0.890\n","[EPOCH 11] VALID F1: 0.736501079913607 VALID ACCURACY: 75.077, VALID AUROC: 0.836\n","epoch12: running_loss=13.143181592226028\n","[EPOCH 12] TRAIN F1: 0.7756556442417332 TRAIN ACCURACY: 79.906, TRAIN AUROC: 0.895\n","[EPOCH 12] VALID F1: 0.7150259067357514 VALID ACCURACY: 74.719, VALID AUROC: 0.836\n","epoch13: running_loss=13.036985874176025\n","[EPOCH 13] TRAIN F1: 0.7975671030014545 TRAIN ACCURACY: 80.454, TRAIN AUROC: 0.900\n","[EPOCH 13] VALID F1: 0.7433155080213905 VALID ACCURACY: 75.485, VALID AUROC: 0.835\n","epoch14: running_loss=12.779887676239014\n","[EPOCH 14] TRAIN F1: 0.7969696969696969 TRAIN ACCURACY: 81.182, TRAIN AUROC: 0.905\n","[EPOCH 14] VALID F1: 0.7331118493909191 VALID ACCURACY: 75.383, VALID AUROC: 0.834\n","epoch15: running_loss=12.553857266902924\n","[EPOCH 15] TRAIN F1: 0.7999999999999999 TRAIN ACCURACY: 81.016, TRAIN AUROC: 0.905\n","[EPOCH 15] VALID F1: 0.7369553523399677 VALID ACCURACY: 75.026, VALID AUROC: 0.826\n","epoch16: running_loss=12.314286947250366\n","[EPOCH 16] TRAIN F1: 0.8078656288406391 TRAIN ACCURACY: 82.038, TRAIN AUROC: 0.912\n","[EPOCH 16] VALID F1: 0.7271727172717272 VALID ACCURACY: 74.668, VALID AUROC: 0.832\n","epoch17: running_loss=12.085371792316437\n","[EPOCH 17] TRAIN F1: 0.8183481442760063 TRAIN ACCURACY: 82.255, TRAIN AUROC: 0.915\n","[EPOCH 17] VALID F1: 0.7471022128556375 VALID ACCURACY: 75.485, VALID AUROC: 0.837\n","epoch18: running_loss=11.947975516319275\n","[EPOCH 18] TRAIN F1: 0.8091954022988506 TRAIN ACCURACY: 81.986, TRAIN AUROC: 0.915\n","[EPOCH 18] VALID F1: 0.7344262295081968 VALID ACCURACY: 75.179, VALID AUROC: 0.831\n","epoch19: running_loss=11.821724742650986\n","[EPOCH 19] TRAIN F1: 0.8140360458765701 TRAIN ACCURACY: 82.612, TRAIN AUROC: 0.919\n","[EPOCH 19] VALID F1: 0.7240811848601206 VALID ACCURACY: 74.311, VALID AUROC: 0.826\n","epoch20: running_loss=11.650254517793655\n","[EPOCH 20] TRAIN F1: 0.8259358288770055 TRAIN ACCURACY: 83.378, TRAIN AUROC: 0.925\n","[EPOCH 20] VALID F1: 0.7371829465731246 VALID ACCURACY: 75.128, VALID AUROC: 0.828\n","epoch21: running_loss=11.52887961268425\n","[EPOCH 21] TRAIN F1: 0.8244254409406734 TRAIN ACCURACY: 83.225, TRAIN AUROC: 0.928\n","[EPOCH 21] VALID F1: 0.7317333333333333 VALID ACCURACY: 74.311, VALID AUROC: 0.825\n","epoch22: running_loss=11.329166650772095\n","[EPOCH 22] TRAIN F1: 0.8273864384463463 TRAIN ACCURACY: 83.263, TRAIN AUROC: 0.927\n","[EPOCH 22] VALID F1: 0.7286166842661036 VALID ACCURACY: 73.749, VALID AUROC: 0.826\n","epoch23: running_loss=11.21055492758751\n","[EPOCH 23] TRAIN F1: 0.8285215523029408 TRAIN ACCURACY: 83.697, TRAIN AUROC: 0.931\n","[EPOCH 23] VALID F1: 0.7176151761517616 VALID ACCURACY: 73.391, VALID AUROC: 0.820\n","epoch24: running_loss=11.064673006534576\n","[EPOCH 24] TRAIN F1: 0.8286689419795221 TRAIN ACCURACY: 83.978, TRAIN AUROC: 0.933\n","[EPOCH 24] VALID F1: 0.7134955752212391 VALID ACCURACY: 73.544, VALID AUROC: 0.819\n","epoch25: running_loss=10.878859013319016\n","[EPOCH 25] TRAIN F1: 0.8208011243851019 TRAIN ACCURACY: 83.723, TRAIN AUROC: 0.933\n","[EPOCH 25] VALID F1: 0.7084038353073887 VALID ACCURACY: 73.596, VALID AUROC: 0.823\n","epoch26: running_loss=10.810145795345306\n","[EPOCH 26] TRAIN F1: 0.8355448331322879 TRAIN ACCURACY: 84.336, TRAIN AUROC: 0.936\n","[EPOCH 26] VALID F1: 0.7284413497589717 VALID ACCURACY: 74.106, VALID AUROC: 0.822\n","epoch27: running_loss=10.514103323221207\n","[EPOCH 27] TRAIN F1: 0.8311939268461007 TRAIN ACCURACY: 84.387, TRAIN AUROC: 0.938\n","[EPOCH 27] VALID F1: 0.7046223224351748 VALID ACCURACY: 73.238, VALID AUROC: 0.816\n","epoch28: running_loss=10.583250164985657\n","[EPOCH 28] TRAIN F1: 0.8379478827361564 TRAIN ACCURACY: 84.757, TRAIN AUROC: 0.941\n","[EPOCH 28] VALID F1: 0.7136659436008677 VALID ACCURACY: 73.034, VALID AUROC: 0.818\n","epoch29: running_loss=10.408784538507462\n","[EPOCH 29] TRAIN F1: 0.8475205515778308 TRAIN ACCURACY: 85.319, TRAIN AUROC: 0.942\n","[EPOCH 29] VALID F1: 0.7295864262990457 VALID ACCURACY: 73.953, VALID AUROC: 0.820\n","epoch30: running_loss=10.332039505243301\n","[EPOCH 30] TRAIN F1: 0.8482541349435548 TRAIN ACCURACY: 85.242, TRAIN AUROC: 0.943\n","[EPOCH 30] VALID F1: 0.7288842544316998 VALID ACCURACY: 73.442, VALID AUROC: 0.820\n","epoch31: running_loss=10.108495563268661\n","[EPOCH 31] TRAIN F1: 0.8473874806001034 TRAIN ACCURACY: 84.936, TRAIN AUROC: 0.942\n","[EPOCH 31] VALID F1: 0.7224806201550389 VALID ACCURACY: 72.574, VALID AUROC: 0.811\n","epoch32: running_loss=10.158127754926682\n","[EPOCH 32] TRAIN F1: 0.8443364385041177 TRAIN ACCURACY: 85.280, TRAIN AUROC: 0.944\n","[EPOCH 32] VALID F1: 0.7107709130672499 VALID ACCURACY: 72.983, VALID AUROC: 0.813\n","epoch33: running_loss=9.989908963441849\n","[EPOCH 33] TRAIN F1: 0.8568034842285864 TRAIN ACCURACY: 86.148, TRAIN AUROC: 0.948\n","[EPOCH 33] VALID F1: 0.7271767810026385 VALID ACCURACY: 73.596, VALID AUROC: 0.815\n","epoch34: running_loss=9.890976548194885\n","[EPOCH 34] TRAIN F1: 0.8520551613335118 TRAIN ACCURACY: 85.893, TRAIN AUROC: 0.947\n","[EPOCH 34] VALID F1: 0.7138994050838292 VALID ACCURACY: 72.983, VALID AUROC: 0.813\n","epoch35: running_loss=9.806017696857452\n","[EPOCH 35] TRAIN F1: 0.8528190705772064 TRAIN ACCURACY: 85.970, TRAIN AUROC: 0.950\n","[EPOCH 35] VALID F1: 0.7101293103448275 VALID ACCURACY: 72.523, VALID AUROC: 0.808\n","epoch36: running_loss=9.686659455299377\n","[EPOCH 36] TRAIN F1: 0.858661825726141 TRAIN ACCURACY: 86.085, TRAIN AUROC: 0.951\n","[EPOCH 36] VALID F1: 0.7177334732423925 VALID ACCURACY: 72.523, VALID AUROC: 0.803\n","epoch37: running_loss=9.572786062955856\n","[EPOCH 37] TRAIN F1: 0.8589135021097046 TRAIN ACCURACY: 86.340, TRAIN AUROC: 0.951\n","[EPOCH 37] VALID F1: 0.7145118733509236 VALID ACCURACY: 72.370, VALID AUROC: 0.809\n","epoch38: running_loss=9.469366431236267\n","[EPOCH 38] TRAIN F1: 0.8475524475524475 TRAIN ACCURACY: 86.085, TRAIN AUROC: 0.953\n","[EPOCH 38] VALID F1: 0.6902050113895216 VALID ACCURACY: 72.217, VALID AUROC: 0.804\n","epoch39: running_loss=9.437512248754501\n","[EPOCH 39] TRAIN F1: 0.8599869024230518 TRAIN ACCURACY: 86.353, TRAIN AUROC: 0.953\n","[EPOCH 39] VALID F1: 0.7143614202437732 VALID ACCURACY: 72.472, VALID AUROC: 0.805\n","epoch40: running_loss=9.194182366132736\n","[EPOCH 40] TRAIN F1: 0.8631084431684718 TRAIN ACCURACY: 86.608, TRAIN AUROC: 0.954\n","[EPOCH 40] VALID F1: 0.7259337190952131 VALID ACCURACY: 73.391, VALID AUROC: 0.812\n","epoch41: running_loss=9.145581528544426\n","[EPOCH 41] TRAIN F1: 0.8607931860527016 TRAIN ACCURACY: 86.646, TRAIN AUROC: 0.954\n","[EPOCH 41] VALID F1: 0.7108498129342598 VALID ACCURACY: 72.370, VALID AUROC: 0.804\n","epoch42: running_loss=9.256345748901367\n","[EPOCH 42] TRAIN F1: 0.8659552316501823 TRAIN ACCURACY: 86.851, TRAIN AUROC: 0.956\n","[EPOCH 42] VALID F1: 0.7277486910994765 VALID ACCURACY: 73.442, VALID AUROC: 0.810\n","epoch43: running_loss=9.092067286372185\n","[EPOCH 43] TRAIN F1: 0.868293991416309 TRAIN ACCURACY: 87.463, TRAIN AUROC: 0.957\n","[EPOCH 43] VALID F1: 0.7063875469672571 VALID ACCURACY: 72.063, VALID AUROC: 0.805\n","epoch44: running_loss=9.02345722913742\n","[EPOCH 44] TRAIN F1: 0.8675907590759074 TRAIN ACCURACY: 87.195, TRAIN AUROC: 0.957\n","[EPOCH 44] VALID F1: 0.7129237288135593 VALID ACCURACY: 72.319, VALID AUROC: 0.807\n","epoch45: running_loss=8.83656607568264\n","[EPOCH 45] TRAIN F1: 0.8664521319388575 TRAIN ACCURACY: 87.285, TRAIN AUROC: 0.958\n","[EPOCH 45] VALID F1: 0.7026443604964923 VALID ACCURACY: 71.859, VALID AUROC: 0.798\n","epoch46: running_loss=8.778998970985413\n","[EPOCH 46] TRAIN F1: 0.8705790905557715 TRAIN ACCURACY: 87.246, TRAIN AUROC: 0.959\n","[EPOCH 46] VALID F1: 0.7129337539432178 VALID ACCURACY: 72.114, VALID AUROC: 0.802\n","epoch47: running_loss=8.752294287085533\n","[EPOCH 47] TRAIN F1: 0.8721527320605662 TRAIN ACCURACY: 87.604, TRAIN AUROC: 0.959\n","[EPOCH 47] VALID F1: 0.7130712008501593 VALID ACCURACY: 72.421, VALID AUROC: 0.800\n","epoch48: running_loss=8.71456789970398\n","[EPOCH 48] TRAIN F1: 0.8713082988106374 TRAIN ACCURACY: 87.706, TRAIN AUROC: 0.961\n","[EPOCH 48] VALID F1: 0.7023230686115614 VALID ACCURACY: 71.859, VALID AUROC: 0.802\n","epoch49: running_loss=8.631656661629677\n","[EPOCH 49] TRAIN F1: 0.8769913815617655 TRAIN ACCURACY: 87.974, TRAIN AUROC: 0.962\n","[EPOCH 49] VALID F1: 0.7186836518046708 VALID ACCURACY: 72.932, VALID AUROC: 0.807\n","epoch50: running_loss=8.549451440572739\n","[EPOCH 50] TRAIN F1: 0.8734092431346282 TRAIN ACCURACY: 87.936, TRAIN AUROC: 0.962\n","[EPOCH 50] VALID F1: 0.7027896995708155 VALID ACCURACY: 71.706, VALID AUROC: 0.802\n","epoch51: running_loss=8.40686009824276\n","[EPOCH 51] TRAIN F1: 0.8763412017167381 TRAIN ACCURACY: 88.229, TRAIN AUROC: 0.964\n","[EPOCH 51] VALID F1: 0.705945945945946 VALID ACCURACY: 72.217, VALID AUROC: 0.805\n","epoch52: running_loss=8.335886061191559\n","[EPOCH 52] TRAIN F1: 0.88118436036948 TRAIN ACCURACY: 88.012, TRAIN AUROC: 0.964\n","[EPOCH 52] VALID F1: 0.7196309584828293 VALID ACCURACY: 72.063, VALID AUROC: 0.802\n","epoch53: running_loss=8.242961034178734\n","[EPOCH 53] TRAIN F1: 0.8789825970548861 TRAIN ACCURACY: 88.459, TRAIN AUROC: 0.964\n","[EPOCH 53] VALID F1: 0.7025246981339188 VALID ACCURACY: 72.319, VALID AUROC: 0.802\n","epoch54: running_loss=8.305183291435242\n","[EPOCH 54] TRAIN F1: 0.8860792155850856 TRAIN ACCURACY: 88.727, TRAIN AUROC: 0.966\n","[EPOCH 54] VALID F1: 0.7128712871287128 VALID ACCURACY: 71.859, VALID AUROC: 0.798\n","epoch55: running_loss=8.208884909749031\n","[EPOCH 55] TRAIN F1: 0.8839285714285715 TRAIN ACCURACY: 88.714, TRAIN AUROC: 0.966\n","[EPOCH 55] VALID F1: 0.6961206896551723 VALID ACCURACY: 71.195, VALID AUROC: 0.797\n","epoch56: running_loss=8.181698575615883\n","[EPOCH 56] TRAIN F1: 0.8810643730681361 TRAIN ACCURACY: 88.702, TRAIN AUROC: 0.965\n","[EPOCH 56] VALID F1: 0.7021739130434782 VALID ACCURACY: 72.012, VALID AUROC: 0.800\n","epoch57: running_loss=8.242526769638062\n","[EPOCH 57] TRAIN F1: 0.8839736127279781 TRAIN ACCURACY: 88.548, TRAIN AUROC: 0.966\n","[EPOCH 57] VALID F1: 0.7059442398737507 VALID ACCURACY: 71.450, VALID AUROC: 0.797\n","epoch58: running_loss=8.106413558125496\n","[EPOCH 58] TRAIN F1: 0.8825422365245373 TRAIN ACCURACY: 88.817, TRAIN AUROC: 0.968\n","[EPOCH 58] VALID F1: 0.7021161150298426 VALID ACCURACY: 71.961, VALID AUROC: 0.801\n","epoch59: running_loss=7.951935723423958\n","[EPOCH 59] TRAIN F1: 0.8884802311835018 TRAIN ACCURACY: 89.161, TRAIN AUROC: 0.968\n","[EPOCH 59] VALID F1: 0.701216287678477 VALID ACCURACY: 71.144, VALID AUROC: 0.798\n","epoch60: running_loss=7.922487363219261\n","[EPOCH 60] TRAIN F1: 0.8837147062759266 TRAIN ACCURACY: 88.906, TRAIN AUROC: 0.968\n","[EPOCH 60] VALID F1: 0.6971677559912854 VALID ACCURACY: 71.604, VALID AUROC: 0.795\n","F1 on best model: 0.758130 (Epoch8)\n","(1958, 2)\n","\n","Final CV = 0.74093\n","(9800, 2)\n","===== fix_leak =====\n","Fix index1704: 1\n","To 1\n","Fix index3707: 1\n","To 1\n","Fix index4353: 1\n","To 1\n","Fix index4453: 1\n","To 1\n","Fix index4645: 1\n","To 0\n","Fix index6909: 1\n","To 1\n","Fix index8232: 1\n","To 0\n","[save file] ./outputs/Exp002_saint/scripts/SAINT_vol2.ipynb\n","[save file] ./outputs/Exp002_saint/scripts/EDA.ipynb\n","[save file] ./outputs/Exp002_saint/scripts/LightGBM.ipynb\n","[save file] ./outputs/Exp002_saint/scripts/DeBERTa-base.ipynb\n","[save file] ./outputs/Exp002_saint/scripts/SAINT_vol1.ipynb\n","[save file] ./outputs/Exp002_saint/scripts/SAINT_vol3.ipynb\n","[save file] ./outputs/Exp002_saint/scripts/SAINT_vol4.ipynb\n","[save file] ./outputs/Exp002_saint/scripts/DeBERTa_SAINT.ipynb\n"]}]},{"cell_type":"markdown","source":["# Parameter tuning"],"metadata":{"id":"E2E_Wb5IGQDz"}},{"cell_type":"markdown","source":["# Debug"],"metadata":{"id":"sQbfUtLQifRO"}},{"cell_type":"code","source":[],"metadata":{"id":"Y-ZQlfOsgoej","executionInfo":{"status":"ok","timestamp":1662720720467,"user_tz":-540,"elapsed":22,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":13,"outputs":[]}]}